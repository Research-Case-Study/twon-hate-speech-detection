{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16a280c3-8d6d-47b4-a831-4976f833dfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b96f834a-5e45-4f3b-9372-92a027371391",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/prompt_experiments_explainations/llm_results_final_prompt_006.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2d36f92c-9be6-4b62-8984-2801711814bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'post_id': '1181224026519359490_twitter', 'tweet_text': 'team name washington warhogs team colors red white and blue team location washington dc team president anybody but bruce allen', 'key_features': '[]', 'target': nan, 'label': 'normal'}\""
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]['Input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a72618a5-a21c-4ca9-9e80-0fc1cea1d52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row Number</th>\n",
       "      <th>Model</th>\n",
       "      <th>Prompt Name</th>\n",
       "      <th>Input</th>\n",
       "      <th>Response</th>\n",
       "      <th>Time Taken (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121</td>\n",
       "      <td>Hermes-3-Llama-3.1-70B-Q5_K_S:latest</td>\n",
       "      <td>zero_shot_prompt</td>\n",
       "      <td>{'post_id': '1181224026519359490_twitter', 'tw...</td>\n",
       "      <td>Based on the available data, this tweet appear...</td>\n",
       "      <td>21.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121</td>\n",
       "      <td>Hermes-3-Llama-3.1-70B-Q5_K_S:latest</td>\n",
       "      <td>few_shot_prompt</td>\n",
       "      <td>{'post_id': '1181224026519359490_twitter', 'tw...</td>\n",
       "      <td>The tweet has been labeled as normal because i...</td>\n",
       "      <td>14.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121</td>\n",
       "      <td>Hermes-3-Llama-3.1-70B-Q5_K_S:latest</td>\n",
       "      <td>few_shot_CoT_prompt</td>\n",
       "      <td>{'post_id': '1181224026519359490_twitter', 'tw...</td>\n",
       "      <td>The text appears to be a harmless suggestion f...</td>\n",
       "      <td>20.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>122</td>\n",
       "      <td>Hermes-3-Llama-3.1-70B-Q5_K_S:latest</td>\n",
       "      <td>zero_shot_prompt</td>\n",
       "      <td>{'post_id': '1083159533848023041_twitter', 'tw...</td>\n",
       "      <td>This tweet falls into the normal category beca...</td>\n",
       "      <td>15.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>122</td>\n",
       "      <td>Hermes-3-Llama-3.1-70B-Q5_K_S:latest</td>\n",
       "      <td>few_shot_CoT_prompt</td>\n",
       "      <td>{'post_id': '1083159533848023041_twitter', 'tw...</td>\n",
       "      <td>The classification of this text as \"normal\" is...</td>\n",
       "      <td>25.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Row Number                                 Model          Prompt Name  \\\n",
       "0         121  Hermes-3-Llama-3.1-70B-Q5_K_S:latest     zero_shot_prompt   \n",
       "1         121  Hermes-3-Llama-3.1-70B-Q5_K_S:latest      few_shot_prompt   \n",
       "2         121  Hermes-3-Llama-3.1-70B-Q5_K_S:latest  few_shot_CoT_prompt   \n",
       "3         122  Hermes-3-Llama-3.1-70B-Q5_K_S:latest     zero_shot_prompt   \n",
       "4         122  Hermes-3-Llama-3.1-70B-Q5_K_S:latest  few_shot_CoT_prompt   \n",
       "\n",
       "                                               Input  \\\n",
       "0  {'post_id': '1181224026519359490_twitter', 'tw...   \n",
       "1  {'post_id': '1181224026519359490_twitter', 'tw...   \n",
       "2  {'post_id': '1181224026519359490_twitter', 'tw...   \n",
       "3  {'post_id': '1083159533848023041_twitter', 'tw...   \n",
       "4  {'post_id': '1083159533848023041_twitter', 'tw...   \n",
       "\n",
       "                                            Response  Time Taken (s)  \n",
       "0  Based on the available data, this tweet appear...           21.82  \n",
       "1  The tweet has been labeled as normal because i...           14.56  \n",
       "2  The text appears to be a harmless suggestion f...           20.67  \n",
       "3  This tweet falls into the normal category beca...           15.31  \n",
       "4  The classification of this text as \"normal\" is...           25.57  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6efce0d8-1175-4f68-8abc-f7fc3670df0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prompt Name\n",
       "zero_shot_prompt       500\n",
       "few_shot_prompt        500\n",
       "few_shot_CoT_prompt    500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Prompt Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "64cf3306-2723-476b-8844-667270c6788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Create the three new columns based on 'Prompt Name'\n",
    "# df_pivoted = df.pivot(index='Row Number', columns='Prompt Name', values='Response')\n",
    "\n",
    "# # Join pivoted DataFrame back to original to preserve other columns\n",
    "# df = df.set_index('Row Number').join(df_pivoted).reset_index()\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2906298a-ee99-4d76-b23a-0ba7effa5211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# # Extract 'tweet_text' from 'Input' column and store it in 'tweet_text' column\n",
    "# df['tweet_text'] = df['Input'].apply(lambda x: re.search(r\"'tweet_text': '(.*?)', 'key_features':\", x).group(1))\n",
    "\n",
    "# print(df[['Row Number', 'tweet_text']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8cea089d-195c-4ff0-8825-58f0033c5e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Check for missing values in each column\n",
    "missing_values = df.isna().sum()\n",
    "\n",
    "# Reshape dataframe to have separate columns for each 'Prompt Name'\n",
    "pivoted_df = df.pivot_table(index='Row Number', columns='Prompt Name', values='Response', aggfunc='first')\n",
    "\n",
    "# Rename columns to match the desired ones\n",
    "pivoted_df.columns = ['zero_shot_prompt', 'few_shot_prompt', 'few_shot_CoT_prompt']\n",
    "\n",
    "# If you want to merge this back into the original dataframe, use:\n",
    "df = df[['Row Number', 'Input']].drop_duplicates().set_index('Row Number').join(pivoted_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "204df670-4f39-4151-b2de-e6fbdeda7b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>zero_shot_prompt</th>\n",
       "      <th>few_shot_prompt</th>\n",
       "      <th>few_shot_CoT_prompt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Row Number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>{'post_id': '1181224026519359490_twitter', 'tw...</td>\n",
       "      <td>The text appears to be a harmless suggestion f...</td>\n",
       "      <td>The tweet has been labeled as normal because i...</td>\n",
       "      <td>Based on the available data, this tweet appear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>{'post_id': '1083159533848023041_twitter', 'tw...</td>\n",
       "      <td>The classification of this text as \"normal\" is...</td>\n",
       "      <td>This tweet has been labeled as normal because ...</td>\n",
       "      <td>This tweet falls into the normal category beca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>{'post_id': '1091106800408190976_twitter', 'tw...</td>\n",
       "      <td>**Offensive**:\\n- tweet_text: \"tfw jews want t...</td>\n",
       "      <td>This statement is labeled offensive because it...</td>\n",
       "      <td>The text you provided falls into the \"offensiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>{'post_id': '15801100_gab', 'tweet_text': 'mic...</td>\n",
       "      <td>**Hate Speech**\\n\\nThe tweet contains a highly...</td>\n",
       "      <td>This statement is classified as hate speech be...</td>\n",
       "      <td>The tweet text falls into the category of hate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>{'post_id': '1177985601628442630_twitter', 'tw...</td>\n",
       "      <td>This tweet falls into the **Offensive** catego...</td>\n",
       "      <td>Explanation: The tweet has been labeled normal...</td>\n",
       "      <td>The text \"im wearing white pants and i look li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>{'post_id': '1163281024706633728_twitter', 'tw...</td>\n",
       "      <td>The text is classified as normal due to its ca...</td>\n",
       "      <td>The tweet has been labeled normal because the ...</td>\n",
       "      <td>Based on the given information, this tweet fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>{'post_id': '1181254867228250112_twitter', 'tw...</td>\n",
       "      <td>This tweet is classified as hate speech due to...</td>\n",
       "      <td>Explanation: This tweet has been labeled as no...</td>\n",
       "      <td>It appears that this tweet has been classified...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>{'post_id': '1177368240605007872_twitter', 'tw...</td>\n",
       "      <td>The text is classified as normal due to its de...</td>\n",
       "      <td>The tweet has been labeled normal because it s...</td>\n",
       "      <td>This tweet falls into the \"Normal\" category be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>{'post_id': '1103453694735966213_twitter', 'tw...</td>\n",
       "      <td>Based on the given text:\\n\\n1. **Normal**: The...</td>\n",
       "      <td>Explanation: This tweet has been labeled as no...</td>\n",
       "      <td>Based on the available data, this tweet appear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>{'post_id': '1109322805299027968_twitter', 'tw...</td>\n",
       "      <td>This text falls into the hate speech category ...</td>\n",
       "      <td>The text you provided has been categorized as ...</td>\n",
       "      <td>Based on the given tweet text, it appears to f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Input  \\\n",
       "Row Number                                                      \n",
       "121         {'post_id': '1181224026519359490_twitter', 'tw...   \n",
       "122         {'post_id': '1083159533848023041_twitter', 'tw...   \n",
       "123         {'post_id': '1091106800408190976_twitter', 'tw...   \n",
       "124         {'post_id': '15801100_gab', 'tweet_text': 'mic...   \n",
       "125         {'post_id': '1177985601628442630_twitter', 'tw...   \n",
       "...                                                       ...   \n",
       "616         {'post_id': '1163281024706633728_twitter', 'tw...   \n",
       "617         {'post_id': '1181254867228250112_twitter', 'tw...   \n",
       "618         {'post_id': '1177368240605007872_twitter', 'tw...   \n",
       "619         {'post_id': '1103453694735966213_twitter', 'tw...   \n",
       "620         {'post_id': '1109322805299027968_twitter', 'tw...   \n",
       "\n",
       "                                             zero_shot_prompt  \\\n",
       "Row Number                                                      \n",
       "121         The text appears to be a harmless suggestion f...   \n",
       "122         The classification of this text as \"normal\" is...   \n",
       "123         **Offensive**:\\n- tweet_text: \"tfw jews want t...   \n",
       "124         **Hate Speech**\\n\\nThe tweet contains a highly...   \n",
       "125         This tweet falls into the **Offensive** catego...   \n",
       "...                                                       ...   \n",
       "616         The text is classified as normal due to its ca...   \n",
       "617         This tweet is classified as hate speech due to...   \n",
       "618         The text is classified as normal due to its de...   \n",
       "619         Based on the given text:\\n\\n1. **Normal**: The...   \n",
       "620         This text falls into the hate speech category ...   \n",
       "\n",
       "                                              few_shot_prompt  \\\n",
       "Row Number                                                      \n",
       "121         The tweet has been labeled as normal because i...   \n",
       "122         This tweet has been labeled as normal because ...   \n",
       "123         This statement is labeled offensive because it...   \n",
       "124         This statement is classified as hate speech be...   \n",
       "125         Explanation: The tweet has been labeled normal...   \n",
       "...                                                       ...   \n",
       "616         The tweet has been labeled normal because the ...   \n",
       "617         Explanation: This tweet has been labeled as no...   \n",
       "618         The tweet has been labeled normal because it s...   \n",
       "619         Explanation: This tweet has been labeled as no...   \n",
       "620         The text you provided has been categorized as ...   \n",
       "\n",
       "                                          few_shot_CoT_prompt  \n",
       "Row Number                                                     \n",
       "121         Based on the available data, this tweet appear...  \n",
       "122         This tweet falls into the normal category beca...  \n",
       "123         The text you provided falls into the \"offensiv...  \n",
       "124         The tweet text falls into the category of hate...  \n",
       "125         The text \"im wearing white pants and i look li...  \n",
       "...                                                       ...  \n",
       "616         Based on the given information, this tweet fal...  \n",
       "617         It appears that this tweet has been classified...  \n",
       "618         This tweet falls into the \"Normal\" category be...  \n",
       "619         Based on the available data, this tweet appear...  \n",
       "620         Based on the given tweet text, it appears to f...  \n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1da302bb-d890-4513-8386-b581235ce4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Define the pattern to extract tweet_text\n",
    "pattern = r\"'tweet_text': '(.*?)', 'key_features':\"\n",
    "\n",
    "# Extract tweet_text and save it in a new column\n",
    "df['tweet_text'] = df['Input'].apply(lambda x: re.search(pattern, x).group(1) if re.search(pattern, x) else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4de69131-6e41-40cf-8de8-6fa2e619f9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>zero_shot_prompt</th>\n",
       "      <th>few_shot_prompt</th>\n",
       "      <th>few_shot_CoT_prompt</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Row Number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>{'post_id': '1181224026519359490_twitter', 'tw...</td>\n",
       "      <td>The text appears to be a harmless suggestion f...</td>\n",
       "      <td>The tweet has been labeled as normal because i...</td>\n",
       "      <td>Based on the available data, this tweet appear...</td>\n",
       "      <td>team name washington warhogs team colors red w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>{'post_id': '1083159533848023041_twitter', 'tw...</td>\n",
       "      <td>The classification of this text as \"normal\" is...</td>\n",
       "      <td>This tweet has been labeled as normal because ...</td>\n",
       "      <td>This tweet falls into the normal category beca...</td>\n",
       "      <td>the same niggas that be flexing jewelry be the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>{'post_id': '1091106800408190976_twitter', 'tw...</td>\n",
       "      <td>**Offensive**:\\n- tweet_text: \"tfw jews want t...</td>\n",
       "      <td>This statement is labeled offensive because it...</td>\n",
       "      <td>The text you provided falls into the \"offensiv...</td>\n",
       "      <td>tfw jews want to ban p*rn &lt;censored&gt; tfw now i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>{'post_id': '15801100_gab', 'tweet_text': 'mic...</td>\n",
       "      <td>**Hate Speech**\\n\\nThe tweet contains a highly...</td>\n",
       "      <td>This statement is classified as hate speech be...</td>\n",
       "      <td>The tweet text falls into the category of hate...</td>\n",
       "      <td>microchip has had more nigger cocks in him tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>{'post_id': '1177985601628442630_twitter', 'tw...</td>\n",
       "      <td>This tweet falls into the **Offensive** catego...</td>\n",
       "      <td>Explanation: The tweet has been labeled normal...</td>\n",
       "      <td>The text \"im wearing white pants and i look li...</td>\n",
       "      <td>im wearing white pants and i look like a faggot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>{'post_id': '1163281024706633728_twitter', 'tw...</td>\n",
       "      <td>The text is classified as normal due to its ca...</td>\n",
       "      <td>The tweet has been labeled normal because the ...</td>\n",
       "      <td>Based on the given information, this tweet fal...</td>\n",
       "      <td>&lt;user&gt; &lt;user&gt; can not relate tho lmao i am not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>{'post_id': '1181254867228250112_twitter', 'tw...</td>\n",
       "      <td>This tweet is classified as hate speech due to...</td>\n",
       "      <td>Explanation: This tweet has been labeled as no...</td>\n",
       "      <td>It appears that this tweet has been classified...</td>\n",
       "      <td>weed guys the most emotional niggas ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>{'post_id': '1177368240605007872_twitter', 'tw...</td>\n",
       "      <td>The text is classified as normal due to its de...</td>\n",
       "      <td>The tweet has been labeled normal because it s...</td>\n",
       "      <td>This tweet falls into the \"Normal\" category be...</td>\n",
       "      <td>the elders of monroe are swarming the streets ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>{'post_id': '1103453694735966213_twitter', 'tw...</td>\n",
       "      <td>Based on the given text:\\n\\n1. **Normal**: The...</td>\n",
       "      <td>Explanation: This tweet has been labeled as no...</td>\n",
       "      <td>Based on the available data, this tweet appear...</td>\n",
       "      <td>shout out to ol jews and ol rules</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>{'post_id': '1109322805299027968_twitter', 'tw...</td>\n",
       "      <td>This text falls into the hate speech category ...</td>\n",
       "      <td>The text you provided has been categorized as ...</td>\n",
       "      <td>Based on the given tweet text, it appears to f...</td>\n",
       "      <td>cause it a grimy world and niggas bout shit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Input  \\\n",
       "Row Number                                                      \n",
       "121         {'post_id': '1181224026519359490_twitter', 'tw...   \n",
       "122         {'post_id': '1083159533848023041_twitter', 'tw...   \n",
       "123         {'post_id': '1091106800408190976_twitter', 'tw...   \n",
       "124         {'post_id': '15801100_gab', 'tweet_text': 'mic...   \n",
       "125         {'post_id': '1177985601628442630_twitter', 'tw...   \n",
       "...                                                       ...   \n",
       "616         {'post_id': '1163281024706633728_twitter', 'tw...   \n",
       "617         {'post_id': '1181254867228250112_twitter', 'tw...   \n",
       "618         {'post_id': '1177368240605007872_twitter', 'tw...   \n",
       "619         {'post_id': '1103453694735966213_twitter', 'tw...   \n",
       "620         {'post_id': '1109322805299027968_twitter', 'tw...   \n",
       "\n",
       "                                             zero_shot_prompt  \\\n",
       "Row Number                                                      \n",
       "121         The text appears to be a harmless suggestion f...   \n",
       "122         The classification of this text as \"normal\" is...   \n",
       "123         **Offensive**:\\n- tweet_text: \"tfw jews want t...   \n",
       "124         **Hate Speech**\\n\\nThe tweet contains a highly...   \n",
       "125         This tweet falls into the **Offensive** catego...   \n",
       "...                                                       ...   \n",
       "616         The text is classified as normal due to its ca...   \n",
       "617         This tweet is classified as hate speech due to...   \n",
       "618         The text is classified as normal due to its de...   \n",
       "619         Based on the given text:\\n\\n1. **Normal**: The...   \n",
       "620         This text falls into the hate speech category ...   \n",
       "\n",
       "                                              few_shot_prompt  \\\n",
       "Row Number                                                      \n",
       "121         The tweet has been labeled as normal because i...   \n",
       "122         This tweet has been labeled as normal because ...   \n",
       "123         This statement is labeled offensive because it...   \n",
       "124         This statement is classified as hate speech be...   \n",
       "125         Explanation: The tweet has been labeled normal...   \n",
       "...                                                       ...   \n",
       "616         The tweet has been labeled normal because the ...   \n",
       "617         Explanation: This tweet has been labeled as no...   \n",
       "618         The tweet has been labeled normal because it s...   \n",
       "619         Explanation: This tweet has been labeled as no...   \n",
       "620         The text you provided has been categorized as ...   \n",
       "\n",
       "                                          few_shot_CoT_prompt  \\\n",
       "Row Number                                                      \n",
       "121         Based on the available data, this tweet appear...   \n",
       "122         This tweet falls into the normal category beca...   \n",
       "123         The text you provided falls into the \"offensiv...   \n",
       "124         The tweet text falls into the category of hate...   \n",
       "125         The text \"im wearing white pants and i look li...   \n",
       "...                                                       ...   \n",
       "616         Based on the given information, this tweet fal...   \n",
       "617         It appears that this tweet has been classified...   \n",
       "618         This tweet falls into the \"Normal\" category be...   \n",
       "619         Based on the available data, this tweet appear...   \n",
       "620         Based on the given tweet text, it appears to f...   \n",
       "\n",
       "                                                   tweet_text  \n",
       "Row Number                                                     \n",
       "121         team name washington warhogs team colors red w...  \n",
       "122         the same niggas that be flexing jewelry be the...  \n",
       "123         tfw jews want to ban p*rn <censored> tfw now i...  \n",
       "124         microchip has had more nigger cocks in him tha...  \n",
       "125           im wearing white pants and i look like a faggot  \n",
       "...                                                       ...  \n",
       "616         <user> <user> can not relate tho lmao i am not...  \n",
       "617                  weed guys the most emotional niggas ever  \n",
       "618         the elders of monroe are swarming the streets ...  \n",
       "619                         shout out to ol jews and ol rules  \n",
       "620               cause it a grimy world and niggas bout shit  \n",
       "\n",
       "[500 rows x 5 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "93cb0c15-2330-4247-9616-1f27fe5014d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"LimeSurvey/LimeSurvey_data_pivoted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6d77f267-5474-42b5-aa26-507a4f3d051d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total length of responses for each row\n",
    "df['total_len'] = df['zero_shot_prompt'].apply(len) + df['few_shot_prompt'].apply(len) + df['few_shot_CoT_prompt'].apply(len)\n",
    "\n",
    "# Sort the DataFrame by the total length in descending order\n",
    "df_sorted = df.sort_values(by='total_len', ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bb5c496f-073f-4e0b-9b56-f9570efd81f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted.to_csv(\"LimeSurvey/LimeSurvey_data_pivoted_sorted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "93c4ccac-b7ea-4f72-8062-3f1ea36f29c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create new columns for each 'Prompt Name' and store the corresponding 'Response'\n",
    "df_wide = df.pivot(index='Row Number', columns='Prompt Name', values='Response').reset_index()\n",
    "\n",
    "# # Step 2: Extract 'tweet_text' from the 'Input' column\n",
    "# import ast\n",
    "\n",
    "# def extract_tweet_text(input_str):\n",
    "#     try:\n",
    "#         input_dict = ast.literal_eval(input_str)\n",
    "#         print(input_dict)\n",
    "#         return input_dict.get('tweet_text', None)\n",
    "#     except (ValueError, SyntaxError):\n",
    "#         return None\n",
    "\n",
    "# df['tweet_text'] = df['Input']# .apply(extract_tweet_text)\n",
    "\n",
    "import re\n",
    "\n",
    "# Regular expression pattern to extract the 'tweet_text' value\n",
    "pattern = r\"'tweet_text': '(.*?)', 'key_features':\"\n",
    "\n",
    "# Function to extract tweet_text from the row\n",
    "def extract_tweet_text_from_row(row):\n",
    "    match = re.search(pattern, row)\n",
    "    if match:\n",
    "        return match.group(1)  # Return the extracted tweet_text\n",
    "    else:\n",
    "        print(f\"Error parsing row: {row}\")\n",
    "        return None\n",
    "\n",
    "# Assuming you are applying this function to a column in a dataframe\n",
    "df['tweet_text'] = df['Input'].apply(extract_tweet_text_from_row)\n",
    "\n",
    "# Merging the extracted tweet_text with the reshaped DataFrame\n",
    "df_final = pd.merge(df_wide, df[['Row Number', 'tweet_text']].drop_duplicates(), on='Row Number')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4a87a73d-c916-4733-a33b-e13688ea7112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row Number</th>\n",
       "      <th>few_shot_CoT_prompt</th>\n",
       "      <th>few_shot_prompt</th>\n",
       "      <th>zero_shot_prompt</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121</td>\n",
       "      <td>The text appears to be a harmless suggestion f...</td>\n",
       "      <td>The tweet has been labeled as normal because i...</td>\n",
       "      <td>Based on the available data, this tweet appear...</td>\n",
       "      <td>team name washington warhogs team colors red w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122</td>\n",
       "      <td>The classification of this text as \"normal\" is...</td>\n",
       "      <td>This tweet has been labeled as normal because ...</td>\n",
       "      <td>This tweet falls into the normal category beca...</td>\n",
       "      <td>the same niggas that be flexing jewelry be the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123</td>\n",
       "      <td>**Offensive**:\\n- tweet_text: \"tfw jews want t...</td>\n",
       "      <td>This statement is labeled offensive because it...</td>\n",
       "      <td>The text you provided falls into the \"offensiv...</td>\n",
       "      <td>tfw jews want to ban p*rn &lt;censored&gt; tfw now i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>124</td>\n",
       "      <td>**Hate Speech**\\n\\nThe tweet contains a highly...</td>\n",
       "      <td>This statement is classified as hate speech be...</td>\n",
       "      <td>The tweet text falls into the category of hate...</td>\n",
       "      <td>microchip has had more nigger cocks in him tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125</td>\n",
       "      <td>This tweet falls into the **Offensive** catego...</td>\n",
       "      <td>Explanation: The tweet has been labeled normal...</td>\n",
       "      <td>The text \"im wearing white pants and i look li...</td>\n",
       "      <td>im wearing white pants and i look like a faggot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>616</td>\n",
       "      <td>The text is classified as normal due to its ca...</td>\n",
       "      <td>The tweet has been labeled normal because the ...</td>\n",
       "      <td>Based on the given information, this tweet fal...</td>\n",
       "      <td>&lt;user&gt; &lt;user&gt; can not relate tho lmao i am not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>617</td>\n",
       "      <td>This tweet is classified as hate speech due to...</td>\n",
       "      <td>Explanation: This tweet has been labeled as no...</td>\n",
       "      <td>It appears that this tweet has been classified...</td>\n",
       "      <td>weed guys the most emotional niggas ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>618</td>\n",
       "      <td>The text is classified as normal due to its de...</td>\n",
       "      <td>The tweet has been labeled normal because it s...</td>\n",
       "      <td>This tweet falls into the \"Normal\" category be...</td>\n",
       "      <td>the elders of monroe are swarming the streets ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>619</td>\n",
       "      <td>Based on the given text:\\n\\n1. **Normal**: The...</td>\n",
       "      <td>Explanation: This tweet has been labeled as no...</td>\n",
       "      <td>Based on the available data, this tweet appear...</td>\n",
       "      <td>shout out to ol jews and ol rules</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>620</td>\n",
       "      <td>This text falls into the hate speech category ...</td>\n",
       "      <td>The text you provided has been categorized as ...</td>\n",
       "      <td>Based on the given tweet text, it appears to f...</td>\n",
       "      <td>cause it a grimy world and niggas bout shit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Row Number                                few_shot_CoT_prompt  \\\n",
       "0           121  The text appears to be a harmless suggestion f...   \n",
       "1           122  The classification of this text as \"normal\" is...   \n",
       "2           123  **Offensive**:\\n- tweet_text: \"tfw jews want t...   \n",
       "3           124  **Hate Speech**\\n\\nThe tweet contains a highly...   \n",
       "4           125  This tweet falls into the **Offensive** catego...   \n",
       "..          ...                                                ...   \n",
       "495         616  The text is classified as normal due to its ca...   \n",
       "496         617  This tweet is classified as hate speech due to...   \n",
       "497         618  The text is classified as normal due to its de...   \n",
       "498         619  Based on the given text:\\n\\n1. **Normal**: The...   \n",
       "499         620  This text falls into the hate speech category ...   \n",
       "\n",
       "                                       few_shot_prompt  \\\n",
       "0    The tweet has been labeled as normal because i...   \n",
       "1    This tweet has been labeled as normal because ...   \n",
       "2    This statement is labeled offensive because it...   \n",
       "3    This statement is classified as hate speech be...   \n",
       "4    Explanation: The tweet has been labeled normal...   \n",
       "..                                                 ...   \n",
       "495  The tweet has been labeled normal because the ...   \n",
       "496  Explanation: This tweet has been labeled as no...   \n",
       "497  The tweet has been labeled normal because it s...   \n",
       "498  Explanation: This tweet has been labeled as no...   \n",
       "499  The text you provided has been categorized as ...   \n",
       "\n",
       "                                      zero_shot_prompt  \\\n",
       "0    Based on the available data, this tweet appear...   \n",
       "1    This tweet falls into the normal category beca...   \n",
       "2    The text you provided falls into the \"offensiv...   \n",
       "3    The tweet text falls into the category of hate...   \n",
       "4    The text \"im wearing white pants and i look li...   \n",
       "..                                                 ...   \n",
       "495  Based on the given information, this tweet fal...   \n",
       "496  It appears that this tweet has been classified...   \n",
       "497  This tweet falls into the \"Normal\" category be...   \n",
       "498  Based on the available data, this tweet appear...   \n",
       "499  Based on the given tweet text, it appears to f...   \n",
       "\n",
       "                                            tweet_text  \n",
       "0    team name washington warhogs team colors red w...  \n",
       "1    the same niggas that be flexing jewelry be the...  \n",
       "2    tfw jews want to ban p*rn <censored> tfw now i...  \n",
       "3    microchip has had more nigger cocks in him tha...  \n",
       "4      im wearing white pants and i look like a faggot  \n",
       "..                                                 ...  \n",
       "495  <user> <user> can not relate tho lmao i am not...  \n",
       "496           weed guys the most emotional niggas ever  \n",
       "497  the elders of monroe are swarming the streets ...  \n",
       "498                  shout out to ol jews and ol rules  \n",
       "499        cause it a grimy world and niggas bout shit  \n",
       "\n",
       "[500 rows x 5 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59fff8a-79e1-42fc-8802-f2abedf702fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['tweet_text'] = df_final['tweet_text'].apply(extract_tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56456ee3-ab51-40a0-98d7-2d8db2b73632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dbc454c8-28c2-4a48-8eab-f13319da505b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with missing tweet_text: Empty DataFrame\n",
      "Columns: [Row Number, Model, Prompt Name, Input, Response, Time Taken (s), tweet_text]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Regular expression pattern to extract the 'tweet_text' value\n",
    "pattern = r\"'tweet_text': '(.*?)', 'key_features':\"\n",
    "\n",
    "# Function to extract tweet_text from the row\n",
    "def extract_tweet_text_from_row(row):\n",
    "    match = re.search(pattern, row)\n",
    "    if match:\n",
    "        return match.group(1)  # Return the extracted tweet_text\n",
    "    else:\n",
    "        print(f\"Error parsing row: {row}\")\n",
    "        return None\n",
    "\n",
    "# Assuming you are applying this function to a column in a dataframe\n",
    "df['tweet_text'] = df['Input'].apply(extract_tweet_text_from_row)\n",
    "\n",
    "# Check rows where 'tweet_text' is still missing\n",
    "missing_tweet_text_rows = df[df['tweet_text'].isnull()]\n",
    "print(f\"Rows with missing tweet_text: {missing_tweet_text_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "26b02127-ed8d-4b86-b2aa-2c3da0d0f7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row Number</th>\n",
       "      <th>Model</th>\n",
       "      <th>Prompt Name</th>\n",
       "      <th>Input</th>\n",
       "      <th>Response</th>\n",
       "      <th>Time Taken (s)</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121</td>\n",
       "      <td>Hermes-3-Llama-3.1-70B-Q5_K_S:latest</td>\n",
       "      <td>zero_shot_prompt</td>\n",
       "      <td>{'post_id': '1181224026519359490_twitter', 'tw...</td>\n",
       "      <td>Based on the available data, this tweet appear...</td>\n",
       "      <td>21.82</td>\n",
       "      <td>team name washington warhogs team colors red w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121</td>\n",
       "      <td>Hermes-3-Llama-3.1-70B-Q5_K_S:latest</td>\n",
       "      <td>few_shot_prompt</td>\n",
       "      <td>{'post_id': '1181224026519359490_twitter', 'tw...</td>\n",
       "      <td>The tweet has been labeled as normal because i...</td>\n",
       "      <td>14.56</td>\n",
       "      <td>team name washington warhogs team colors red w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121</td>\n",
       "      <td>Hermes-3-Llama-3.1-70B-Q5_K_S:latest</td>\n",
       "      <td>few_shot_CoT_prompt</td>\n",
       "      <td>{'post_id': '1181224026519359490_twitter', 'tw...</td>\n",
       "      <td>The text appears to be a harmless suggestion f...</td>\n",
       "      <td>20.67</td>\n",
       "      <td>team name washington warhogs team colors red w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>122</td>\n",
       "      <td>Hermes-3-Llama-3.1-70B-Q5_K_S:latest</td>\n",
       "      <td>zero_shot_prompt</td>\n",
       "      <td>{'post_id': '1083159533848023041_twitter', 'tw...</td>\n",
       "      <td>This tweet falls into the normal category beca...</td>\n",
       "      <td>15.31</td>\n",
       "      <td>the same niggas that be flexing jewelry be the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>122</td>\n",
       "      <td>Hermes-3-Llama-3.1-70B-Q5_K_S:latest</td>\n",
       "      <td>few_shot_CoT_prompt</td>\n",
       "      <td>{'post_id': '1083159533848023041_twitter', 'tw...</td>\n",
       "      <td>The classification of this text as \"normal\" is...</td>\n",
       "      <td>25.57</td>\n",
       "      <td>the same niggas that be flexing jewelry be the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>619</td>\n",
       "      <td>Hermes-3-Llama-3.1-70B-Q5_K_S:latest</td>\n",
       "      <td>zero_shot_prompt</td>\n",
       "      <td>{'post_id': '1103453694735966213_twitter', 'tw...</td>\n",
       "      <td>Based on the available data, this tweet appear...</td>\n",
       "      <td>16.94</td>\n",
       "      <td>shout out to ol jews and ol rules</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>619</td>\n",
       "      <td>Hermes-3-Llama-3.1-70B-Q5_K_S:latest</td>\n",
       "      <td>few_shot_CoT_prompt</td>\n",
       "      <td>{'post_id': '1103453694735966213_twitter', 'tw...</td>\n",
       "      <td>Based on the given text:\\n\\n1. **Normal**: The...</td>\n",
       "      <td>14.73</td>\n",
       "      <td>shout out to ol jews and ol rules</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>620</td>\n",
       "      <td>Hermes-3-Llama-3.1-70B-Q5_K_S:latest</td>\n",
       "      <td>few_shot_prompt</td>\n",
       "      <td>{'post_id': '1109322805299027968_twitter', 'tw...</td>\n",
       "      <td>The text you provided has been categorized as ...</td>\n",
       "      <td>18.35</td>\n",
       "      <td>cause it a grimy world and niggas bout shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>620</td>\n",
       "      <td>Hermes-3-Llama-3.1-70B-Q5_K_S:latest</td>\n",
       "      <td>zero_shot_prompt</td>\n",
       "      <td>{'post_id': '1109322805299027968_twitter', 'tw...</td>\n",
       "      <td>Based on the given tweet text, it appears to f...</td>\n",
       "      <td>24.40</td>\n",
       "      <td>cause it a grimy world and niggas bout shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>620</td>\n",
       "      <td>Hermes-3-Llama-3.1-70B-Q5_K_S:latest</td>\n",
       "      <td>few_shot_CoT_prompt</td>\n",
       "      <td>{'post_id': '1109322805299027968_twitter', 'tw...</td>\n",
       "      <td>This text falls into the hate speech category ...</td>\n",
       "      <td>17.56</td>\n",
       "      <td>cause it a grimy world and niggas bout shit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Row Number                                 Model          Prompt Name  \\\n",
       "0            121  Hermes-3-Llama-3.1-70B-Q5_K_S:latest     zero_shot_prompt   \n",
       "1            121  Hermes-3-Llama-3.1-70B-Q5_K_S:latest      few_shot_prompt   \n",
       "2            121  Hermes-3-Llama-3.1-70B-Q5_K_S:latest  few_shot_CoT_prompt   \n",
       "3            122  Hermes-3-Llama-3.1-70B-Q5_K_S:latest     zero_shot_prompt   \n",
       "4            122  Hermes-3-Llama-3.1-70B-Q5_K_S:latest  few_shot_CoT_prompt   \n",
       "...          ...                                   ...                  ...   \n",
       "1495         619  Hermes-3-Llama-3.1-70B-Q5_K_S:latest     zero_shot_prompt   \n",
       "1496         619  Hermes-3-Llama-3.1-70B-Q5_K_S:latest  few_shot_CoT_prompt   \n",
       "1497         620  Hermes-3-Llama-3.1-70B-Q5_K_S:latest      few_shot_prompt   \n",
       "1498         620  Hermes-3-Llama-3.1-70B-Q5_K_S:latest     zero_shot_prompt   \n",
       "1499         620  Hermes-3-Llama-3.1-70B-Q5_K_S:latest  few_shot_CoT_prompt   \n",
       "\n",
       "                                                  Input  \\\n",
       "0     {'post_id': '1181224026519359490_twitter', 'tw...   \n",
       "1     {'post_id': '1181224026519359490_twitter', 'tw...   \n",
       "2     {'post_id': '1181224026519359490_twitter', 'tw...   \n",
       "3     {'post_id': '1083159533848023041_twitter', 'tw...   \n",
       "4     {'post_id': '1083159533848023041_twitter', 'tw...   \n",
       "...                                                 ...   \n",
       "1495  {'post_id': '1103453694735966213_twitter', 'tw...   \n",
       "1496  {'post_id': '1103453694735966213_twitter', 'tw...   \n",
       "1497  {'post_id': '1109322805299027968_twitter', 'tw...   \n",
       "1498  {'post_id': '1109322805299027968_twitter', 'tw...   \n",
       "1499  {'post_id': '1109322805299027968_twitter', 'tw...   \n",
       "\n",
       "                                               Response  Time Taken (s)  \\\n",
       "0     Based on the available data, this tweet appear...           21.82   \n",
       "1     The tweet has been labeled as normal because i...           14.56   \n",
       "2     The text appears to be a harmless suggestion f...           20.67   \n",
       "3     This tweet falls into the normal category beca...           15.31   \n",
       "4     The classification of this text as \"normal\" is...           25.57   \n",
       "...                                                 ...             ...   \n",
       "1495  Based on the available data, this tweet appear...           16.94   \n",
       "1496  Based on the given text:\\n\\n1. **Normal**: The...           14.73   \n",
       "1497  The text you provided has been categorized as ...           18.35   \n",
       "1498  Based on the given tweet text, it appears to f...           24.40   \n",
       "1499  This text falls into the hate speech category ...           17.56   \n",
       "\n",
       "                                             tweet_text  \n",
       "0     team name washington warhogs team colors red w...  \n",
       "1     team name washington warhogs team colors red w...  \n",
       "2     team name washington warhogs team colors red w...  \n",
       "3     the same niggas that be flexing jewelry be the...  \n",
       "4     the same niggas that be flexing jewelry be the...  \n",
       "...                                                 ...  \n",
       "1495                  shout out to ol jews and ol rules  \n",
       "1496                  shout out to ol jews and ol rules  \n",
       "1497        cause it a grimy world and niggas bout shit  \n",
       "1498        cause it a grimy world and niggas bout shit  \n",
       "1499        cause it a grimy world and niggas bout shit  \n",
       "\n",
       "[1500 rows x 7 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c3b64aac-7066-461a-93ce-17bc5a88cc5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'key_features_str' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Apply the function to extract 'tweet_text'\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mInput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextract_tweet_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Step 3: Merge the reshaped DataFrame with the extracted 'tweet_text'\u001b[39;00m\n\u001b[0;32m     36\u001b[0m df_final \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(\n\u001b[0;32m     37\u001b[0m     df_wide,\n\u001b[0;32m     38\u001b[0m     df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRow Number\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_text\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdrop_duplicates(),\n\u001b[0;32m     39\u001b[0m     on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRow Number\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     40\u001b[0m     how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Ensure no rows are dropped\u001b[39;00m\n\u001b[0;32m     41\u001b[0m )\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[46], line 14\u001b[0m, in \u001b[0;36mextract_tweet_text\u001b[1;34m(input_str)\u001b[0m\n\u001b[0;32m     12\u001b[0m input_str \u001b[38;5;241m=\u001b[39m input_str\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Normalize single quotes to double quotes\u001b[39;00m\n\u001b[0;32m     13\u001b[0m input_str \u001b[38;5;241m=\u001b[39m input_str\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Ensure proper list formatting\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m key_features_str \u001b[38;5;241m=\u001b[39m \u001b[43mkey_features_str\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Safely parse the string into a Python dictionary\u001b[39;00m\n\u001b[0;32m     17\u001b[0m input_dict \u001b[38;5;241m=\u001b[39m ast\u001b[38;5;241m.\u001b[39mliteral_eval(input_str)\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'key_features_str' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import json\n",
    "\n",
    "# Step 1: Pivot the DataFrame to create separate columns for each 'Prompt Name'\n",
    "df_wide = df.pivot(index='Row Number', columns='Prompt Name', values='Response').reset_index()\n",
    "\n",
    "# Step 2: Extract 'tweet_text' from the 'Input' column\n",
    "def extract_tweet_text(input_str):\n",
    "    try:\n",
    "        # Fix any list-like string formatting in 'key_features'\n",
    "        input_str = input_str.replace(\"'\", '\"')  # Normalize single quotes to double quotes\n",
    "        input_str = input_str.replace('[', '[').replace(']', ']')  # Ensure proper list formatting\n",
    "        key_features_str = key_features_str.replace(\"'\", '\"')\n",
    "\n",
    "        # Safely parse the string into a Python dictionary\n",
    "        input_dict = ast.literal_eval(input_str)\n",
    "\n",
    "        return input_dict.get('tweet_text', None)\n",
    "    except (ValueError, SyntaxError, json.JSONDecodeError):\n",
    "        # Fallback: Try parsing with json.loads\n",
    "        try:\n",
    "            input_dict = json.loads(input_str)\n",
    "            return input_dict.get('tweet_text', None)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error parsing row: {input_str}\")\n",
    "            return None\n",
    "\n",
    "# Ensure consistent quotes before parsing\n",
    "df['Input'] = df['Input'].str.replace('\"', \"'\", regex=False)\n",
    "\n",
    "# Apply the function to extract 'tweet_text'\n",
    "df['tweet_text'] = df['Input'].apply(extract_tweet_text)\n",
    "\n",
    "# Step 3: Merge the reshaped DataFrame with the extracted 'tweet_text'\n",
    "df_final = pd.merge(\n",
    "    df_wide,\n",
    "    df[['Row Number', 'tweet_text']].drop_duplicates(),\n",
    "    on='Row Number',\n",
    "    how='left'  # Ensure no rows are dropped\n",
    ")\n",
    "\n",
    "# Debug any rows where 'tweet_text' is missing\n",
    "missing_tweet_text_rows = df_final[df_final['tweet_text'].isnull()]\n",
    "print(\"Rows with missing 'tweet_text':\", missing_tweet_text_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "243fb346-0d60-49da-8ba7-b514356ed28a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'key_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'key_features'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Assuming your dataframe is called `df`\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey_features\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkey_features\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(parse_key_features)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Step 3: Apply the function to extract 'tweet_text' from the 'Input' column\u001b[39;00m\n\u001b[0;32m     29\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(extract_tweet_text)\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'key_features'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Step 1: Normalize and safely parse the 'key_features' column\n",
    "def parse_key_features(key_features_str):\n",
    "    try:\n",
    "        # Fix any list-like string formatting, convert it to proper list\n",
    "        key_features_str = key_features_str.replace(\"'\", '\"')  # Normalize quotes\n",
    "        key_features_list = ast.literal_eval(key_features_str)  # Safely parse as a list\n",
    "        return key_features_list\n",
    "    except (ValueError, SyntaxError, TypeError):\n",
    "        print(f\"Error parsing key_features: {key_features_str}\")\n",
    "        return []\n",
    "\n",
    "# Step 2: Parse the input column correctly\n",
    "def extract_tweet_text(input_str):\n",
    "    try:\n",
    "        # Replace single quotes with double quotes and parse the input string\n",
    "        input_dict = ast.literal_eval(input_str.replace(\"'\", '\"'))\n",
    "        return input_dict.get('tweet_text', None)\n",
    "    except (ValueError, SyntaxError, TypeError):\n",
    "        print(f\"Error parsing row: {input_str}\")\n",
    "        return None\n",
    "\n",
    "# Assuming your dataframe is called `df`\n",
    "df['key_features'] = df['key_features'].apply(parse_key_features)\n",
    "\n",
    "# Step 3: Apply the function to extract 'tweet_text' from the 'Input' column\n",
    "df['tweet_text'] = df['Input'].apply(extract_tweet_text)\n",
    "\n",
    "# Check any rows where 'tweet_text' is still missing\n",
    "missing_tweet_text_rows = df[df['tweet_text'].isnull()]\n",
    "print(f\"Rows with missing tweet_text: {missing_tweet_text_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95a68a9-c3ec-4e97-9b0b-2bcc2b71fb55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
