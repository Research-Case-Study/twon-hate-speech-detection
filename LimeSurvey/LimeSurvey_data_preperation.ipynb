{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16a280c3-8d6d-47b4-a831-4976f833dfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b96f834a-5e45-4f3b-9372-92a027371391",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/prompt_experiments_explainations/llm_results_final_prompt_007.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d36f92c-9be6-4b62-8984-2801711814bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\'post_id\\': \\'1179074562870386688_twitter\\', \\'tweet_text\\': \\'this fat faggot id such a child grow up porky\\', \\'key_features\\': \"[\\'fat\\', \\'faggot\\']\", \\'target\\': \\'Homosexual, Nonreligious, Other\\', \\'label\\': \\'hatespeech\\'}'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]['Input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a72618a5-a21c-4ca9-9e80-0fc1cea1d52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row Number</th>\n",
       "      <th>Model</th>\n",
       "      <th>Prompt Name</th>\n",
       "      <th>Input</th>\n",
       "      <th>Response</th>\n",
       "      <th>Time Taken (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>621</td>\n",
       "      <td>Hermes-3-Llama-3.1-70B-Q5_K_S:latest</td>\n",
       "      <td>zero_shot_prompt</td>\n",
       "      <td>{'post_id': '1179074562870386688_twitter', 'tw...</td>\n",
       "      <td>The text you provided falls into the category ...</td>\n",
       "      <td>33.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>621</td>\n",
       "      <td>Hermes-3-Llama-3.1-70B-Q5_K_S:latest</td>\n",
       "      <td>few_shot_prompt</td>\n",
       "      <td>{'post_id': '1179074562870386688_twitter', 'tw...</td>\n",
       "      <td>This statement is classified as hate speech be...</td>\n",
       "      <td>18.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>621</td>\n",
       "      <td>Hermes-3-Llama-3.1-70B-Q5_K_S:latest</td>\n",
       "      <td>few_shot_CoT_prompt</td>\n",
       "      <td>{'post_id': '1179074562870386688_twitter', 'tw...</td>\n",
       "      <td>The text is labeled as hate speech due to the ...</td>\n",
       "      <td>14.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>622</td>\n",
       "      <td>Hermes-3-Llama-3.1-70B-Q5_K_S:latest</td>\n",
       "      <td>few_shot_prompt</td>\n",
       "      <td>{'post_id': '16535198_gab', 'tweet_text': 'let...</td>\n",
       "      <td>The tweet you wrote has been classified as hat...</td>\n",
       "      <td>22.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>622</td>\n",
       "      <td>Hermes-3-Llama-3.1-70B-Q5_K_S:latest</td>\n",
       "      <td>few_shot_CoT_prompt</td>\n",
       "      <td>{'post_id': '16535198_gab', 'tweet_text': 'let...</td>\n",
       "      <td>The text is classified as hate speech due to i...</td>\n",
       "      <td>16.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Row Number                                 Model          Prompt Name  \\\n",
       "0         621  Hermes-3-Llama-3.1-70B-Q5_K_S:latest     zero_shot_prompt   \n",
       "1         621  Hermes-3-Llama-3.1-70B-Q5_K_S:latest      few_shot_prompt   \n",
       "2         621  Hermes-3-Llama-3.1-70B-Q5_K_S:latest  few_shot_CoT_prompt   \n",
       "3         622  Hermes-3-Llama-3.1-70B-Q5_K_S:latest      few_shot_prompt   \n",
       "4         622  Hermes-3-Llama-3.1-70B-Q5_K_S:latest  few_shot_CoT_prompt   \n",
       "\n",
       "                                               Input  \\\n",
       "0  {'post_id': '1179074562870386688_twitter', 'tw...   \n",
       "1  {'post_id': '1179074562870386688_twitter', 'tw...   \n",
       "2  {'post_id': '1179074562870386688_twitter', 'tw...   \n",
       "3  {'post_id': '16535198_gab', 'tweet_text': 'let...   \n",
       "4  {'post_id': '16535198_gab', 'tweet_text': 'let...   \n",
       "\n",
       "                                            Response  Time Taken (s)  \n",
       "0  The text you provided falls into the category ...           33.54  \n",
       "1  This statement is classified as hate speech be...           18.62  \n",
       "2  The text is labeled as hate speech due to the ...           14.42  \n",
       "3  The tweet you wrote has been classified as hat...           22.88  \n",
       "4  The text is classified as hate speech due to i...           16.94  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6efce0d8-1175-4f68-8abc-f7fc3670df0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prompt Name\n",
       "zero_shot_prompt       100\n",
       "few_shot_prompt        100\n",
       "few_shot_CoT_prompt    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Prompt Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64cf3306-2723-476b-8844-667270c6788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Create the three new columns based on 'Prompt Name'\n",
    "# df_pivoted = df.pivot(index='Row Number', columns='Prompt Name', values='Response')\n",
    "\n",
    "# # Join pivoted DataFrame back to original to preserve other columns\n",
    "# df = df.set_index('Row Number').join(df_pivoted).reset_index()\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2906298a-ee99-4d76-b23a-0ba7effa5211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# # Extract 'tweet_text' from 'Input' column and store it in 'tweet_text' column\n",
    "# df['tweet_text'] = df['Input'].apply(lambda x: re.search(r\"'tweet_text': '(.*?)', 'key_features':\", x).group(1))\n",
    "\n",
    "# print(df[['Row Number', 'tweet_text']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cea089d-195c-4ff0-8825-58f0033c5e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Check for missing values in each column\n",
    "missing_values = df.isna().sum()\n",
    "\n",
    "# Reshape dataframe to have separate columns for each 'Prompt Name'\n",
    "pivoted_df = df.pivot_table(index='Row Number', columns='Prompt Name', values='Response', aggfunc='first')\n",
    "\n",
    "# Rename columns to match the desired ones\n",
    "pivoted_df.columns = ['zero_shot_prompt', 'few_shot_prompt', 'few_shot_CoT_prompt']\n",
    "\n",
    "# If you want to merge this back into the original dataframe, use:\n",
    "df = df[['Row Number', 'Input']].drop_duplicates().set_index('Row Number').join(pivoted_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "204df670-4f39-4151-b2de-e6fbdeda7b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>zero_shot_prompt</th>\n",
       "      <th>few_shot_prompt</th>\n",
       "      <th>few_shot_CoT_prompt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Row Number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>{'post_id': '1179074562870386688_twitter', 'tw...</td>\n",
       "      <td>The text is labeled as hate speech due to the ...</td>\n",
       "      <td>This statement is classified as hate speech be...</td>\n",
       "      <td>The text you provided falls into the category ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>{'post_id': '16535198_gab', 'tweet_text': 'let...</td>\n",
       "      <td>The text is classified as hate speech due to i...</td>\n",
       "      <td>The tweet you wrote has been classified as hat...</td>\n",
       "      <td>The text provided falls into the category of h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>{'post_id': '1179039577777983488_twitter', 'tw...</td>\n",
       "      <td>The text is classified as normal because it do...</td>\n",
       "      <td>The given text has been labeled as \"normal\" be...</td>\n",
       "      <td>This tweet is categorized as normal because it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>{'post_id': '1178942851696283649_twitter', 'tw...</td>\n",
       "      <td>The text falls into the normal category for se...</td>\n",
       "      <td>Explanation: This tweet has been labeled as no...</td>\n",
       "      <td>This tweet falls into the normal category beca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>{'post_id': '23169645_gab', 'tweet_text': 'idi...</td>\n",
       "      <td>**Hate Speech**:\\n- The tweet employs extremel...</td>\n",
       "      <td>This statement is classified as hate speech be...</td>\n",
       "      <td>This tweet falls into the hate speech category...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>{'post_id': '1178728443783127040_twitter', 'tw...</td>\n",
       "      <td>The text is classified as hate speech due to t...</td>\n",
       "      <td>The tweet has been labeled as hate speech beca...</td>\n",
       "      <td>The tweet text \"fuck you raghead\" falls into t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>{'post_id': '1178852220424445952_twitter', 'tw...</td>\n",
       "      <td>**Hate Speech Analysis**:\\n\\n- The classificat...</td>\n",
       "      <td>The tweet has been labeled as hate speech beca...</td>\n",
       "      <td>This tweet falls into the category of hate spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>{'post_id': '13076830_gab', 'tweet_text': 'met...</td>\n",
       "      <td>The text is classified as hate speech due to i...</td>\n",
       "      <td>This tweet has been labeled as hate speech bec...</td>\n",
       "      <td>This tweet falls into the hate speech category...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>{'post_id': '3695492_gab', 'tweet_text': '&lt;use...</td>\n",
       "      <td>The text is classified as **Offensive** due to...</td>\n",
       "      <td>The tweet has been labeled as offensive becaus...</td>\n",
       "      <td>This tweet falls into the \"offensive\" category...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>{'post_id': '22913175_gab', 'tweet_text': 'and...</td>\n",
       "      <td>**Hate Speech**:\\n\\n- The tweet text uses high...</td>\n",
       "      <td>The tweet you posted has been classified as ha...</td>\n",
       "      <td>This tweet falls into the hate speech category...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Input  \\\n",
       "Row Number                                                      \n",
       "621         {'post_id': '1179074562870386688_twitter', 'tw...   \n",
       "622         {'post_id': '16535198_gab', 'tweet_text': 'let...   \n",
       "623         {'post_id': '1179039577777983488_twitter', 'tw...   \n",
       "624         {'post_id': '1178942851696283649_twitter', 'tw...   \n",
       "625         {'post_id': '23169645_gab', 'tweet_text': 'idi...   \n",
       "...                                                       ...   \n",
       "716         {'post_id': '1178728443783127040_twitter', 'tw...   \n",
       "717         {'post_id': '1178852220424445952_twitter', 'tw...   \n",
       "718         {'post_id': '13076830_gab', 'tweet_text': 'met...   \n",
       "719         {'post_id': '3695492_gab', 'tweet_text': '<use...   \n",
       "720         {'post_id': '22913175_gab', 'tweet_text': 'and...   \n",
       "\n",
       "                                             zero_shot_prompt  \\\n",
       "Row Number                                                      \n",
       "621         The text is labeled as hate speech due to the ...   \n",
       "622         The text is classified as hate speech due to i...   \n",
       "623         The text is classified as normal because it do...   \n",
       "624         The text falls into the normal category for se...   \n",
       "625         **Hate Speech**:\\n- The tweet employs extremel...   \n",
       "...                                                       ...   \n",
       "716         The text is classified as hate speech due to t...   \n",
       "717         **Hate Speech Analysis**:\\n\\n- The classificat...   \n",
       "718         The text is classified as hate speech due to i...   \n",
       "719         The text is classified as **Offensive** due to...   \n",
       "720         **Hate Speech**:\\n\\n- The tweet text uses high...   \n",
       "\n",
       "                                              few_shot_prompt  \\\n",
       "Row Number                                                      \n",
       "621         This statement is classified as hate speech be...   \n",
       "622         The tweet you wrote has been classified as hat...   \n",
       "623         The given text has been labeled as \"normal\" be...   \n",
       "624         Explanation: This tweet has been labeled as no...   \n",
       "625         This statement is classified as hate speech be...   \n",
       "...                                                       ...   \n",
       "716         The tweet has been labeled as hate speech beca...   \n",
       "717         The tweet has been labeled as hate speech beca...   \n",
       "718         This tweet has been labeled as hate speech bec...   \n",
       "719         The tweet has been labeled as offensive becaus...   \n",
       "720         The tweet you posted has been classified as ha...   \n",
       "\n",
       "                                          few_shot_CoT_prompt  \n",
       "Row Number                                                     \n",
       "621         The text you provided falls into the category ...  \n",
       "622         The text provided falls into the category of h...  \n",
       "623         This tweet is categorized as normal because it...  \n",
       "624         This tweet falls into the normal category beca...  \n",
       "625         This tweet falls into the hate speech category...  \n",
       "...                                                       ...  \n",
       "716         The tweet text \"fuck you raghead\" falls into t...  \n",
       "717         This tweet falls into the category of hate spe...  \n",
       "718         This tweet falls into the hate speech category...  \n",
       "719         This tweet falls into the \"offensive\" category...  \n",
       "720         This tweet falls into the hate speech category...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1da302bb-d890-4513-8386-b581235ce4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Define the pattern to extract tweet_text\n",
    "pattern = r\"'tweet_text': '(.*?)', 'key_features':\"\n",
    "\n",
    "# Extract tweet_text and save it in a new column\n",
    "df['tweet_text'] = df['Input'].apply(lambda x: re.search(pattern, x).group(1) if re.search(pattern, x) else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4de69131-6e41-40cf-8de8-6fa2e619f9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>zero_shot_prompt</th>\n",
       "      <th>few_shot_prompt</th>\n",
       "      <th>few_shot_CoT_prompt</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Row Number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>{'post_id': '1179074562870386688_twitter', 'tw...</td>\n",
       "      <td>The text is labeled as hate speech due to the ...</td>\n",
       "      <td>This statement is classified as hate speech be...</td>\n",
       "      <td>The text you provided falls into the category ...</td>\n",
       "      <td>this fat faggot id such a child grow up porky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>{'post_id': '16535198_gab', 'tweet_text': 'let...</td>\n",
       "      <td>The text is classified as hate speech due to i...</td>\n",
       "      <td>The tweet you wrote has been classified as hat...</td>\n",
       "      <td>The text provided falls into the category of h...</td>\n",
       "      <td>let masha and the bitches send that one to nig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>{'post_id': '1179039577777983488_twitter', 'tw...</td>\n",
       "      <td>The text is classified as normal because it do...</td>\n",
       "      <td>The given text has been labeled as \"normal\" be...</td>\n",
       "      <td>This tweet is categorized as normal because it...</td>\n",
       "      <td>in recent years we have frequently seen poor p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>{'post_id': '1178942851696283649_twitter', 'tw...</td>\n",
       "      <td>The text falls into the normal category for se...</td>\n",
       "      <td>Explanation: This tweet has been labeled as no...</td>\n",
       "      <td>This tweet falls into the normal category beca...</td>\n",
       "      <td>&lt;user&gt; &lt;user&gt; pointing out disproportionate ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>{'post_id': '23169645_gab', 'tweet_text': 'idi...</td>\n",
       "      <td>**Hate Speech**:\\n- The tweet employs extremel...</td>\n",
       "      <td>This statement is classified as hate speech be...</td>\n",
       "      <td>This tweet falls into the hate speech category...</td>\n",
       "      <td>idiot boy trudeau his somali moslem immigratio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>{'post_id': '1178728443783127040_twitter', 'tw...</td>\n",
       "      <td>The text is classified as hate speech due to t...</td>\n",
       "      <td>The tweet has been labeled as hate speech beca...</td>\n",
       "      <td>The tweet text \"fuck you raghead\" falls into t...</td>\n",
       "      <td>&lt;user&gt; fuck you raghead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>{'post_id': '1178852220424445952_twitter', 'tw...</td>\n",
       "      <td>**Hate Speech Analysis**:\\n\\n- The classificat...</td>\n",
       "      <td>The tweet has been labeled as hate speech beca...</td>\n",
       "      <td>This tweet falls into the category of hate spe...</td>\n",
       "      <td>&lt;user&gt; a rag makes her a rag head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>{'post_id': '13076830_gab', 'tweet_text': 'met...</td>\n",
       "      <td>The text is classified as hate speech due to i...</td>\n",
       "      <td>This tweet has been labeled as hate speech bec...</td>\n",
       "      <td>This tweet falls into the hate speech category...</td>\n",
       "      <td>met police terror attack in london quick lads ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>{'post_id': '3695492_gab', 'tweet_text': '&lt;use...</td>\n",
       "      <td>The text is classified as **Offensive** due to...</td>\n",
       "      <td>The tweet has been labeled as offensive becaus...</td>\n",
       "      <td>This tweet falls into the \"offensive\" category...</td>\n",
       "      <td>&lt;user&gt; good one ricky wait till those diesel d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>{'post_id': '22913175_gab', 'tweet_text': 'and...</td>\n",
       "      <td>**Hate Speech**:\\n\\n- The tweet text uses high...</td>\n",
       "      <td>The tweet you posted has been classified as ha...</td>\n",
       "      <td>This tweet falls into the hate speech category...</td>\n",
       "      <td>and just like you she is a welfare whore with ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Input  \\\n",
       "Row Number                                                      \n",
       "621         {'post_id': '1179074562870386688_twitter', 'tw...   \n",
       "622         {'post_id': '16535198_gab', 'tweet_text': 'let...   \n",
       "623         {'post_id': '1179039577777983488_twitter', 'tw...   \n",
       "624         {'post_id': '1178942851696283649_twitter', 'tw...   \n",
       "625         {'post_id': '23169645_gab', 'tweet_text': 'idi...   \n",
       "...                                                       ...   \n",
       "716         {'post_id': '1178728443783127040_twitter', 'tw...   \n",
       "717         {'post_id': '1178852220424445952_twitter', 'tw...   \n",
       "718         {'post_id': '13076830_gab', 'tweet_text': 'met...   \n",
       "719         {'post_id': '3695492_gab', 'tweet_text': '<use...   \n",
       "720         {'post_id': '22913175_gab', 'tweet_text': 'and...   \n",
       "\n",
       "                                             zero_shot_prompt  \\\n",
       "Row Number                                                      \n",
       "621         The text is labeled as hate speech due to the ...   \n",
       "622         The text is classified as hate speech due to i...   \n",
       "623         The text is classified as normal because it do...   \n",
       "624         The text falls into the normal category for se...   \n",
       "625         **Hate Speech**:\\n- The tweet employs extremel...   \n",
       "...                                                       ...   \n",
       "716         The text is classified as hate speech due to t...   \n",
       "717         **Hate Speech Analysis**:\\n\\n- The classificat...   \n",
       "718         The text is classified as hate speech due to i...   \n",
       "719         The text is classified as **Offensive** due to...   \n",
       "720         **Hate Speech**:\\n\\n- The tweet text uses high...   \n",
       "\n",
       "                                              few_shot_prompt  \\\n",
       "Row Number                                                      \n",
       "621         This statement is classified as hate speech be...   \n",
       "622         The tweet you wrote has been classified as hat...   \n",
       "623         The given text has been labeled as \"normal\" be...   \n",
       "624         Explanation: This tweet has been labeled as no...   \n",
       "625         This statement is classified as hate speech be...   \n",
       "...                                                       ...   \n",
       "716         The tweet has been labeled as hate speech beca...   \n",
       "717         The tweet has been labeled as hate speech beca...   \n",
       "718         This tweet has been labeled as hate speech bec...   \n",
       "719         The tweet has been labeled as offensive becaus...   \n",
       "720         The tweet you posted has been classified as ha...   \n",
       "\n",
       "                                          few_shot_CoT_prompt  \\\n",
       "Row Number                                                      \n",
       "621         The text you provided falls into the category ...   \n",
       "622         The text provided falls into the category of h...   \n",
       "623         This tweet is categorized as normal because it...   \n",
       "624         This tweet falls into the normal category beca...   \n",
       "625         This tweet falls into the hate speech category...   \n",
       "...                                                       ...   \n",
       "716         The tweet text \"fuck you raghead\" falls into t...   \n",
       "717         This tweet falls into the category of hate spe...   \n",
       "718         This tweet falls into the hate speech category...   \n",
       "719         This tweet falls into the \"offensive\" category...   \n",
       "720         This tweet falls into the hate speech category...   \n",
       "\n",
       "                                                   tweet_text  \n",
       "Row Number                                                     \n",
       "621             this fat faggot id such a child grow up porky  \n",
       "622         let masha and the bitches send that one to nig...  \n",
       "623         in recent years we have frequently seen poor p...  \n",
       "624         <user> <user> pointing out disproportionate ra...  \n",
       "625         idiot boy trudeau his somali moslem immigratio...  \n",
       "...                                                       ...  \n",
       "716                                   <user> fuck you raghead  \n",
       "717                         <user> a rag makes her a rag head  \n",
       "718         met police terror attack in london quick lads ...  \n",
       "719         <user> good one ricky wait till those diesel d...  \n",
       "720         and just like you she is a welfare whore with ...  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e52702bb-e768-44db-bacc-13df63bc72ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Input                  0\n",
       "zero_shot_prompt       0\n",
       "few_shot_prompt        0\n",
       "few_shot_CoT_prompt    0\n",
       "tweet_text             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93cb0c15-2330-4247-9616-1f27fe5014d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"LimeSurvey/LimeSurvey_data_pivoted_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d77f267-5474-42b5-aa26-507a4f3d051d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total length of responses for each row\n",
    "df['total_len'] = df['zero_shot_prompt'].apply(len) + df['few_shot_prompt'].apply(len) + df['few_shot_CoT_prompt'].apply(len)\n",
    "\n",
    "# Sort the DataFrame by the total length in descending order\n",
    "df_sorted = df.sort_values(by='total_len', ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb5c496f-073f-4e0b-9b56-f9570efd81f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted.to_csv(\"LimeSurvey/LimeSurvey_data_pivoted_sorted_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01ca2a6f-5ac0-47ef-acf6-9a27278dc6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>zero_shot_prompt</th>\n",
       "      <th>few_shot_prompt</th>\n",
       "      <th>few_shot_CoT_prompt</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>total_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Row Number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>{'post_id': '1142977246283599872_twitter', 'tw...</td>\n",
       "      <td>The tweet \"blue jeans white t shirt\" falls und...</td>\n",
       "      <td>Explanation: This tweet is categorized as norm...</td>\n",
       "      <td>The text \"blue jeans white t shirt\" falls into...</td>\n",
       "      <td>blue jeans white t shirt</td>\n",
       "      <td>1235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>{'post_id': '19369977_gab', 'tweet_text': 'he ...</td>\n",
       "      <td>**Normal**:\\n- tweet_text: \"he dindunuffin tho...</td>\n",
       "      <td>Explanation: This tweet has been labeled as no...</td>\n",
       "      <td>Based on the given text, it appears to be a no...</td>\n",
       "      <td>he dindunuffin tho &lt;laugh&gt;</td>\n",
       "      <td>1356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>{'post_id': '3695492_gab', 'tweet_text': '&lt;use...</td>\n",
       "      <td>The text is classified as **Offensive** due to...</td>\n",
       "      <td>The tweet has been labeled as offensive becaus...</td>\n",
       "      <td>This tweet falls into the \"offensive\" category...</td>\n",
       "      <td>&lt;user&gt; good one ricky wait till those diesel d...</td>\n",
       "      <td>1728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>{'post_id': '17315138_gab', 'tweet_text': 'get...</td>\n",
       "      <td>**Offensive**:\\n\\n- The tweet text, \"get the h...</td>\n",
       "      <td>This statement is labeled as offensive because...</td>\n",
       "      <td>The tweet \"get the honky cat\" falls into the c...</td>\n",
       "      <td>get the honky cat</td>\n",
       "      <td>1743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>{'post_id': '1178809032796180481_twitter', 'tw...</td>\n",
       "      <td>The provided tweet text, \"one can is enuff ðŸ˜‚\",...</td>\n",
       "      <td>Based on the given tweet text, it falls into t...</td>\n",
       "      <td>Based on the provided information, the tweet t...</td>\n",
       "      <td>&lt;user&gt; &lt;user&gt; one can is enuff ðŸ˜©</td>\n",
       "      <td>1805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>{'post_id': '1178849684447809536_twitter', 'tw...</td>\n",
       "      <td>The text appears to express frustration regard...</td>\n",
       "      <td>Explanation: The tweet has been labeled as nor...</td>\n",
       "      <td>The text appears to fall into the normal categ...</td>\n",
       "      <td>let a get this straight i can be called a raci...</td>\n",
       "      <td>3593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>{'post_id': '17261158_gab', 'tweet_text': 'eve...</td>\n",
       "      <td>The text is classified as \"Offensive\" due to i...</td>\n",
       "      <td>This statement is labeled as offensive because...</td>\n",
       "      <td>This tweet falls into the \"offensive\" category...</td>\n",
       "      <td>every time neocohens and neolibshits bomb a mo...</td>\n",
       "      <td>3674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>{'post_id': '23637308_gab', 'tweet_text': 'mon...</td>\n",
       "      <td>This text is classified as hate speech due to ...</td>\n",
       "      <td>This tweet is classified as hate speech becaus...</td>\n",
       "      <td>This tweet falls into the hate speech category...</td>\n",
       "      <td>monday kike nigga kike tuesday nigga kike nigg...</td>\n",
       "      <td>3903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>{'post_id': '15762396_gab', 'tweet_text': 'wel...</td>\n",
       "      <td>The text is classified as hate speech due to i...</td>\n",
       "      <td>This statement is classified as hate speech be...</td>\n",
       "      <td>This text falls into the hate speech category ...</td>\n",
       "      <td>welfare is a kike scam to enable niggers like ...</td>\n",
       "      <td>3953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>{'post_id': '23169645_gab', 'tweet_text': 'idi...</td>\n",
       "      <td>**Hate Speech**:\\n- The tweet employs extremel...</td>\n",
       "      <td>This statement is classified as hate speech be...</td>\n",
       "      <td>This tweet falls into the hate speech category...</td>\n",
       "      <td>idiot boy trudeau his somali moslem immigratio...</td>\n",
       "      <td>4355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Input  \\\n",
       "Row Number                                                      \n",
       "685         {'post_id': '1142977246283599872_twitter', 'tw...   \n",
       "710         {'post_id': '19369977_gab', 'tweet_text': 'he ...   \n",
       "719         {'post_id': '3695492_gab', 'tweet_text': '<use...   \n",
       "688         {'post_id': '17315138_gab', 'tweet_text': 'get...   \n",
       "691         {'post_id': '1178809032796180481_twitter', 'tw...   \n",
       "...                                                       ...   \n",
       "665         {'post_id': '1178849684447809536_twitter', 'tw...   \n",
       "641         {'post_id': '17261158_gab', 'tweet_text': 'eve...   \n",
       "673         {'post_id': '23637308_gab', 'tweet_text': 'mon...   \n",
       "653         {'post_id': '15762396_gab', 'tweet_text': 'wel...   \n",
       "625         {'post_id': '23169645_gab', 'tweet_text': 'idi...   \n",
       "\n",
       "                                             zero_shot_prompt  \\\n",
       "Row Number                                                      \n",
       "685         The tweet \"blue jeans white t shirt\" falls und...   \n",
       "710         **Normal**:\\n- tweet_text: \"he dindunuffin tho...   \n",
       "719         The text is classified as **Offensive** due to...   \n",
       "688         **Offensive**:\\n\\n- The tweet text, \"get the h...   \n",
       "691         The provided tweet text, \"one can is enuff ðŸ˜‚\",...   \n",
       "...                                                       ...   \n",
       "665         The text appears to express frustration regard...   \n",
       "641         The text is classified as \"Offensive\" due to i...   \n",
       "673         This text is classified as hate speech due to ...   \n",
       "653         The text is classified as hate speech due to i...   \n",
       "625         **Hate Speech**:\\n- The tweet employs extremel...   \n",
       "\n",
       "                                              few_shot_prompt  \\\n",
       "Row Number                                                      \n",
       "685         Explanation: This tweet is categorized as norm...   \n",
       "710         Explanation: This tweet has been labeled as no...   \n",
       "719         The tweet has been labeled as offensive becaus...   \n",
       "688         This statement is labeled as offensive because...   \n",
       "691         Based on the given tweet text, it falls into t...   \n",
       "...                                                       ...   \n",
       "665         Explanation: The tweet has been labeled as nor...   \n",
       "641         This statement is labeled as offensive because...   \n",
       "673         This tweet is classified as hate speech becaus...   \n",
       "653         This statement is classified as hate speech be...   \n",
       "625         This statement is classified as hate speech be...   \n",
       "\n",
       "                                          few_shot_CoT_prompt  \\\n",
       "Row Number                                                      \n",
       "685         The text \"blue jeans white t shirt\" falls into...   \n",
       "710         Based on the given text, it appears to be a no...   \n",
       "719         This tweet falls into the \"offensive\" category...   \n",
       "688         The tweet \"get the honky cat\" falls into the c...   \n",
       "691         Based on the provided information, the tweet t...   \n",
       "...                                                       ...   \n",
       "665         The text appears to fall into the normal categ...   \n",
       "641         This tweet falls into the \"offensive\" category...   \n",
       "673         This tweet falls into the hate speech category...   \n",
       "653         This text falls into the hate speech category ...   \n",
       "625         This tweet falls into the hate speech category...   \n",
       "\n",
       "                                                   tweet_text  total_len  \n",
       "Row Number                                                                \n",
       "685                                  blue jeans white t shirt       1235  \n",
       "710                                he dindunuffin tho <laugh>       1356  \n",
       "719         <user> good one ricky wait till those diesel d...       1728  \n",
       "688                                         get the honky cat       1743  \n",
       "691                          <user> <user> one can is enuff ðŸ˜©       1805  \n",
       "...                                                       ...        ...  \n",
       "665         let a get this straight i can be called a raci...       3593  \n",
       "641         every time neocohens and neolibshits bomb a mo...       3674  \n",
       "673         monday kike nigga kike tuesday nigga kike nigg...       3903  \n",
       "653         welfare is a kike scam to enable niggers like ...       3953  \n",
       "625         idiot boy trudeau his somali moslem immigratio...       4355  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "93c4ccac-b7ea-4f72-8062-3f1ea36f29c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create new columns for each 'Prompt Name' and store the corresponding 'Response'\n",
    "df_wide = df.pivot(index='Row Number', columns='Prompt Name', values='Response').reset_index()\n",
    "\n",
    "# # Step 2: Extract 'tweet_text' from the 'Input' column\n",
    "# import ast\n",
    "\n",
    "# def extract_tweet_text(input_str):\n",
    "#     try:\n",
    "#         input_dict = ast.literal_eval(input_str)\n",
    "#         print(input_dict)\n",
    "#         return input_dict.get('tweet_text', None)\n",
    "#     except (ValueError, SyntaxError):\n",
    "#         return None\n",
    "\n",
    "# df['tweet_text'] = df['Input']# .apply(extract_tweet_text)\n",
    "\n",
    "import re\n",
    "\n",
    "# Regular expression pattern to extract the 'tweet_text' value\n",
    "pattern = r\"'tweet_text': '(.*?)', 'key_features':\"\n",
    "\n",
    "# Function to extract tweet_text from the row\n",
    "def extract_tweet_text_from_row(row):\n",
    "    match = re.search(pattern, row)\n",
    "    if match:\n",
    "        return match.group(1)  # Return the extracted tweet_text\n",
    "    else:\n",
    "        print(f\"Error parsing row: {row}\")\n",
    "        return None\n",
    "\n",
    "# Assuming you are applying this function to a column in a dataframe\n",
    "df['tweet_text'] = df['Input'].apply(extract_tweet_text_from_row)\n",
    "\n",
    "# Merging the extracted tweet_text with the reshaped DataFrame\n",
    "df_final = pd.merge(df_wide, df[['Row Number', 'tweet_text']].drop_duplicates(), on='Row Number')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4a87a73d-c916-4733-a33b-e13688ea7112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row Number</th>\n",
       "      <th>few_shot_CoT_prompt</th>\n",
       "      <th>few_shot_prompt</th>\n",
       "      <th>zero_shot_prompt</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121</td>\n",
       "      <td>The text appears to be a harmless suggestion f...</td>\n",
       "      <td>The tweet has been labeled as normal because i...</td>\n",
       "      <td>Based on the available data, this tweet appear...</td>\n",
       "      <td>team name washington warhogs team colors red w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122</td>\n",
       "      <td>The classification of this text as \"normal\" is...</td>\n",
       "      <td>This tweet has been labeled as normal because ...</td>\n",
       "      <td>This tweet falls into the normal category beca...</td>\n",
       "      <td>the same niggas that be flexing jewelry be the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123</td>\n",
       "      <td>**Offensive**:\\n- tweet_text: \"tfw jews want t...</td>\n",
       "      <td>This statement is labeled offensive because it...</td>\n",
       "      <td>The text you provided falls into the \"offensiv...</td>\n",
       "      <td>tfw jews want to ban p*rn &lt;censored&gt; tfw now i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>124</td>\n",
       "      <td>**Hate Speech**\\n\\nThe tweet contains a highly...</td>\n",
       "      <td>This statement is classified as hate speech be...</td>\n",
       "      <td>The tweet text falls into the category of hate...</td>\n",
       "      <td>microchip has had more nigger cocks in him tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125</td>\n",
       "      <td>This tweet falls into the **Offensive** catego...</td>\n",
       "      <td>Explanation: The tweet has been labeled normal...</td>\n",
       "      <td>The text \"im wearing white pants and i look li...</td>\n",
       "      <td>im wearing white pants and i look like a faggot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>616</td>\n",
       "      <td>The text is classified as normal due to its ca...</td>\n",
       "      <td>The tweet has been labeled normal because the ...</td>\n",
       "      <td>Based on the given information, this tweet fal...</td>\n",
       "      <td>&lt;user&gt; &lt;user&gt; can not relate tho lmao i am not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>617</td>\n",
       "      <td>This tweet is classified as hate speech due to...</td>\n",
       "      <td>Explanation: This tweet has been labeled as no...</td>\n",
       "      <td>It appears that this tweet has been classified...</td>\n",
       "      <td>weed guys the most emotional niggas ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>618</td>\n",
       "      <td>The text is classified as normal due to its de...</td>\n",
       "      <td>The tweet has been labeled normal because it s...</td>\n",
       "      <td>This tweet falls into the \"Normal\" category be...</td>\n",
       "      <td>the elders of monroe are swarming the streets ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>619</td>\n",
       "      <td>Based on the given text:\\n\\n1. **Normal**: The...</td>\n",
       "      <td>Explanation: This tweet has been labeled as no...</td>\n",
       "      <td>Based on the available data, this tweet appear...</td>\n",
       "      <td>shout out to ol jews and ol rules</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>620</td>\n",
       "      <td>This text falls into the hate speech category ...</td>\n",
       "      <td>The text you provided has been categorized as ...</td>\n",
       "      <td>Based on the given tweet text, it appears to f...</td>\n",
       "      <td>cause it a grimy world and niggas bout shit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Row Number                                few_shot_CoT_prompt  \\\n",
       "0           121  The text appears to be a harmless suggestion f...   \n",
       "1           122  The classification of this text as \"normal\" is...   \n",
       "2           123  **Offensive**:\\n- tweet_text: \"tfw jews want t...   \n",
       "3           124  **Hate Speech**\\n\\nThe tweet contains a highly...   \n",
       "4           125  This tweet falls into the **Offensive** catego...   \n",
       "..          ...                                                ...   \n",
       "495         616  The text is classified as normal due to its ca...   \n",
       "496         617  This tweet is classified as hate speech due to...   \n",
       "497         618  The text is classified as normal due to its de...   \n",
       "498         619  Based on the given text:\\n\\n1. **Normal**: The...   \n",
       "499         620  This text falls into the hate speech category ...   \n",
       "\n",
       "                                       few_shot_prompt  \\\n",
       "0    The tweet has been labeled as normal because i...   \n",
       "1    This tweet has been labeled as normal because ...   \n",
       "2    This statement is labeled offensive because it...   \n",
       "3    This statement is classified as hate speech be...   \n",
       "4    Explanation: The tweet has been labeled normal...   \n",
       "..                                                 ...   \n",
       "495  The tweet has been labeled normal because the ...   \n",
       "496  Explanation: This tweet has been labeled as no...   \n",
       "497  The tweet has been labeled normal because it s...   \n",
       "498  Explanation: This tweet has been labeled as no...   \n",
       "499  The text you provided has been categorized as ...   \n",
       "\n",
       "                                      zero_shot_prompt  \\\n",
       "0    Based on the available data, this tweet appear...   \n",
       "1    This tweet falls into the normal category beca...   \n",
       "2    The text you provided falls into the \"offensiv...   \n",
       "3    The tweet text falls into the category of hate...   \n",
       "4    The text \"im wearing white pants and i look li...   \n",
       "..                                                 ...   \n",
       "495  Based on the given information, this tweet fal...   \n",
       "496  It appears that this tweet has been classified...   \n",
       "497  This tweet falls into the \"Normal\" category be...   \n",
       "498  Based on the available data, this tweet appear...   \n",
       "499  Based on the given tweet text, it appears to f...   \n",
       "\n",
       "                                            tweet_text  \n",
       "0    team name washington warhogs team colors red w...  \n",
       "1    the same niggas that be flexing jewelry be the...  \n",
       "2    tfw jews want to ban p*rn <censored> tfw now i...  \n",
       "3    microchip has had more nigger cocks in him tha...  \n",
       "4      im wearing white pants and i look like a faggot  \n",
       "..                                                 ...  \n",
       "495  <user> <user> can not relate tho lmao i am not...  \n",
       "496           weed guys the most emotional niggas ever  \n",
       "497  the elders of monroe are swarming the streets ...  \n",
       "498                  shout out to ol jews and ol rules  \n",
       "499        cause it a grimy world and niggas bout shit  \n",
       "\n",
       "[500 rows x 5 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59fff8a-79e1-42fc-8802-f2abedf702fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['tweet_text'] = df_final['tweet_text'].apply(extract_tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56456ee3-ab51-40a0-98d7-2d8db2b73632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dbc454c8-28c2-4a48-8eab-f13319da505b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with missing tweet_text: Empty DataFrame\n",
      "Columns: [Row Number, Model, Prompt Name, Input, Response, Time Taken (s), tweet_text]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Regular expression pattern to extract the 'tweet_text' value\n",
    "pattern = r\"'tweet_text': '(.*?)', 'key_features':\"\n",
    "\n",
    "# Function to extract tweet_text from the row\n",
    "def extract_tweet_text_from_row(row):\n",
    "    match = re.search(pattern, row)\n",
    "    if match:\n",
    "        return match.group(1)  # Return the extracted tweet_text\n",
    "    else:\n",
    "        print(f\"Error parsing row: {row}\")\n",
    "        return None\n",
    "\n",
    "# Assuming you are applying this function to a column in a dataframe\n",
    "df['tweet_text'] = df['Input'].apply(extract_tweet_text_from_row)\n",
    "\n",
    "# Check rows where 'tweet_text' is still missing\n",
    "missing_tweet_text_rows = df[df['tweet_text'].isnull()]\n",
    "print(f\"Rows with missing tweet_text: {missing_tweet_text_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "26b02127-ed8d-4b86-b2aa-2c3da0d0f7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row Number</th>\n",
       "      <th>Model</th>\n",
       "      <th>Prompt Name</th>\n",
       "      <th>Input</th>\n",
       "      <th>Response</th>\n",
       "      <th>Time Taken (s)</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121</td>\n",
       "      <td>Hermes-3-Llama-3.1-70B-Q5_K_S:latest</td>\n",
       "      <td>zero_shot_prompt</td>\n",
       "      <td>{'post_id': '1181224026519359490_twitter', 'tw...</td>\n",
       "      <td>Based on the available data, this tweet appear...</td>\n",
       "      <td>21.82</td>\n",
       "      <td>team name washington warhogs team colors red w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121</td>\n",
       "      <td>Hermes-3-Llama-3.1-70B-Q5_K_S:latest</td>\n",
       "      <td>few_shot_prompt</td>\n",
       "      <td>{'post_id': '1181224026519359490_twitter', 'tw...</td>\n",
       "      <td>The tweet has been labeled as normal because i...</td>\n",
       "      <td>14.56</td>\n",
       "      <td>team name washington warhogs team colors red w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121</td>\n",
       "      <td>Hermes-3-Llama-3.1-70B-Q5_K_S:latest</td>\n",
       "      <td>few_shot_CoT_prompt</td>\n",
       "      <td>{'post_id': '1181224026519359490_twitter', 'tw...</td>\n",
       "      <td>The text appears to be a harmless suggestion f...</td>\n",
       "      <td>20.67</td>\n",
       "      <td>team name washington warhogs team colors red w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>122</td>\n",
       "      <td>Hermes-3-Llama-3.1-70B-Q5_K_S:latest</td>\n",
       "      <td>zero_shot_prompt</td>\n",
       "      <td>{'post_id': '1083159533848023041_twitter', 'tw...</td>\n",
       "      <td>This tweet falls into the normal category beca...</td>\n",
       "      <td>15.31</td>\n",
       "      <td>the same niggas that be flexing jewelry be the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>122</td>\n",
       "      <td>Hermes-3-Llama-3.1-70B-Q5_K_S:latest</td>\n",
       "      <td>few_shot_CoT_prompt</td>\n",
       "      <td>{'post_id': '1083159533848023041_twitter', 'tw...</td>\n",
       "      <td>The classification of this text as \"normal\" is...</td>\n",
       "      <td>25.57</td>\n",
       "      <td>the same niggas that be flexing jewelry be the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>619</td>\n",
       "      <td>Hermes-3-Llama-3.1-70B-Q5_K_S:latest</td>\n",
       "      <td>zero_shot_prompt</td>\n",
       "      <td>{'post_id': '1103453694735966213_twitter', 'tw...</td>\n",
       "      <td>Based on the available data, this tweet appear...</td>\n",
       "      <td>16.94</td>\n",
       "      <td>shout out to ol jews and ol rules</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>619</td>\n",
       "      <td>Hermes-3-Llama-3.1-70B-Q5_K_S:latest</td>\n",
       "      <td>few_shot_CoT_prompt</td>\n",
       "      <td>{'post_id': '1103453694735966213_twitter', 'tw...</td>\n",
       "      <td>Based on the given text:\\n\\n1. **Normal**: The...</td>\n",
       "      <td>14.73</td>\n",
       "      <td>shout out to ol jews and ol rules</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>620</td>\n",
       "      <td>Hermes-3-Llama-3.1-70B-Q5_K_S:latest</td>\n",
       "      <td>few_shot_prompt</td>\n",
       "      <td>{'post_id': '1109322805299027968_twitter', 'tw...</td>\n",
       "      <td>The text you provided has been categorized as ...</td>\n",
       "      <td>18.35</td>\n",
       "      <td>cause it a grimy world and niggas bout shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>620</td>\n",
       "      <td>Hermes-3-Llama-3.1-70B-Q5_K_S:latest</td>\n",
       "      <td>zero_shot_prompt</td>\n",
       "      <td>{'post_id': '1109322805299027968_twitter', 'tw...</td>\n",
       "      <td>Based on the given tweet text, it appears to f...</td>\n",
       "      <td>24.40</td>\n",
       "      <td>cause it a grimy world and niggas bout shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>620</td>\n",
       "      <td>Hermes-3-Llama-3.1-70B-Q5_K_S:latest</td>\n",
       "      <td>few_shot_CoT_prompt</td>\n",
       "      <td>{'post_id': '1109322805299027968_twitter', 'tw...</td>\n",
       "      <td>This text falls into the hate speech category ...</td>\n",
       "      <td>17.56</td>\n",
       "      <td>cause it a grimy world and niggas bout shit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Row Number                                 Model          Prompt Name  \\\n",
       "0            121  Hermes-3-Llama-3.1-70B-Q5_K_S:latest     zero_shot_prompt   \n",
       "1            121  Hermes-3-Llama-3.1-70B-Q5_K_S:latest      few_shot_prompt   \n",
       "2            121  Hermes-3-Llama-3.1-70B-Q5_K_S:latest  few_shot_CoT_prompt   \n",
       "3            122  Hermes-3-Llama-3.1-70B-Q5_K_S:latest     zero_shot_prompt   \n",
       "4            122  Hermes-3-Llama-3.1-70B-Q5_K_S:latest  few_shot_CoT_prompt   \n",
       "...          ...                                   ...                  ...   \n",
       "1495         619  Hermes-3-Llama-3.1-70B-Q5_K_S:latest     zero_shot_prompt   \n",
       "1496         619  Hermes-3-Llama-3.1-70B-Q5_K_S:latest  few_shot_CoT_prompt   \n",
       "1497         620  Hermes-3-Llama-3.1-70B-Q5_K_S:latest      few_shot_prompt   \n",
       "1498         620  Hermes-3-Llama-3.1-70B-Q5_K_S:latest     zero_shot_prompt   \n",
       "1499         620  Hermes-3-Llama-3.1-70B-Q5_K_S:latest  few_shot_CoT_prompt   \n",
       "\n",
       "                                                  Input  \\\n",
       "0     {'post_id': '1181224026519359490_twitter', 'tw...   \n",
       "1     {'post_id': '1181224026519359490_twitter', 'tw...   \n",
       "2     {'post_id': '1181224026519359490_twitter', 'tw...   \n",
       "3     {'post_id': '1083159533848023041_twitter', 'tw...   \n",
       "4     {'post_id': '1083159533848023041_twitter', 'tw...   \n",
       "...                                                 ...   \n",
       "1495  {'post_id': '1103453694735966213_twitter', 'tw...   \n",
       "1496  {'post_id': '1103453694735966213_twitter', 'tw...   \n",
       "1497  {'post_id': '1109322805299027968_twitter', 'tw...   \n",
       "1498  {'post_id': '1109322805299027968_twitter', 'tw...   \n",
       "1499  {'post_id': '1109322805299027968_twitter', 'tw...   \n",
       "\n",
       "                                               Response  Time Taken (s)  \\\n",
       "0     Based on the available data, this tweet appear...           21.82   \n",
       "1     The tweet has been labeled as normal because i...           14.56   \n",
       "2     The text appears to be a harmless suggestion f...           20.67   \n",
       "3     This tweet falls into the normal category beca...           15.31   \n",
       "4     The classification of this text as \"normal\" is...           25.57   \n",
       "...                                                 ...             ...   \n",
       "1495  Based on the available data, this tweet appear...           16.94   \n",
       "1496  Based on the given text:\\n\\n1. **Normal**: The...           14.73   \n",
       "1497  The text you provided has been categorized as ...           18.35   \n",
       "1498  Based on the given tweet text, it appears to f...           24.40   \n",
       "1499  This text falls into the hate speech category ...           17.56   \n",
       "\n",
       "                                             tweet_text  \n",
       "0     team name washington warhogs team colors red w...  \n",
       "1     team name washington warhogs team colors red w...  \n",
       "2     team name washington warhogs team colors red w...  \n",
       "3     the same niggas that be flexing jewelry be the...  \n",
       "4     the same niggas that be flexing jewelry be the...  \n",
       "...                                                 ...  \n",
       "1495                  shout out to ol jews and ol rules  \n",
       "1496                  shout out to ol jews and ol rules  \n",
       "1497        cause it a grimy world and niggas bout shit  \n",
       "1498        cause it a grimy world and niggas bout shit  \n",
       "1499        cause it a grimy world and niggas bout shit  \n",
       "\n",
       "[1500 rows x 7 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c3b64aac-7066-461a-93ce-17bc5a88cc5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'key_features_str' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Apply the function to extract 'tweet_text'\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mInput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextract_tweet_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Step 3: Merge the reshaped DataFrame with the extracted 'tweet_text'\u001b[39;00m\n\u001b[0;32m     36\u001b[0m df_final \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(\n\u001b[0;32m     37\u001b[0m     df_wide,\n\u001b[0;32m     38\u001b[0m     df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRow Number\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_text\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdrop_duplicates(),\n\u001b[0;32m     39\u001b[0m     on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRow Number\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     40\u001b[0m     how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Ensure no rows are dropped\u001b[39;00m\n\u001b[0;32m     41\u001b[0m )\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[46], line 14\u001b[0m, in \u001b[0;36mextract_tweet_text\u001b[1;34m(input_str)\u001b[0m\n\u001b[0;32m     12\u001b[0m input_str \u001b[38;5;241m=\u001b[39m input_str\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Normalize single quotes to double quotes\u001b[39;00m\n\u001b[0;32m     13\u001b[0m input_str \u001b[38;5;241m=\u001b[39m input_str\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Ensure proper list formatting\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m key_features_str \u001b[38;5;241m=\u001b[39m \u001b[43mkey_features_str\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Safely parse the string into a Python dictionary\u001b[39;00m\n\u001b[0;32m     17\u001b[0m input_dict \u001b[38;5;241m=\u001b[39m ast\u001b[38;5;241m.\u001b[39mliteral_eval(input_str)\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'key_features_str' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import json\n",
    "\n",
    "# Step 1: Pivot the DataFrame to create separate columns for each 'Prompt Name'\n",
    "df_wide = df.pivot(index='Row Number', columns='Prompt Name', values='Response').reset_index()\n",
    "\n",
    "# Step 2: Extract 'tweet_text' from the 'Input' column\n",
    "def extract_tweet_text(input_str):\n",
    "    try:\n",
    "        # Fix any list-like string formatting in 'key_features'\n",
    "        input_str = input_str.replace(\"'\", '\"')  # Normalize single quotes to double quotes\n",
    "        input_str = input_str.replace('[', '[').replace(']', ']')  # Ensure proper list formatting\n",
    "        key_features_str = key_features_str.replace(\"'\", '\"')\n",
    "\n",
    "        # Safely parse the string into a Python dictionary\n",
    "        input_dict = ast.literal_eval(input_str)\n",
    "\n",
    "        return input_dict.get('tweet_text', None)\n",
    "    except (ValueError, SyntaxError, json.JSONDecodeError):\n",
    "        # Fallback: Try parsing with json.loads\n",
    "        try:\n",
    "            input_dict = json.loads(input_str)\n",
    "            return input_dict.get('tweet_text', None)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error parsing row: {input_str}\")\n",
    "            return None\n",
    "\n",
    "# Ensure consistent quotes before parsing\n",
    "df['Input'] = df['Input'].str.replace('\"', \"'\", regex=False)\n",
    "\n",
    "# Apply the function to extract 'tweet_text'\n",
    "df['tweet_text'] = df['Input'].apply(extract_tweet_text)\n",
    "\n",
    "# Step 3: Merge the reshaped DataFrame with the extracted 'tweet_text'\n",
    "df_final = pd.merge(\n",
    "    df_wide,\n",
    "    df[['Row Number', 'tweet_text']].drop_duplicates(),\n",
    "    on='Row Number',\n",
    "    how='left'  # Ensure no rows are dropped\n",
    ")\n",
    "\n",
    "# Debug any rows where 'tweet_text' is missing\n",
    "missing_tweet_text_rows = df_final[df_final['tweet_text'].isnull()]\n",
    "print(\"Rows with missing 'tweet_text':\", missing_tweet_text_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "243fb346-0d60-49da-8ba7-b514356ed28a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'key_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'key_features'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Assuming your dataframe is called `df`\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey_features\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkey_features\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(parse_key_features)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Step 3: Apply the function to extract 'tweet_text' from the 'Input' column\u001b[39;00m\n\u001b[0;32m     29\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(extract_tweet_text)\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'key_features'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Step 1: Normalize and safely parse the 'key_features' column\n",
    "def parse_key_features(key_features_str):\n",
    "    try:\n",
    "        # Fix any list-like string formatting, convert it to proper list\n",
    "        key_features_str = key_features_str.replace(\"'\", '\"')  # Normalize quotes\n",
    "        key_features_list = ast.literal_eval(key_features_str)  # Safely parse as a list\n",
    "        return key_features_list\n",
    "    except (ValueError, SyntaxError, TypeError):\n",
    "        print(f\"Error parsing key_features: {key_features_str}\")\n",
    "        return []\n",
    "\n",
    "# Step 2: Parse the input column correctly\n",
    "def extract_tweet_text(input_str):\n",
    "    try:\n",
    "        # Replace single quotes with double quotes and parse the input string\n",
    "        input_dict = ast.literal_eval(input_str.replace(\"'\", '\"'))\n",
    "        return input_dict.get('tweet_text', None)\n",
    "    except (ValueError, SyntaxError, TypeError):\n",
    "        print(f\"Error parsing row: {input_str}\")\n",
    "        return None\n",
    "\n",
    "# Assuming your dataframe is called `df`\n",
    "df['key_features'] = df['key_features'].apply(parse_key_features)\n",
    "\n",
    "# Step 3: Apply the function to extract 'tweet_text' from the 'Input' column\n",
    "df['tweet_text'] = df['Input'].apply(extract_tweet_text)\n",
    "\n",
    "# Check any rows where 'tweet_text' is still missing\n",
    "missing_tweet_text_rows = df[df['tweet_text'].isnull()]\n",
    "print(f\"Rows with missing tweet_text: {missing_tweet_text_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95a68a9-c3ec-4e97-9b0b-2bcc2b71fb55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
