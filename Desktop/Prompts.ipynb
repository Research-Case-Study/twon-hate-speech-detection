{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccecc1ba-e2f8-4a97-9396-817aebeb6500",
   "metadata": {},
   "source": [
    "# Zero shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5db3e188-0d2b-461c-a0c0-87ce9a1ee992",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "you are AI agent which is specialized in analyzing a text for 3 different classes which is hate speech, offensive and normal, and then provide and educated\n",
    "explanation for why the text falls into any of these categories.\n",
    "In order for you to do that, you have the following key feautures available to you which helps you in your analysis and creating the explanation for it\n",
    "\n",
    "available data: \n",
    "\n",
    "{'post_id': ## post id . ignore it\n",
    " 'tweet_text': #its the main user text that you need to write explaination on.\n",
    " 'key_features': [] # list of the words that made a decision, important feature\n",
    " 'target': # targetted audience. \n",
    " 'label': # either offensive, hate speech or normal.   \n",
    " }\n",
    "Based on the the label present in the available data, write your explanation for each tweet text.\n",
    " \n",
    "# Notes:\n",
    "1) the explnatation should be consice. \n",
    "2) your explanations should be analytical and starightforward. \n",
    "3) while generating the explanations you should also consider the possible context for the text which the user might have in mind when writing the tweet\n",
    "4) The purpose of these explanations is to educate the user as to why certain text written by them falls into certain category and can harm a \n",
    "certain group of people.\n",
    "Now you will be given user input and you have to write explainations.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778d4a5c-38b1-4774-942f-6cd2882eca07",
   "metadata": {},
   "source": [
    "# Zero Shot for Label- Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "722f654f-e997-4398-a216-356be4174514",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "you are AI agent which is specialized in analyzing a text for 3 different classes which is hate speech, offensive and normal.\n",
    "\n",
    "available data: \n",
    "\n",
    "{'post_id': ## post id . ignore it\n",
    " 'tweet_text': #its the main user text that you need to write explaination on.\n",
    " 'key_features': [] # list of the words that made a decision, important feature\n",
    " 'target': # targetted audience. \n",
    " 'label': # either offensive, hate speech or normal.   \n",
    " }\n",
    "Your output should contain:\n",
    "- the existing label.\n",
    "- Your own decision for the label based on the tweet text.\n",
    " \n",
    "# Notes:\n",
    "1) the output should NOT ontain justification of the deciion. Only the existing label and your own predicted label.\n",
    "2) the outpout should be in the form of a dictionary. \n",
    "3) while predicting the label you should also consider the possible context for the text which the user might have in mind when writing the tweet\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c30dbb-f17d-4474-87ef-10c6e35856a2",
   "metadata": {},
   "source": [
    "# Few shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dc137b-daea-449f-8ec0-4bbd73767204",
   "metadata": {},
   "outputs": [],
   "source": [
    "you are AI agent which is specialized in analyzing a text for 3 different classes which is hate speech, offensive and normal,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01cc2d91-ff42-4f50-ac58-d317b63870eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "you are AI agent which is specialized in analyzing a text for 3 different classes which is hate speech, offensive and normal, and then provide and educated\n",
    "explanation for why the text falls into any of these categories. \n",
    "In order for you to do that, you have the following key feautures available to you which helps you in your analysis and creating the explanation for it\n",
    "\n",
    "key_features: \n",
    "\n",
    "{'post_id': ## post id . ignore it\n",
    " 'tweet_text': #its the main user text that you need to write explaination on.\n",
    " 'key_features': [] # list of the words that made a decision, important feature\n",
    " 'target': # targetted audience. \n",
    " 'label': # either offensive, hate speech or normal.   \n",
    " }\n",
    "below are some of the example tweet_text and their explanations for each categories, refer those and learn from them to generate your explanations :\n",
    "\n",
    "Label -> Normal\n",
    "\n",
    "1. \"i know this is somewhat hypocritical but what the fuck is the deal with queer guys and slightly too small white tshirts\"\n",
    "Explanation: The tweet has been labeled normal because the user is solely expressing an observation. However the use of vulgar terms such as “fuck” may indicate that the user has a rather negative outlook towards topics concerning queers. Given that the context is not clear it may be understood as a neutral observation. The targets used within the dataset do not contain the word “queer” but the word homosexual. \n",
    "\n",
    "\n",
    "2. “wore a nipsey blue suit today only the niggers in the work place feel the energy”\n",
    "Explanation:This tweet has been labeled normal because it seems to be a positive reference of paying tribute to the rapper nipsey hussle who is known for a specific shade of blue that is affiliated to the crib gang culture of LA.\n",
    "The use of the term \"niggers\" is offensive and rooted in racism. Even if no direct harm or attack is evident, it perpetuates a derogatory term, which many systems and definitions include as hate speech. However, disagreement in labeling often arises due to contextual interpretations. Example for that could be Cultural or Social Context that goes Intended Meaning. In the tweet addition The phrase might be interpreted as describing a situation where the \"energy\" of the outfit is appreciated by a certain group, which could be seen as neutral, despite the offensive language.\n",
    "\n",
    "\n",
    "3. rafiullah shaheed a young man from levi force was shot dead by unknown men in muslim bagh a levies officer was killed in a bomb blast in lashkar gah on sunday while militants were also killed on the same day three people including mullahaniyev were killed in chaman\"\n",
    "Explanation: The statement is a factual report of events without any explicit derogatory, hateful, or harmful language targeting a specific individual or group based on characteristics like race, religion, or ethnicity. It lacks the intention to incite hate or violence, which is key to labeling content as hate speech.\n",
    "\n",
    "Label -> Offensive\n",
    " \n",
    "1) “pocahontas jumps in bed with moslem terrorists interesting combo”\n",
    "Explanation:This statement is labeled offensive because it uses derogatory language and stereotypes to insult and demean individuals or groups. Referring to someone as \"Pocahontas\" in a pejorative context is disrespectful, and associating them with \"Muslim terrorists\" perpetuates harmful stereotypes and biases, making the comment offensive and inappropriate.\n",
    "\n",
    "2) iIslamophobic you for real and how is islam a race you half wit\n",
    "Explanation: It is labled offensive beacuse it contains an insult.\n",
    "\n",
    "3) treat the immigrants as drug traffickers they will soon have a change of mind\n",
    "Explanation: This statement is offensive because it unjustly stereotypes immigrants as drug traffickers, promoting a harmful generalization that dehumanizes and criminalizes an entire group of people. Such language fosters prejudice, discrimination, and hostility toward immigrants. Furthermore it incitement to\n",
    "\n",
    " \n",
    "Label -> Hate Speech\n",
    "\n",
    "1)you niggas is fake asl that why you dont see none round me\n",
    "Explanation:This statement is classified as hate speech because it uses a racial slur (\"niggas\"), which is historically and culturally offensive, particularly against Black individuals. Even when used in some contexts as reclaimed language, its use in this statement appears derogatory, contributing to a hostile and discriminatory tone. The inclusion of aggressive language further amplifies its hateful nature.\n",
    "\n",
    "\n",
    "2) \"online nazi haha guys the left can not meme <number> white privilege diversity is our strength race is just skin color the holocaust racist sexist bigot homophobe islamophobe anti semite\"\n",
    "Explanation: This statement is hate speech because it mocks and trivializes serious societal issues, such as racism, sexism, and discrimination, using a sarcastic tone to dismiss terms like \"white privilege,\" \"diversity is our strength,\" and \"anti-Semite.\" By doing so, it undermines the significance of these issues and belittles those advocating for equality. References to \"Nazi\" and \"the Holocaust\" in a dismissive context further minimize historical atrocities and signal alignment with extremist ideologies. Overall, the statement ridicules efforts to address inequality and promotes hostility, making it hate speech.\n",
    "\n",
    "3) \"pro tip the niggers do not care if you never owned slaves granddaddy fought the natzis or great great grandad ground the confederacy into dust with the boot heel of the proto bolshevik yankee gubment force of weight and arms behind it they hate you because you are white and you exist altright\"\n",
    "Explanation:This statement is classified as hate speech because it uses the racial slur (\"niggers\"). The statement further vilifies an entire group by making sweeping generalizations, such as claiming that Black people \"hate you because you are white and you exist.\" This kind of language fosters an \"us vs. them\" narrative, portraying Black people as inherently hostile toward white people, which promotes racial division and resentment. The inclusion of terms like \"proto Bolshevik Yankee gubment force\" and \"altright\" reflects alignment with extremist ideologies often associated with white nationalism and discriminatory rhetoric. Additionally, references to historical events such as \"granddaddy fought the Nazis\" and \"great great grandad ground the Confederacy\" are weaponized to evoke a sense of pride in white heritage while simultaneously vilifying Black individuals. \n",
    "\n",
    "# Notes:\n",
    "1) the explnatation should be consice. \n",
    "2) your explanations should be analytical and starightforward. \n",
    "3) while generating the explanations you should also consider the possible context for the text which the user might have in mind when writing the tweet\n",
    "4) The purpose of these explanations is to educate the user as to why certain text written by them falls into certain category and can harm a \n",
    "certain group of people.\n",
    "Now you will be given user input and you have to write explainations.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e88fc5-790e-4d14-99c2-b80d905dfca5",
   "metadata": {},
   "source": [
    "# Few Shot + Chain of Thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04830158-b8c8-435a-a5cf-bf744411cb72",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '“' (U+201C) (2381031.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[27], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    Hate speech is “discriminatory” (biased, bigoted, or intolerant) or “pejorative” (prejudiced, contemptuous, or demeaning) of an individual or group.\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '“' (U+201C)\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "\n",
    "you are AI agent which is specialized in analyzing a text for 3 different classes which is hate speech, offensive and normal, and then provide and educated\n",
    "explanation for why the text falls into any of these categories.\n",
    "\n",
    "\n",
    "available data:\n",
    "- tweet_text: The main user text requiring explanation.\n",
    "- key_features: Words or phrases crucial to the decision.\n",
    "- target: The audience or group targeted by the text.\n",
    "- label: The classification of the text (hate speech, offensive, or neutral).\n",
    "\n",
    "Your job is to:\n",
    "1. Start by identifying the label of the text and summarizing what it indicates about the content.\n",
    "2. Analyze the key features and explain how they support the classification.\n",
    "3. Consider the target and evaluate how the text affects or refers to this group.\n",
    "4. Examine the overall context and tone to understand the user's intent.\n",
    "5. Conclude with a detailed explanation, justifying the classification and the reasoning behind it.\n",
    "\n",
    "Guidelines:\n",
    "- Ensure the explanation is concise.\n",
    "- Highlight what helped in making the decision and why the text is classified as it is.\n",
    "- your explanations should be analytical and starightforward\n",
    "- If the label is neutral, but you believe the text could be hate speech or offensive, explain why it is still considered neutral.\n",
    "- If the label is offensive, describe the nature of the offense and how the key features contribute to it.\n",
    "\n",
    "Here are examples for guidance:\n",
    "\n",
    "1. **Hate Speech**:\n",
    "   tweet_text: \"A negro moslem doctor got struck off for negligence when a white <number> year old kid with down syndrome died; the guardian's response is to help promote a crowdfunding campaign for her.\"\n",
    "   - key_features: [\"negro\", \"moslem\", \"white <number> year old kid\", \"down syndrome\"]\n",
    "   - target: Ethnic groups (Black and White), religious group (Muslim), and individuals with disabilities (Down syndrome)\n",
    "   - label: Hate Speech\n",
    "   Reasoning:\n",
    "   Step 1: The label is Hate Speech, indicating that the content may upset or insult individuals based on ethnicity, religion, or disability.\n",
    "   Step 2: Key features include derogatory terms based on race (\"negro\"), religion (\"moslem\"), and descriptors that unnecessarily highlight race and disability in a sensitive context.\n",
    "   Step 3: The target includes multiple vulnerable groups, which compounds the potential for offense.\n",
    "   Step 4: The context suggests an underlying bias in how different ethnic and religious groups are treated and discussed in relation to a tragic incident.\n",
    "   Conclusion: This text is categorized as Hate Speech due to its derogatory language and the sensitive context in which these terms are employed, targeting specific ethnic, religious, and disabled groups.\n",
    "\n",
    "2. **Offensive**:\n",
    "   - tweet_text: \"Why are men so bad at taking care of kids?\"\n",
    "   - key_features: [\"men\", \"bad at taking care\"]\n",
    "   - target: Men\n",
    "   - label: Offensive\n",
    "   Reasoning:\n",
    "   Step 1: The label is offensive, which suggests the text contains harmful stereotypes or derogatory assumptions.  \n",
    "   Step 2: Key features like \"bad at taking care\" perpetuate a stereotype that questions men’s abilities in caregiving.  \n",
    "   Step 3: The target is men, a group generalized and negatively characterized in this statement.  \n",
    "   Step 4: While the tone is not explicitly harmful, the language dismisses and demeans the target group.  \n",
    "   Conclusion: This text is offensive because it perpetuates a harmful stereotype about men, although it does not incite direct harm.\n",
    "\n",
    "3. **Neutral**:\n",
    "   - tweet_text: \"What’s everyone’s favorite food?\"\n",
    "   - key_features: None\n",
    "   - target: None\n",
    "   - label: Neutral\n",
    "   Reasoning:\n",
    "   Step 1: The label is neutral, meaning the text does not contain offensive or harmful language.  \n",
    "   Step 2: There are no key features or elements that suggest hostility, harm, or stereotypes.  \n",
    "   Step 3: The content is inclusive and general, without targeting any group or individual.  \n",
    "   Step 4: The context and tone are friendly and open-ended, with no intent to harm or offend.  \n",
    "   Conclusion: This text is neutral because it is non-controversial, lacks harmful language, and does not target any individual or group.\n",
    "\n",
    "Now, write an explanation for the given input using this reasoning framework.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d50f52d-bd7d-43de-abd3-161ca35d03be",
   "metadata": {},
   "source": [
    "# Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c64ea9a1-257f-4ac8-a51c-d95f2724cf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams, Batch\n",
    "from collections import Counter\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9fa2d6-3a17-4818-af15-58af2de3b457",
   "metadata": {},
   "source": [
    "## Load and Transform Dataset + convert to DF | Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c923dcb-7f15-4d68-ba43-e4478ac90161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset.json file\n",
    "file_path = 'dataset.json'\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b50ddcb3-7d9e-4e21-a22a-735d9722a96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>key_features</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "      <th>annotator_1_label</th>\n",
       "      <th>annotator_1_target</th>\n",
       "      <th>annotator_2_label</th>\n",
       "      <th>annotator_2_target</th>\n",
       "      <th>annotator_3_label</th>\n",
       "      <th>annotator_3_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20143</th>\n",
       "      <td>9989999_gab</td>\n",
       "      <td>if ur still on twitter tell carlton i said his...</td>\n",
       "      <td>[alcoholic, drug, addicted, teenage, single, m...</td>\n",
       "      <td>Men, None, Other, Women</td>\n",
       "      <td>offensive</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Men, Women, Other</td>\n",
       "      <td>offensive</td>\n",
       "      <td>None</td>\n",
       "      <td>normal</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20144</th>\n",
       "      <td>9990225_gab</td>\n",
       "      <td>when i first got on here and said i hate trump...</td>\n",
       "      <td>[i, hate, trump, i, was, hating, niggers]</td>\n",
       "      <td>African, None, Other</td>\n",
       "      <td>offensive</td>\n",
       "      <td>offensive</td>\n",
       "      <td>African</td>\n",
       "      <td>offensive</td>\n",
       "      <td>African, Other</td>\n",
       "      <td>normal</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20145</th>\n",
       "      <td>9991681_gab</td>\n",
       "      <td>was macht der moslem wenn der zion gegen seine...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Islam, None, Other</td>\n",
       "      <td>normal</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Islam</td>\n",
       "      <td>normal</td>\n",
       "      <td>Other</td>\n",
       "      <td>normal</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20146</th>\n",
       "      <td>9992513_gab</td>\n",
       "      <td>it is awful look at world demographics asians ...</td>\n",
       "      <td>[asians, are, fucking, everywhere, white, geno...</td>\n",
       "      <td>Asian, Hispanic</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>Asian</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20147</th>\n",
       "      <td>9998729_gab</td>\n",
       "      <td>the jewish globalist elite have only imported ...</td>\n",
       "      <td>[imported, few, million, muslims, to, multicul...</td>\n",
       "      <td>African, Islam, Jewish</td>\n",
       "      <td>offensive</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>African, Islam</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Islam, Jewish</td>\n",
       "      <td>offensive</td>\n",
       "      <td>African, Islam, Jewish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           post_id                                         tweet_text  \\\n",
       "20143  9989999_gab  if ur still on twitter tell carlton i said his...   \n",
       "20144  9990225_gab  when i first got on here and said i hate trump...   \n",
       "20145  9991681_gab  was macht der moslem wenn der zion gegen seine...   \n",
       "20146  9992513_gab  it is awful look at world demographics asians ...   \n",
       "20147  9998729_gab  the jewish globalist elite have only imported ...   \n",
       "\n",
       "                                            key_features  \\\n",
       "20143  [alcoholic, drug, addicted, teenage, single, m...   \n",
       "20144          [i, hate, trump, i, was, hating, niggers]   \n",
       "20145                                                 []   \n",
       "20146  [asians, are, fucking, everywhere, white, geno...   \n",
       "20147  [imported, few, million, muslims, to, multicul...   \n",
       "\n",
       "                        target       label annotator_1_label  \\\n",
       "20143  Men, None, Other, Women   offensive         offensive   \n",
       "20144     African, None, Other   offensive         offensive   \n",
       "20145       Islam, None, Other      normal         offensive   \n",
       "20146          Asian, Hispanic  hatespeech        hatespeech   \n",
       "20147   African, Islam, Jewish   offensive        hatespeech   \n",
       "\n",
       "      annotator_1_target annotator_2_label annotator_2_target  \\\n",
       "20143  Men, Women, Other         offensive               None   \n",
       "20144            African         offensive     African, Other   \n",
       "20145              Islam            normal              Other   \n",
       "20146           Hispanic        hatespeech              Asian   \n",
       "20147     African, Islam         offensive      Islam, Jewish   \n",
       "\n",
       "      annotator_3_label      annotator_3_target  \n",
       "20143            normal                    None  \n",
       "20144            normal                    None  \n",
       "20145            normal                    None  \n",
       "20146         offensive                   Asian  \n",
       "20147         offensive  African, Islam, Jewish  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for row in data.items():\n",
    "    post_id = row[1]['post_id']\n",
    "    post_tokens = row[1]['post_tokens']\n",
    "    rationales = row[1]['rationales']\n",
    "    annotators = row[1]['annotators']\n",
    "    tweet_text = \" \".join(post_tokens)\n",
    "\n",
    "    # Aggregate all rationales\n",
    "    combined_rationale = [any(rat[i] for rat in rationales) for i in range(len(post_tokens))] if rationales else [0] * len(post_tokens)\n",
    "\n",
    "    # Extract key features\n",
    "    key_features = [post_tokens[i] for i, is_key in enumerate(combined_rationale) if is_key]\n",
    "\n",
    "    annotator_data = {}\n",
    "    all_targets = set()  # To store unique targets\n",
    "    labels = []  # To collect labels for voting\n",
    "\n",
    "    for index, annotator in enumerate(annotators, start=1):  # Use index as annotator_id\n",
    "        annotator_data[f\"annotator_{index}_label\"] = annotator['label']\n",
    "        annotator_data[f\"annotator_{index}_target\"] = \", \".join(annotator['target']) if annotator['target'] else None\n",
    "\n",
    "        # Collect all targets\n",
    "        all_targets.update(annotator['target'])\n",
    "\n",
    "        # Collect labels for voting\n",
    "        labels.append(annotator['label'])\n",
    "\n",
    "    # Combine all unique targets\n",
    "    combined_target = \", \".join(sorted(all_targets))\n",
    "\n",
    "    # Perform majority voting for the label\n",
    "    label_counts = Counter(labels)\n",
    "    voted_label = label_counts.most_common(1)[0][0] if labels else None\n",
    "\n",
    "    # Create the row\n",
    "    row_data = {\n",
    "        \"post_id\": post_id,\n",
    "        \"tweet_text\": tweet_text,\n",
    "        \"key_features\": key_features,\n",
    "        \"target\": combined_target,\n",
    "        \"label\": voted_label,\n",
    "    }\n",
    "    row_data.update(annotator_data)  # Add annotator-related fields\n",
    "\n",
    "    rows.append(row_data)\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed5b8277-7749-4648-b659-f4bca2df72d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"dataset.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a598a3b-5c2b-4040-b5c9-5a289edd3a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data\n",
    "data = [\n",
    "    {key: d[key] for key in ('post_id', 'tweet_text', 'key_features', 'target', 'label')}\n",
    "    for d in rows\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aea84604-481f-49d2-a69a-b431dbac0bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'post_id': '20216724_gab',\n",
       " 'tweet_text': 'the dark ages was a myth there was nothing dark about it you been listening to too much kike inspired fake history as usual and you hate your own people that much that you immediately believe anything jews tell you',\n",
       " 'key_features': ['kike',\n",
       "  'immediately',\n",
       "  'believe',\n",
       "  'anything',\n",
       "  'jews',\n",
       "  'tell',\n",
       "  'you'],\n",
       " 'target': 'Jewish, None',\n",
       " 'label': 'hatespeech'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see data\n",
    "data[10010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c9550f8-3ba6-4be0-9a12-05ee9045bc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LLM inference function to use later\n",
    "API_URL = \"https://inf.cl.uni-trier.de/chat/\"\n",
    "\n",
    "def llm(model_name, system_prompt, input_query):\n",
    "    # Construct the request payload\n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\"content\": system_prompt, \"role\": \"system\"},\n",
    "            {\"content\": input_query, \"role\": \"user\"}\n",
    "        ],\n",
    "        \"model\": model_name,\n",
    "        \"options\": {}\n",
    "    }\n",
    "    \n",
    "    # Set the request headers\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    # Send the POST request\n",
    "    response = requests.post(API_URL, headers=headers, data=json.dumps(payload))\n",
    "    \n",
    "    # Process the response\n",
    "    if response.status_code == 200:\n",
    "        print(\"Response received successfully:\")\n",
    "        response = response.json() # json.dumps(, indent=4)\n",
    "    else:\n",
    "        print(f\"Failed to retrieve response. Status code: {response.status_code}\")\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "af82f335-4801-4f28-8da5-3239f88b95f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = json.dumps(data[10000])\n",
    "#this is exactly the same as the argument that people who get raped when they were dressed scantily were asking for it you are lame af\"\n",
    "#Label:Normal\n",
    "input_query = user_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b23ba3-ed2b-4c48-8cb7-950e10ddd58e",
   "metadata": {},
   "source": [
    "### Testing Zero Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "577e470e-2d20-4ef5-94f6-f6f3c017e6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "you are AI agent which is specialized in analyzing a text for 3 different classes which is hate speech, offensive and normal, and then provide and educated\n",
    "explanation for why the text falls into any of these categories.\n",
    "In order for you to do that, you have the following key feautures available to you which helps you in your analysis and creating the explanation for it\n",
    "\n",
    "available data: \n",
    "\n",
    "{'post_id': ## post id . ignore it\n",
    " 'tweet_text': #its the main user text that you need to write explaination on.\n",
    " 'key_features': [] # list of the words that made a decision, important feature\n",
    " 'target': # targetted audience. \n",
    " 'label': # either offensive, hate speech or normal.   \n",
    " }\n",
    "Based on the the label present in the available data, write your explanation for each tweet text.\n",
    " \n",
    "# Notes:\n",
    "1) the explnatation should be consice. \n",
    "2) your explanations should be analytical and starightforward. \n",
    "3) while generating the explanations you should also consider the possible context for the text which the user might have in mind when writing the tweet\n",
    "4) The purpose of these explanations is to educate the user as to why certain text written by them falls into certain category and can harm a \n",
    "certain group of people.\n",
    "Now you will be given user input and you have to write explainations.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c05a8bb-55ef-43d3-b209-7ec6d92f8fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response received successfully:\n",
      "The tweet text falls under the category of hate speech due to its derogatory and anti-Semitic language. The use of the term \"kike\" is a strong indicator of this classification, as it is a well-known slur directed towards Jewish people. Additionally, the phrase \"jew-inspired fake history\" perpetuates harmful stereotypes and conspiracy theories about the Jewish community. The tweet also implies that Jewish individuals are manipulative and controlling, which further contributes to its hateful tone. The context suggests that the author is promoting a distorted view of history and fostering animosity towards Jews, which can incite harm and discrimination against this group. This type of language can contribute to a culture of intolerance and prejudice, highlighting the importance of recognizing and rejecting hate speech.\n",
      "CPU times: user 61.4 ms, sys: 19.3 ms, total: 80.7 ms\n",
      "Wall time: 44.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_name = \"llama3.3:70b-instruct-q6_K\"\n",
    "\n",
    "response = llm(model_name, system_prompt, input_query)\n",
    "explaination = response['response']\n",
    "print(explaination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26a899e8-a954-4c61-907a-ab98f87124f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response received successfully:\n",
      " This tweet falls into the category of hate speech due to the use of a derogatory slur against Jews (the word \"kike\"). The text accuses individuals of believing \"anything Jews tell them,\" implying that there is something inherently false or harmful in Jewish information or perspectives. This language can be hurtful and alienating towards Jewish people, and it contributes to a climate of prejudice and intolerance. It's important to remember that using such language only serves to divide people and perpetuate negative stereotypes. Instead of relying on slurs and prejudices, we should strive for understanding, respect, and open-mindedness towards all people and their histories.\n",
      "CPU times: user 50.8 ms, sys: 4.77 ms, total: 55.6 ms\n",
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_name = \"mistral:7b-instruct-v0.2-q6_K\"\n",
    "\n",
    "response = llm(model_name, system_prompt, input_query)\n",
    "explaination = response['response']\n",
    "print(explaination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971c14b6-c924-4ba7-a31a-e6643597764d",
   "metadata": {},
   "source": [
    "### Testing Few Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d6fcbd4-4503-48f1-bdef-3b4db8fcae4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "you are AI agent which is specialized in analyzing a text for 3 different classes which is hate speech, offensive and normal, and then provide and educated\n",
    "explanation for why the text falls into any of these categories. \n",
    "In order for you to do that, you have the following key feautures available to you which helps you in your analysis and creating the explanation for it\n",
    "\n",
    "key_features: \n",
    "\n",
    "{'post_id': ## post id . ignore it\n",
    " 'tweet_text': #its the main user text that you need to write explaination on.\n",
    " 'key_features': [] # list of the words that made a decision, important feature\n",
    " 'target': # targetted audience. \n",
    " 'label': # either offensive, hate speech or normal.   \n",
    " }\n",
    "below are some of the example tweet_text and their explanations for each categories, refer those and learn from them to generate your explanations :\n",
    "\n",
    "Label -> Normal\n",
    "\n",
    "1. \"i know this is somewhat hypocritical but what the fuck is the deal with queer guys and slightly too small white tshirts\"\n",
    "Explanation: The tweet has been labeled normal because the user is solely expressing an observation. However the use of vulgar terms such as “fuck” may indicate that the user has a rather negative outlook towards topics concerning queers. Given that the context is not clear it may be understood as a neutral observation. The targets used within the dataset do not contain the word “queer” but the word homosexual. \n",
    "\n",
    "\n",
    "2. “wore a nipsey blue suit today only the niggers in the work place feel the energy”\n",
    "Explanation:This tweet has been labeled normal because it seems to be a positive reference of paying tribute to the rapper nipsey hussle who is known for a specific shade of blue that is affiliated to the crib gang culture of LA.\n",
    "The use of the term \"niggers\" is offensive and rooted in racism. Even if no direct harm or attack is evident, it perpetuates a derogatory term, which many systems and definitions include as hate speech. However, disagreement in labeling often arises due to contextual interpretations. Example for that could be Cultural or Social Context that goes Intended Meaning. In the tweet addition The phrase might be interpreted as describing a situation where the \"energy\" of the outfit is appreciated by a certain group, which could be seen as neutral, despite the offensive language.\n",
    "\n",
    "\n",
    "3. rafiullah shaheed a young man from levi force was shot dead by unknown men in muslim bagh a levies officer was killed in a bomb blast in lashkar gah on sunday while militants were also killed on the same day three people including mullahaniyev were killed in chaman\"\n",
    "Explanation: The statement is a factual report of events without any explicit derogatory, hateful, or harmful language targeting a specific individual or group based on characteristics like race, religion, or ethnicity. It lacks the intention to incite hate or violence, which is key to labeling content as hate speech.\n",
    "\n",
    "Label -> Offensive\n",
    " \n",
    "1) “pocahontas jumps in bed with moslem terrorists interesting combo”\n",
    "Explanation:This statement is labeled offensive because it uses derogatory language and stereotypes to insult and demean individuals or groups. Referring to someone as \"Pocahontas\" in a pejorative context is disrespectful, and associating them with \"Muslim terrorists\" perpetuates harmful stereotypes and biases, making the comment offensive and inappropriate.\n",
    "\n",
    "2) iIslamophobic you for real and how is islam a race you half wit\n",
    "Explanation: It is labled offensive beacuse it contains an insult.\n",
    "\n",
    "3) treat the immigrants as drug traffickers they will soon have a change of mind\n",
    "Explanation: This statement is offensive because it unjustly stereotypes immigrants as drug traffickers, promoting a harmful generalization that dehumanizes and criminalizes an entire group of people. Such language fosters prejudice, discrimination, and hostility toward immigrants. Furthermore it incitement to\n",
    "\n",
    " \n",
    "Label -> Hate Speech\n",
    "\n",
    "1)you niggas is fake asl that why you dont see none round me\n",
    "Explanation:This statement is classified as hate speech because it uses a racial slur (\"niggas\"), which is historically and culturally offensive, particularly against Black individuals. Even when used in some contexts as reclaimed language, its use in this statement appears derogatory, contributing to a hostile and discriminatory tone. The inclusion of aggressive language further amplifies its hateful nature.\n",
    "\n",
    "\n",
    "2) \"online nazi haha guys the left can not meme <number> white privilege diversity is our strength race is just skin color the holocaust racist sexist bigot homophobe islamophobe anti semite\"\n",
    "Explanation: This statement is hate speech because it mocks and trivializes serious societal issues, such as racism, sexism, and discrimination, using a sarcastic tone to dismiss terms like \"white privilege,\" \"diversity is our strength,\" and \"anti-Semite.\" By doing so, it undermines the significance of these issues and belittles those advocating for equality. References to \"Nazi\" and \"the Holocaust\" in a dismissive context further minimize historical atrocities and signal alignment with extremist ideologies. Overall, the statement ridicules efforts to address inequality and promotes hostility, making it hate speech.\n",
    "\n",
    "3) \"pro tip the niggers do not care if you never owned slaves granddaddy fought the natzis or great great grandad ground the confederacy into dust with the boot heel of the proto bolshevik yankee gubment force of weight and arms behind it they hate you because you are white and you exist altright\"\n",
    "Explanation:This statement is classified as hate speech because it uses the racial slur (\"niggers\"). The statement further vilifies an entire group by making sweeping generalizations, such as claiming that Black people \"hate you because you are white and you exist.\" This kind of language fosters an \"us vs. them\" narrative, portraying Black people as inherently hostile toward white people, which promotes racial division and resentment. The inclusion of terms like \"proto Bolshevik Yankee gubment force\" and \"altright\" reflects alignment with extremist ideologies often associated with white nationalism and discriminatory rhetoric. Additionally, references to historical events such as \"granddaddy fought the Nazis\" and \"great great grandad ground the Confederacy\" are weaponized to evoke a sense of pride in white heritage while simultaneously vilifying Black individuals. \n",
    "\n",
    "# Notes:\n",
    "1) the explnatation should be consice. \n",
    "2) your explanations should be analytical and starightforward. \n",
    "3) while generating the explanations you should also consider the possible context for the text which the user might have in mind when writing the tweet\n",
    "4) The purpose of these explanations is to educate the user as to why certain text written by them falls into certain category and can harm a \n",
    "certain group of people.\n",
    "Now you will be given user input and you have to write explainations.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5d7bd3c-5f04-49a1-82d5-9af7a8efc39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response received successfully:\n",
      "This statement is classified as hate speech because it contains a highly offensive and derogatory term (\"kike\") to refer to Jewish people. The use of this slur is historically associated with anti-Semitic harassment and discrimination. Furthermore, the statement promotes conspiracy theories about Jewish people controlling or manipulating historical narratives, which is a common trope in anti-Semitic rhetoric. \n",
      "\n",
      "The phrase \"you hate your own people\" suggests that the user is accusing someone of self-hatred for accepting historical facts, implying that there is a traitorous act in acknowledging Jewish contributions to history. This kind of language fosters division, promotes hatred, and undermines trust between different groups. The statement's intent is to discredit and demean Jewish individuals by questioning their integrity and implying they spread \"fake history.\" \n",
      "\n",
      "The use of the term \"Jews\" in this context also perpetuates a harmful stereotype that Jewish people are manipulative or dishonest. Overall, the language used here is aggressive, discriminatory, and contributes to a hostile environment against Jewish individuals. It's essential to recognize the harm caused by such rhetoric and to promote respectful dialogue and accurate historical representation.\n",
      "CPU times: user 56.7 ms, sys: 18.5 ms, total: 75.1 ms\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_name = \"llama3.3:70b-instruct-q6_K\"\n",
    "\n",
    "response = llm(model_name, system_prompt, input_query)\n",
    "explaination = response['response']\n",
    "print(explaination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78a34229-873a-4c98-afe3-68bd57bfa888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response received successfully:\n",
      " Explanation: This tweet is classified as hate speech because it contains the derogatory term \"kike,\" which is an anti-Semitic slur used to demean and discriminate against Jewish people. The statement accuses those who believe in certain historical narratives as being gullible and hating their own people, specifically targeting Jewish individuals. By insinuating that Jewish people have a malicious intent to spread false history, this tweet perpetuates harmful stereotypes and promotes hate speech against the Jewish community. The statement's intention is to provoke anger, discrimination, and hostility towards Jews based on their religious identity. Additionally, the term \"kike\" has been historically used as a label to dehumanize and degrade Jewish people, making it a clear example of hateful language.\n",
      "CPU times: user 53.7 ms, sys: 4.65 ms, total: 58.3 ms\n",
      "Wall time: 20.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_name = \"mistral:7b-instruct-v0.2-q6_K\"\n",
    "\n",
    "response = llm(model_name, system_prompt, input_query)\n",
    "explaination = response['response']\n",
    "print(explaination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3651104c-6253-460c-9313-d44a0fae2677",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "\n",
    "you are AI agent which is specialized in analyzing a text for 3 different classes which is hate speech, offensive and normal, and then provide and educated\n",
    "explanation for why the text falls into any of these categories.\n",
    "\n",
    "\n",
    "available data:\n",
    "- tweet_text: The main user text requiring explanation.\n",
    "- key_features: Words or phrases crucial to the decision.\n",
    "- target: The audience or group targeted by the text.\n",
    "- label: The classification of the text (hate speech, offensive, or neutral).\n",
    "\n",
    "Your job is to:\n",
    "1. Start by identifying the label of the text and summarizing what it indicates about the content.\n",
    "2. Analyze the key features and explain how they support the classification.\n",
    "3. Consider the target and evaluate how the text affects or refers to this group.\n",
    "4. Examine the overall context and tone to understand the user's intent.\n",
    "5. Conclude with a detailed explanation, justifying the classification and the reasoning behind it.\n",
    "\n",
    "Guidelines:\n",
    "- Ensure the explanation is concise.\n",
    "- your explanations should be analytical and starightforward\n",
    "- If the label is neutral, but you believe the text could be hate speech or offensive, explain why it is still considered neutral.\n",
    "- If the label is offensive, describe the nature of the offense and how the key features contribute to it.\n",
    "\n",
    "Here are examples for guidance:\n",
    "\n",
    "1. **Hate Speech**:\n",
    "   tweet_text: \"A negro moslem doctor got struck off for negligence when a white <number> year old kid with down syndrome died; the guardian's response is to help promote a crowdfunding campaign for her.\"\n",
    "   - key_features: [\"negro\", \"moslem\", \"white <number> year old kid\", \"down syndrome\"]\n",
    "   - target: Ethnic groups (Black and White), religious group (Muslim), and individuals with disabilities (Down syndrome)\n",
    "   - label: Hate Speech\n",
    "   Reasoning:\n",
    "   Step 1: The label is Hate Speech, indicating that the content may upset or insult individuals based on ethnicity, religion, or disability.\n",
    "   Step 2: Key features include derogatory terms based on race (\"negro\"), religion (\"moslem\"), and descriptors that unnecessarily highlight race and disability in a sensitive context.\n",
    "   Step 3: The target includes multiple vulnerable groups, which compounds the potential for offense.\n",
    "   Step 4: The context suggests an underlying bias in how different ethnic and religious groups are treated and discussed in relation to a tragic incident.\n",
    "   Conclusion: This text is categorized as Hate Speech due to its derogatory language and the sensitive context in which these terms are employed, targeting specific ethnic, religious, and disabled groups.\n",
    "\n",
    "2. **Offensive**:\n",
    "   - tweet_text: \"Why are men so bad at taking care of kids?\"\n",
    "   - key_features: [\"men\", \"bad at taking care\"]\n",
    "   - target: Men\n",
    "   - label: Offensive\n",
    "   Reasoning:\n",
    "   Step 1: The label is offensive, which suggests the text contains harmful stereotypes or derogatory assumptions.  \n",
    "   Step 2: Key features like \"bad at taking care\" perpetuate a stereotype that questions men’s abilities in caregiving.  \n",
    "   Step 3: The target is men, a group generalized and negatively characterized in this statement.  \n",
    "   Step 4: While the tone is not explicitly harmful, the language dismisses and demeans the target group.  \n",
    "   Conclusion: This text is offensive because it perpetuates a harmful stereotype about men, although it does not incite direct harm.\n",
    "\n",
    "3. **Neutral**:\n",
    "   - tweet_text: \"What’s everyone’s favorite food?\"\n",
    "   - key_features: None\n",
    "   - target: None\n",
    "   - label: Neutral\n",
    "   Reasoning:\n",
    "   Step 1: The label is neutral, meaning the text does not contain offensive or harmful language.  \n",
    "   Step 2: There are no key features or elements that suggest hostility, harm, or stereotypes.  \n",
    "   Step 3: The content is inclusive and general, without targeting any group or individual.  \n",
    "   Step 4: The context and tone are friendly and open-ended, with no intent to harm or offend.  \n",
    "   Conclusion: This text is neutral because it is non-controversial, lacks harmful language, and does not target any individual or group.\n",
    "\n",
    "Now, write an explanation for the given input using this reasoning framework.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45d5bdc7-59ea-4ace-9987-d491daedc414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response received successfully:\n",
      "**Hate Speech**:\n",
      "\n",
      "The given text is labeled as Hate Speech, which indicates that the content contains language or ideas that are intended to promote hatred, hostility, or violence against a particular group of people.\n",
      "\n",
      "1. **Label Analysis**: The label \"Hate Speech\" suggests that the text may include derogatory terms, stereotypes, or discriminatory language targeting specific groups.\n",
      "2. **Key Features Analysis**: The key features identified in this text, such as [\"kike\", \"immediately\", \"believe\", \"anything\", \"jews\", \"tell\", \"you\"], are crucial to understanding why it falls under Hate Speech. Specifically:\n",
      "   - The term \"kike\" is a highly derogatory and offensive slur used against Jewish people.\n",
      "   - Phrases like \"you hate your own people that much that you immediately believe anything jews tell you\" imply a conspiracy theory where Jews are perceived as manipulators, which is a common anti-Semitic trope.\n",
      "3. **Target Analysis**: The target of this text includes the Jewish community (\"Jewish\") and potentially others who are not specified (\"None\"), implying a broader reach of hostility or influence. The language used directly attacks the Jewish community with derogatory terms and suggests that they are manipulative, which can incite hatred against them.\n",
      "4. **Context and Tone Analysis**: The context of the text discusses historical narratives and accuses those who believe in certain versions of history as being misled by \"kike inspired fake history.\" This not only distorts historical facts but also uses pejorative language to describe Jewish people's perceived influence on history, reinforcing harmful stereotypes. The tone is aggressive and accusatory, aiming to discredit and demean both the historical narrative and the individuals who adhere to it, particularly those of Jewish descent.\n",
      "5. **Conclusion**: This text is categorized as Hate Speech because it employs highly offensive language (\"kike\") against Jewish people, promotes anti-Semitic conspiracy theories by suggesting Jews manipulate others through misinformation, and targets individuals based on their religion or ethnicity with derogatory assumptions. The combination of these elements creates a harmful and hostile environment that can incite violence, discrimination, or prejudice against the targeted group, which is a hallmark of Hate Speech.\n",
      "CPU times: user 61.2 ms, sys: 19.7 ms, total: 80.9 ms\n",
      "Wall time: 3min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_name = \"llama3.3:70b-instruct-q6_K\"\n",
    "\n",
    "response = llm(model_name, system_prompt, input_query)\n",
    "explaination = response['response']\n",
    "print(explaination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d868cc2-2dba-41d3-b472-16f2c579c2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response received successfully:\n",
      " Reasoning:\n",
      "\n",
      "Step 1: The label is Hate Speech, indicating that the content may contain hostile or derogatory language towards a specific group.\n",
      "\n",
      "Step 2: Key features include \"kike,\" which is a derogatory term used to discriminate against Jewish people, and \"immediately believe anything Jews tell you,\" which implies a lack of critical thinking and an assumption that all Jews spread false information. This language perpetuates harmful stereotypes and biases.\n",
      "\n",
      "Step 3: The target in this text is the Jewish community, as indicated by the use of the derogatory term \"kike.\"\n",
      "\n",
      "Step 4: The context and overall tone suggest an underlying hatred or disdain for this group, as indicated by phrases like \"hate your own people\" and the accusation that they spread \"fake history.\" This text is not meant to be inclusive or neutral; instead, it serves to demean and belittle the Jewish community.\n",
      "\n",
      "Conclusion: This text is categorized as Hate Speech due to its derogatory language towards the Jewish community, perpetuating harmful stereotypes and biases, and lacking any friendly or open-ended context.\n",
      "CPU times: user 64.7 ms, sys: 15.8 ms, total: 80.5 ms\n",
      "Wall time: 7.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_name = \"mistral:7b-instruct-v0.2-q6_K\"\n",
    "\n",
    "response = llm(model_name, system_prompt, input_query)\n",
    "explaination = response['response']\n",
    "print(explaination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb36b892-030b-4dcf-b6e1-b0b722c45d7b",
   "metadata": {},
   "source": [
    "### Testing Labelling with Zero Shot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4470c029-558f-4c25-bc34-9d69dcfa9435",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "you are AI agent which is specialized in analyzing a text for 3 different classes which is hate speech, offensive and normal.\n",
    "\n",
    "available data: \n",
    "\n",
    "{'post_id': ## post id . ignore it\n",
    " 'tweet_text': #its the main user text that you need to write explaination on.\n",
    " 'key_features': [] # list of the words that made a decision, important feature\n",
    " 'target': # targetted audience. \n",
    " 'label': # either offensive, hate speech or normal.   \n",
    " }\n",
    "Your output should contain:\n",
    "- the existing label.\n",
    "- Your own decision for the label based on the tweet text.\n",
    " \n",
    "# Notes:\n",
    "1) the output should NOT ontain justification of the deciion. Only the existing label and your own predicted label.\n",
    "2) the outpout should be in the form of a dictionary. \n",
    "3) while predicting the label you should also consider the possible context for the text which the user might have in mind when writing the tweet\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8400f6b5-2c8b-4956-b0d3-24612fa33a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response received successfully:\n",
      "{\"existing_label\": \"normal\", \"predicted_label\": \"offensive\"}\n",
      "CPU times: user 52.1 ms, sys: 4.89 ms, total: 57 ms\n",
      "Wall time: 19.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_name = \"llama3.3:70b-instruct-q6_K\"\n",
    "\n",
    "response = llm(model_name, system_prompt, input_query)\n",
    "explaination = response['response']\n",
    "print(explaination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5501f2c1-e31e-4ab4-990f-f0b61389c17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response received successfully:\n",
      " {\"post_id\": \"1178534874602496000\\_twitter\", \"tweet\\_text\": \"<user> <user> this is exactly the same as the argument that people who get raped when they were dressed scantily were asking for it you are lame af\", \"key\\_features\": [\"rape\", \"dressed scantily\"], \"target\": \"None\", \"label\": \"hate speech\"}\n",
      "\n",
      "The existing label is marked as normal, but the use of the term \"people who get raped when they were dressed scantily\" implies a victim-blaming attitude and could be considered hate speech towards victims of sexual assault.\n",
      "CPU times: user 60.6 ms, sys: 4.59 ms, total: 65.2 ms\n",
      "Wall time: 5.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_name = \"mistral:7b-instruct-v0.2-q6_K\"\n",
    "\n",
    "response = llm(model_name, system_prompt, input_query)\n",
    "explaination = response['response']\n",
    "print(explaination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff6e08e-6016-497f-848c-f470c09d5d62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
