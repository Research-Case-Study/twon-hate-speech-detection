{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccecc1ba-e2f8-4a97-9396-817aebeb6500",
   "metadata": {},
   "source": [
    "# Zero shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5db3e188-0d2b-461c-a0c0-87ce9a1ee992",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_prompt = \"\"\"\n",
    "you are AI agent which is specialized in analyzing a text for 3 different classes which is hate speech, offensive and normal, and then provide and educated\n",
    "explanation for why the text falls into any of these categories.\n",
    "In order for you to do that, you have the following key feautures available to you which helps you in your analysis and creating the explanation for it\n",
    "\n",
    "available data: \n",
    "\n",
    "{'post_id': ## post id . ignore it\n",
    " 'tweet_text': #its the main user text that you need to write explaination on.\n",
    " 'key_features': [] # list of the words that made a decision, important feature\n",
    " 'target': # targetted audience. \n",
    " 'label': # either offensive, hate speech or normal.   \n",
    " }\n",
    "Based on the the label present in the available data, write your explanation for each tweet text.\n",
    " \n",
    "# Notes:\n",
    "1) the explnatation should be consice. \n",
    "2) your explanations should be analytical and starightforward. \n",
    "3) while generating the explanations you should also consider the possible context for the text which the user might have in mind when writing the tweet\n",
    "4) The purpose of these explanations is to educate the user as to why certain text written by them falls into certain category and can harm a \n",
    "certain group of people.\n",
    "Now you will be given user input and you have to write explainations.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778d4a5c-38b1-4774-942f-6cd2882eca07",
   "metadata": {},
   "source": [
    "# Zero Shot for Label- Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "722f654f-e997-4398-a216-356be4174514",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_label_prompt = \"\"\"\n",
    "you are AI agent which is specialized in analyzing a text for 3 different classes which is hate speech, offensive and normal.\n",
    "\n",
    "available data: \n",
    "\n",
    "{'post_id': ## post id . ignore it\n",
    " 'tweet_text': #its the main user text that you need to write explaination on.\n",
    " 'key_features': [] # list of the words that made a decision, important feature\n",
    " 'target': # targetted audience. \n",
    " 'label': # either offensive, hate speech or normal.   \n",
    " }\n",
    "Your output should contain:\n",
    "- the existing label.\n",
    "- Your own decision for the label based on the tweet text.\n",
    " \n",
    "# Notes:\n",
    "1) the output should NOT ontain justification of the deciion. Only the existing label and your own predicted label.\n",
    "2) the outpout should be in the form of a dictionary. \n",
    "3) while predicting the label you should also consider the possible context for the text which the user might have in mind when writing the tweet\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c30dbb-f17d-4474-87ef-10c6e35856a2",
   "metadata": {},
   "source": [
    "# Few shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "01cc2d91-ff42-4f50-ac58-d317b63870eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = \"\"\"\n",
    "you are AI agent which is specialized in analyzing a text for 3 different classes which is hate speech, offensive and normal, and then provide and educated\n",
    "explanation for why the text falls into any of these categories. \n",
    "In order for you to do that, you have the following key feautures available to you which helps you in your analysis and creating the explanation for it\n",
    "\n",
    "key_features: \n",
    "\n",
    "{'post_id': ## post id . ignore it\n",
    " 'tweet_text': #its the main user text that you need to write explaination on.\n",
    " 'key_features': [] # list of the words that made a decision, important feature\n",
    " 'target': # targetted audience. \n",
    " 'label': # either offensive, hate speech or normal.   \n",
    " }\n",
    "below are some of the example tweet_text and their explanations for each categories, refer those and learn from them to generate your explanations :\n",
    "\n",
    "Label -> Normal\n",
    "\n",
    "1. \"i know this is somewhat hypocritical but what the fuck is the deal with queer guys and slightly too small white tshirts\"\n",
    "Explanation: The tweet has been labeled normal because the user is solely expressing an observation. However the use of vulgar terms such as “fuck” may indicate that the user has a rather negative outlook towards topics concerning queers. Given that the context is not clear it may be understood as a neutral observation. The targets used within the dataset do not contain the word “queer” but the word homosexual. \n",
    "\n",
    "\n",
    "2. “wore a nipsey blue suit today only the niggers in the work place feel the energy”\n",
    "Explanation:This tweet has been labeled normal because it seems to be a positive reference of paying tribute to the rapper nipsey hussle who is known for a specific shade of blue that is affiliated to the crib gang culture of LA.\n",
    "The use of the term \"niggers\" is offensive and rooted in racism. Even if no direct harm or attack is evident, it perpetuates a derogatory term, which many systems and definitions include as hate speech. However, disagreement in labeling often arises due to contextual interpretations. Example for that could be Cultural or Social Context that goes Intended Meaning. In the tweet addition The phrase might be interpreted as describing a situation where the \"energy\" of the outfit is appreciated by a certain group, which could be seen as neutral, despite the offensive language.\n",
    "\n",
    "\n",
    "3. rafiullah shaheed a young man from levi force was shot dead by unknown men in muslim bagh a levies officer was killed in a bomb blast in lashkar gah on sunday while militants were also killed on the same day three people including mullahaniyev were killed in chaman\"\n",
    "Explanation: The statement is a factual report of events without any explicit derogatory, hateful, or harmful language targeting a specific individual or group based on characteristics like race, religion, or ethnicity. It lacks the intention to incite hate or violence, which is key to labeling content as hate speech.\n",
    "\n",
    "Label -> Offensive\n",
    " \n",
    "1) “pocahontas jumps in bed with moslem terrorists interesting combo”\n",
    "Explanation:This statement is labeled offensive because it uses derogatory language and stereotypes to insult and demean individuals or groups. Referring to someone as \"Pocahontas\" in a pejorative context is disrespectful, and associating them with \"Muslim terrorists\" perpetuates harmful stereotypes and biases, making the comment offensive and inappropriate.\n",
    "\n",
    "2) iIslamophobic you for real and how is islam a race you half wit\n",
    "Explanation: It is labled offensive beacuse it contains an insult.\n",
    "\n",
    "3) treat the immigrants as drug traffickers they will soon have a change of mind\n",
    "Explanation: This statement is offensive because it unjustly stereotypes immigrants as drug traffickers, promoting a harmful generalization that dehumanizes and criminalizes an entire group of people. Such language fosters prejudice, discrimination, and hostility toward immigrants. Furthermore it incitement to\n",
    "\n",
    " \n",
    "Label -> Hate Speech\n",
    "\n",
    "1)you niggas is fake asl that why you dont see none round me\n",
    "Explanation:This statement is classified as hate speech because it uses a racial slur (\"niggas\"), which is historically and culturally offensive, particularly against Black individuals. Even when used in some contexts as reclaimed language, its use in this statement appears derogatory, contributing to a hostile and discriminatory tone. The inclusion of aggressive language further amplifies its hateful nature.\n",
    "\n",
    "\n",
    "2) \"online nazi haha guys the left can not meme <number> white privilege diversity is our strength race is just skin color the holocaust racist sexist bigot homophobe islamophobe anti semite\"\n",
    "Explanation: This statement is hate speech because it mocks and trivializes serious societal issues, such as racism, sexism, and discrimination, using a sarcastic tone to dismiss terms like \"white privilege,\" \"diversity is our strength,\" and \"anti-Semite.\" By doing so, it undermines the significance of these issues and belittles those advocating for equality. References to \"Nazi\" and \"the Holocaust\" in a dismissive context further minimize historical atrocities and signal alignment with extremist ideologies. Overall, the statement ridicules efforts to address inequality and promotes hostility, making it hate speech.\n",
    "\n",
    "3) \"pro tip the niggers do not care if you never owned slaves granddaddy fought the natzis or great great grandad ground the confederacy into dust with the boot heel of the proto bolshevik yankee gubment force of weight and arms behind it they hate you because you are white and you exist altright\"\n",
    "Explanation:This statement is classified as hate speech because it uses the racial slur (\"niggers\"). The statement further vilifies an entire group by making sweeping generalizations, such as claiming that Black people \"hate you because you are white and you exist.\" This kind of language fosters an \"us vs. them\" narrative, portraying Black people as inherently hostile toward white people, which promotes racial division and resentment. The inclusion of terms like \"proto Bolshevik Yankee gubment force\" and \"altright\" reflects alignment with extremist ideologies often associated with white nationalism and discriminatory rhetoric. Additionally, references to historical events such as \"granddaddy fought the Nazis\" and \"great great grandad ground the Confederacy\" are weaponized to evoke a sense of pride in white heritage while simultaneously vilifying Black individuals. \n",
    "\n",
    "# Notes:\n",
    "1) the explnatation should be consice. \n",
    "2) your explanations should be analytical and starightforward. \n",
    "3) while generating the explanations you should also consider the possible context for the text which the user might have in mind when writing the tweet\n",
    "4) The purpose of these explanations is to educate the user as to why certain text written by them falls into certain category and can harm a \n",
    "certain group of people.\n",
    "Now you will be given user input and you have to write explainations.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e88fc5-790e-4d14-99c2-b80d905dfca5",
   "metadata": {},
   "source": [
    "# Few Shot + Chain of Thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "04830158-b8c8-435a-a5cf-bf744411cb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_CoT_prompt = \"\"\"\n",
    "As an AI agent specialized in text analysis, your task is to classify text into one of three categories: hate speech, offensive, or normal. \n",
    "Based on this classification, provide a concise yet comprehensive explanation of why the text falls into the specified category.\n",
    "\n",
    "Available data:\n",
    "- tweet_text: The text to be analyzed.\n",
    "- key_features: Crucial words or phrases that influenced the classification.\n",
    "- target: The intended audience or group targeted by the text.\n",
    "- label: The classification of the text (hate speech, offensive, or neutral).\n",
    "\n",
    "Procedure:\n",
    "1. Identify and briefly summarize the label's implication for the text.\n",
    "2. Discuss how key features support this classification.\n",
    "3. Evaluate the text's impact on or reference to the target group.\n",
    "4. Assess the context and tone to gauge the user's intent.\n",
    "5. Provide a concise conclusion that justifies the classification based on the analysis.\n",
    "\n",
    "Guidelines:\n",
    "- Keep explanations concise and focused.\n",
    "- Emphasize key factors that support the classification.\n",
    "- If the label is neutral but the text could be seen as offensive or hate speech, explain the rationale for its neutral classification.\n",
    "- For an offensive label, detail the nature of the offense and the contribution of key features.\n",
    "\n",
    "Example analyses:\n",
    "\n",
    "1. **Hate Speech**:\n",
    "   - tweet_text: \"A negro moslem doctor got struck off for negligence when a white <number> year old kid with down syndrome died; the guardian's response is to help promote a crowdfunding campaign for her.\"\n",
    "   - Key points include discriminatory terms and the sensitive context, targeting racial, religious, and disabled groups. The usage of derogatory language in describing an ethnic minority and religious group in a negative incident categorizes this as hate speech.\n",
    "\n",
    "2. **Offensive**:\n",
    "   - tweet_text: \"Why are men so bad at taking care of kids?\"\n",
    "   - Key stereotypes include questioning men’s caregiving abilities. \n",
    "   - This generalized negative portrayal classifies the text as offensive, focusing on undermining a specific gender's capabilities without direct harm.\n",
    "\n",
    "3. **Neutral**:\n",
    "   - tweet_text: \"What’s everyone’s favorite food?\"\n",
    "   - This lacks controversial content or targeted language, making it neutral. The friendly tone and general nature affirm its classification, posing no harm or offense to any group.\n",
    "\n",
    "Please analyze the given text using this streamlined reasoning framework.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d50f52d-bd7d-43de-abd3-161ca35d03be",
   "metadata": {},
   "source": [
    "# Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c64ea9a1-257f-4ac8-a51c-d95f2724cf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams, Batch\n",
    "from collections import Counter\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9fa2d6-3a17-4818-af15-58af2de3b457",
   "metadata": {},
   "source": [
    "## Load and Transform Dataset + convert to DF | Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c923dcb-7f15-4d68-ba43-e4478ac90161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the dataset.json file\n",
    "file_path = '../Data/dataset.json'\n",
    "data = None\n",
    "try:\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    print(\"File loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {file_path}. Please check the file path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b50ddcb3-7d9e-4e21-a22a-735d9722a96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>key_features</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "      <th>annotator_1_label</th>\n",
       "      <th>annotator_1_target</th>\n",
       "      <th>annotator_2_label</th>\n",
       "      <th>annotator_2_target</th>\n",
       "      <th>annotator_3_label</th>\n",
       "      <th>annotator_3_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20143</th>\n",
       "      <td>9989999_gab</td>\n",
       "      <td>if ur still on twitter tell carlton i said his...</td>\n",
       "      <td>[alcoholic, drug, addicted, teenage, single, m...</td>\n",
       "      <td>Men, None, Other, Women</td>\n",
       "      <td>offensive</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Men, Women, Other</td>\n",
       "      <td>offensive</td>\n",
       "      <td>None</td>\n",
       "      <td>normal</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20144</th>\n",
       "      <td>9990225_gab</td>\n",
       "      <td>when i first got on here and said i hate trump...</td>\n",
       "      <td>[i, hate, trump, i, was, hating, niggers]</td>\n",
       "      <td>African, None, Other</td>\n",
       "      <td>offensive</td>\n",
       "      <td>offensive</td>\n",
       "      <td>African</td>\n",
       "      <td>offensive</td>\n",
       "      <td>African, Other</td>\n",
       "      <td>normal</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20145</th>\n",
       "      <td>9991681_gab</td>\n",
       "      <td>was macht der moslem wenn der zion gegen seine...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Islam, None, Other</td>\n",
       "      <td>normal</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Islam</td>\n",
       "      <td>normal</td>\n",
       "      <td>Other</td>\n",
       "      <td>normal</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20146</th>\n",
       "      <td>9992513_gab</td>\n",
       "      <td>it is awful look at world demographics asians ...</td>\n",
       "      <td>[asians, are, fucking, everywhere, white, geno...</td>\n",
       "      <td>Asian, Hispanic</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>Asian</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20147</th>\n",
       "      <td>9998729_gab</td>\n",
       "      <td>the jewish globalist elite have only imported ...</td>\n",
       "      <td>[imported, few, million, muslims, to, multicul...</td>\n",
       "      <td>African, Islam, Jewish</td>\n",
       "      <td>offensive</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>African, Islam</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Islam, Jewish</td>\n",
       "      <td>offensive</td>\n",
       "      <td>African, Islam, Jewish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           post_id                                         tweet_text  \\\n",
       "20143  9989999_gab  if ur still on twitter tell carlton i said his...   \n",
       "20144  9990225_gab  when i first got on here and said i hate trump...   \n",
       "20145  9991681_gab  was macht der moslem wenn der zion gegen seine...   \n",
       "20146  9992513_gab  it is awful look at world demographics asians ...   \n",
       "20147  9998729_gab  the jewish globalist elite have only imported ...   \n",
       "\n",
       "                                            key_features  \\\n",
       "20143  [alcoholic, drug, addicted, teenage, single, m...   \n",
       "20144          [i, hate, trump, i, was, hating, niggers]   \n",
       "20145                                                 []   \n",
       "20146  [asians, are, fucking, everywhere, white, geno...   \n",
       "20147  [imported, few, million, muslims, to, multicul...   \n",
       "\n",
       "                        target       label annotator_1_label  \\\n",
       "20143  Men, None, Other, Women   offensive         offensive   \n",
       "20144     African, None, Other   offensive         offensive   \n",
       "20145       Islam, None, Other      normal         offensive   \n",
       "20146          Asian, Hispanic  hatespeech        hatespeech   \n",
       "20147   African, Islam, Jewish   offensive        hatespeech   \n",
       "\n",
       "      annotator_1_target annotator_2_label annotator_2_target  \\\n",
       "20143  Men, Women, Other         offensive               None   \n",
       "20144            African         offensive     African, Other   \n",
       "20145              Islam            normal              Other   \n",
       "20146           Hispanic        hatespeech              Asian   \n",
       "20147     African, Islam         offensive      Islam, Jewish   \n",
       "\n",
       "      annotator_3_label      annotator_3_target  \n",
       "20143            normal                    None  \n",
       "20144            normal                    None  \n",
       "20145            normal                    None  \n",
       "20146         offensive                   Asian  \n",
       "20147         offensive  African, Islam, Jewish  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for row in data.items():\n",
    "    post_id = row[1]['post_id']\n",
    "    post_tokens = row[1]['post_tokens']\n",
    "    rationales = row[1]['rationales']\n",
    "    annotators = row[1]['annotators']\n",
    "    \n",
    "    tweet_text = \" \".join(post_tokens)\n",
    "\n",
    "    # Aggregate all rationales\n",
    "    combined_rationale = [any(rat[i] for rat in rationales) for i in range(len(post_tokens))] if rationales else [0] * len(post_tokens)\n",
    "\n",
    "    # Extract key features\n",
    "    key_features = [post_tokens[i] for i, is_key in enumerate(combined_rationale) if is_key]\n",
    "\n",
    "    annotator_data = {}\n",
    "    all_targets = set()  # To store unique targets\n",
    "    labels = []  # To collect labels for voting\n",
    "\n",
    "    for index, annotator in enumerate(annotators, start=1):  # Use index as annotator_id\n",
    "        annotator_data[f\"annotator_{index}_label\"] = annotator['label']\n",
    "        annotator_data[f\"annotator_{index}_target\"] = \", \".join(annotator['target']) if annotator['target'] else None\n",
    "\n",
    "        # Collect all targets\n",
    "        all_targets.update(annotator['target'])\n",
    "\n",
    "        # Collect labels for voting\n",
    "        labels.append(annotator['label'])\n",
    "\n",
    "    # Combine all unique targets\n",
    "    combined_target = \", \".join(sorted(all_targets))\n",
    "\n",
    "    # Perform majority voting for the label\n",
    "    label_counts = Counter(labels)\n",
    "    voted_label = label_counts.most_common(1)[0][0] if labels else None\n",
    "\n",
    "    # Create the row\n",
    "    row_data = {\n",
    "        \"post_id\": post_id,\n",
    "        \"tweet_text\": tweet_text,\n",
    "        \"key_features\": key_features,\n",
    "        \"target\": combined_target,\n",
    "        \"label\": voted_label,\n",
    "    }\n",
    "    row_data.update(annotator_data)  # Add annotator-related fields\n",
    "\n",
    "    rows.append(row_data)\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ed5b8277-7749-4648-b659-f4bca2df72d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv(\"dataset.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4a598a3b-5c2b-4040-b5c9-5a289edd3a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data\n",
    "data = [\n",
    "    {key: d[key] for key in ('post_id', 'tweet_text', 'key_features', 'target', 'label')}\n",
    "    for d in rows\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aea84604-481f-49d2-a69a-b431dbac0bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'post_id': '20216724_gab',\n",
       " 'tweet_text': 'the dark ages was a myth there was nothing dark about it you been listening to too much kike inspired fake history as usual and you hate your own people that much that you immediately believe anything jews tell you',\n",
       " 'key_features': ['kike',\n",
       "  'immediately',\n",
       "  'believe',\n",
       "  'anything',\n",
       "  'jews',\n",
       "  'tell',\n",
       "  'you'],\n",
       " 'target': 'Jewish, None',\n",
       " 'label': 'hatespeech'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see data\n",
    "data[10010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7c9550f8-3ba6-4be0-9a12-05ee9045bc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LLM inference function to use later\n",
    "API_URL = \"https://inf.cl.uni-trier.de/chat/\"\n",
    "\n",
    "def llm(model_name, system_prompt, input_query):\n",
    "    # Construct the request payload\n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\"content\": system_prompt, \"role\": \"system\"},\n",
    "            {\"content\": input_query, \"role\": \"user\"}\n",
    "        ],\n",
    "        \"model\": model_name,\n",
    "        \"options\": {}\n",
    "    }\n",
    "    \n",
    "    # Set the request headers\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    # Send the POST request\n",
    "    response = requests.post(API_URL, headers=headers, data=json.dumps(payload))\n",
    "    \n",
    "    # Process the response\n",
    "    if response.status_code == 200:\n",
    "        print(\"Response received successfully:\")\n",
    "        response = response.json() # json.dumps(, indent=4)\n",
    "    else:\n",
    "        print(f\"Failed to retrieve response. Status code: {response.status_code}\")\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af82f335-4801-4f28-8da5-3239f88b95f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = json.dumps(data[10000])\n",
    "#this is exactly the same as the argument that people who get raped when they were dressed scantily were asking for it you are lame af\"\n",
    "#Label:Normal\n",
    "input_query = user_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b23ba3-ed2b-4c48-8cb7-950e10ddd58e",
   "metadata": {},
   "source": [
    "### Testing Zero Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "577e470e-2d20-4ef5-94f6-f6f3c017e6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = zero_shot_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4c05a8bb-55ef-43d3-b209-7ec6d92f8fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response received successfully:\n",
      "I strongly disagree with the label \"normal\" assigned to this tweet. Upon analyzing the text, I would categorize it as \"offensive\". Here's why:\n",
      "\n",
      "The tweet draws an analogy between two sensitive topics: rape and victim-blaming. The comparison is made to criticize someone's argument, but it does so in a way that can be perceived as insensitive and dismissive of the severity of rape. The phrase \"you are lame af\" at the end also comes across as aggressive and condescending.\n",
      "\n",
      "While the user may have intended to highlight the flaws in someone's argument, the chosen analogy and tone are likely to offend or upset individuals who have experienced trauma related to rape or sexual assault. A more constructive approach would be to address the argument without invoking sensitive topics or using derogatory language. \n",
      "\n",
      "In a more suitable context, this tweet could have been labeled as \"offensive\" to educate the user on why their choice of words and analogies may cause harm to others.\n",
      "CPU times: user 85.7 ms, sys: 12.1 ms, total: 97.9 ms\n",
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_name = \"llama3.3:70b-instruct-q6_K\"\n",
    "\n",
    "response = llm(model_name, system_prompt, input_query)\n",
    "explaination = response['response']\n",
    "print(explaination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "26a899e8-a954-4c61-907a-ab98f87124f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response received successfully:\n",
      " This tweet falls into the \"normal\" category because the user is engaging in a discussion or debate with another user, using a figurative expression \"asking for it,\" which is commonly used outside of the context of hate speech or offensive language. In this case, it's likely that the users are discussing a contentious issue and using strong language to express their opinions. However, it's important to note that even if the label is \"normal,\" the tone of the conversation can still be harmful or hurtful to certain individuals, particularly those who have experienced rape or sexual violence. The key feature here is the figurative expression \"asking for it,\" which should not be taken literally and can be understood as an intensifier or a way of expressing strong disagreement. It's always important to consider the context of the conversation and the potential impact on different groups when engaging in online discussions.\n",
      "CPU times: user 63.1 ms, sys: 7.47 ms, total: 70.6 ms\n",
      "Wall time: 25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_name = \"mistral:7b-instruct-v0.2-q6_K\"\n",
    "\n",
    "response = llm(model_name, system_prompt, input_query)\n",
    "explaination = response['response']\n",
    "print(explaination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971c14b6-c924-4ba7-a31a-e6643597764d",
   "metadata": {},
   "source": [
    "### Testing Few Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6fcbd4-4503-48f1-bdef-3b4db8fcae4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = few_shot_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d7bd3c-5f04-49a1-82d5-9af7a8efc39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model_name = \"llama3.3:70b-instruct-q6_K\"\n",
    "\n",
    "response = llm(model_name, system_prompt, input_query)\n",
    "explaination = response['response']\n",
    "print(explaination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a34229-873a-4c98-afe3-68bd57bfa888",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model_name = \"mistral:7b-instruct-v0.2-q6_K\"\n",
    "\n",
    "response = llm(model_name, system_prompt, input_query)\n",
    "explaination = response['response']\n",
    "print(explaination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11424fce-083d-4541-8de1-61d89373ca10",
   "metadata": {},
   "source": [
    "# Testing Few shot + Chain of thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3651104c-6253-460c-9313-d44a0fae2677",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = few_shot_CoT_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d5bdc7-59ea-4ace-9987-d491daedc414",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model_name = \"llama3.3:70b-instruct-q6_K\"\n",
    "\n",
    "response = llm(model_name, system_prompt, input_query)\n",
    "explaination = response['response']\n",
    "print(explaination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d868cc2-2dba-41d3-b472-16f2c579c2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model_name = \"mistral:7b-instruct-v0.2-q6_K\"\n",
    "\n",
    "response = llm(model_name, system_prompt, input_query)\n",
    "explaination = response['response']\n",
    "print(explaination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb36b892-030b-4dcf-b6e1-b0b722c45d7b",
   "metadata": {},
   "source": [
    "### Testing Labelling with Zero Shot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4470c029-558f-4c25-bc34-9d69dcfa9435",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = zero_shot_label_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8400f6b5-2c8b-4956-b0d3-24612fa33a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model_name = \"llama3.3:70b-instruct-q6_K\"\n",
    "\n",
    "response = llm(model_name, system_prompt, input_query)\n",
    "explaination = response['response']\n",
    "print(explaination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5501f2c1-e31e-4ab4-990f-f0b61389c17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model_name = \"mistral:7b-instruct-v0.2-q6_K\"\n",
    "\n",
    "response = llm(model_name, system_prompt, input_query)\n",
    "explaination = response['response']\n",
    "print(explaination)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
