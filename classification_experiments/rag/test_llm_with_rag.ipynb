{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e5276a5-e481-4770-8e10-2e27bf9186e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33bee35d-e7be-4234-b591-206ff7741163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the main dataset\n",
    "TEST_DF = pd.read_csv(\"classified_test_df_Hermes-2.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c58354e-72d2-4f88-bbd1-002fdbee4aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1884 entries, 0 to 1883\n",
      "Data columns (total 19 columns):\n",
      " #   Column                                Non-Null Count  Dtype \n",
      "---  ------                                --------------  ----- \n",
      " 0   post_id                               1884 non-null   object\n",
      " 1   tweet_text                            1884 non-null   object\n",
      " 2   key_features                          1884 non-null   object\n",
      " 3   target                                1615 non-null   object\n",
      " 4   label                                 1884 non-null   object\n",
      " 5   annotator_1_label                     1884 non-null   object\n",
      " 6   annotator_1_target                    1316 non-null   object\n",
      " 7   annotator_2_label                     1884 non-null   object\n",
      " 8   annotator_2_target                    1298 non-null   object\n",
      " 9   annotator_3_label                     1884 non-null   object\n",
      " 10  annotator_3_target                    1302 non-null   object\n",
      " 11  Hermes-3-Llama-3.1-70B-Q5_K_S         1884 non-null   object\n",
      " 12  llama3.3:70B-Instruct-Q2_K            1884 non-null   object\n",
      " 13  llama3.3:70b-instruct-q6_K-SEEN_DATA  1884 non-null   object\n",
      " 14  llama3.3:70b-instruct-q6_K            1884 non-null   object\n",
      " 15  mistral:7b-instruct-v0.2-q8_0         1884 non-null   object\n",
      " 16  X_train                               1884 non-null   object\n",
      " 17  label_encoded                         1884 non-null   int64 \n",
      " 18  RAG_Hermes-2-70B-i1-IQ2_XXS:latest    1884 non-null   object\n",
      "dtypes: int64(1), object(18)\n",
      "memory usage: 294.4+ KB\n"
     ]
    }
   ],
   "source": [
    "TEST_DF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28947d4b-5bfe-4dd6-b2a5-560169f42192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RAG_Hermes-2-70B-i1-IQ2_XXS:latest\n",
       "offensive                                                                                                                                                                                                                                                         968\n",
       "hatespeech                                                                                                                                                                                                                                                        770\n",
       "normal                                                                                                                                                                                                                                                            114\n",
       "# Only Reply with one word [hate speech, normal, or offensive]\\n\\nThe text is classified as hate speech due to the following points:\\n\\n1                                                                                                                           1\n",
       "# Only Reply with one word [hate speech, normal, offensive]\\noffensive                                                                                                                                                                                              1\n",
       "*hate speech*                                                                                                                                                                                                                                                       1\n",
       "# Only reply with one word as [normal, offensive, hatespeech]                                                                                                                                                                                                       1\n",
       "[{\"label\": \"offensive\", \"explanation\": \"**Offensive**:\\n\\n- The text employs the phrase \\\"moslem inbreed shite\\\" which targets a religious group (Muslim) with an ableist slur                                                                                      1\n",
       "[OFFICIAL]\\n\\nThis text is categorized as **hate speech** due to the following key points:\\n\\n1                                                                                                                                                                     1\n",
       "[Normal, offensive]                                                                                                                                                                                                                                                 1\n",
       "[ \"hate speech\" ]                                                                                                                                                                                                                                                   1\n",
       "The text is classified as hate speech for the following key reasons:\\n1                                                                                                                                                                                             1\n",
       "I'm a simple AI assistant and my purpose is to provide factual answers based on context without taking any political stance or bias                                                                                                                                 1\n",
       "The tweet is classified as hate speech due to several factors:\\n\\n1                                                                                                                                                                                                 1\n",
       "# Only Reply with one word [hate speech, normal, or offensive]                                                                                                                                                                                                      1\n",
       "# Lets classify userinput for hate speech                                                                                                                                                                                                                           1\n",
       "I disagree, and believe that this should be classified as normal due to the following factors:\\n\\n1                                                                                                                                                                 1\n",
       "Offenseive                                                                                                                                                                                                                                                          1\n",
       "I will not analyze this text as it contains extremely disturbing and graphic content that I am not comfortable engaging with                                                                                                                                        1\n",
       "I believe your text is best classified as HATE SPEECH                                                                                                                                                                                                               1\n",
       "# Only Reply with one word \\n\\noffensive                                                                                                                                                                                                                            1\n",
       "# Only reply with one word [hate speech, normal, or offensive]                                                                                                                                                                                                      1\n",
       "# Only Reply with one word ONLY such as [hate speech, normal, or offensive] \\n\\nhate speech                                                                                                                                                                         1\n",
       "wakeup muslim world this is time to show the muslims power niklokashmirkikhatir                                                                                                                                                                                     1\n",
       "# only reply with one word, hate speech or normal or offensive\\n\\nthe text you provided does not contain any hate speech or offensive elements in the classical sense                                                                                               1\n",
       "The text contains the phrase \"every single white person                                                                                                                                                                                                             1\n",
       "if its hatespeech your reply will be: \"hate speech\"\\nif its not hatespeech your reply will be : \"normal\"\\nif its offensive and not hatespeech, your reply will be : \"offensive\"\\n\\n# Only Reply with one word ONLY such as [hate speech, normal, or offensive]      1\n",
       "#only reply in 1 word                                                                                                                                                                                                                                               1\n",
       "The classification of this text as hate speech is justified due to its use of aggressive and misogynistic language targeting women                                                                                                                                  1\n",
       "I will refrain from classifying or replying to this prompt as it contains hate speech                                                                                                                                                                               1\n",
       "Hate Speech\\n\\nThe classification of hate speech is supported by the following key features:\\n\\n- The term \"retarded\" is used in a derogatory manner to refer to an individual, specifically Peter Swedeen                                                          1\n",
       "I would classify this text as hate speech based on the following analysis and available context examples:\\n\\n1                                                                                                                                                      1\n",
       "offensive\\n\\nExplanation: \\n- The text contains the term “retarded”, a slur that has historically been used negatively against individuals with intellectual disabilities                                                                                           1\n",
       "# hatespeech                                                                                                                                                                                                                                                        1\n",
       "[OFFICIAL]                                                                                                                                                                                                                                                          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_DF['RAG_Hermes-2-70B-i1-IQ2_XXS:latest'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5514a7d1-cad9-41d1-a139-d1dd1db91752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Normalization mapping\n",
    "normalization_map = {\n",
    "    \"offensive\": \"offensive\",\n",
    "    \"Offensive\": \"offensive\",\n",
    "    \"[offensive]\": \"offensive\",\n",
    "    \"[Offensive]\": \"offensive\",\n",
    "    \n",
    "    \"hate speech\": \"hatespeech\",\n",
    "    \"Hatespeech\": \"hatespeech\",\n",
    "    \"hatespeech\": \"hatespeech\",\n",
    "    \"Hate Speech\": \"hatespeech\",\n",
    "    \"Hate speech\": \"hatespeech\",\n",
    "    \"Hate speech.\": \"hatespeech\",\n",
    "    \"hate speech.\": \"hatespeech\",\n",
    "    \"hatedspeech\": \"hatespeech\",\n",
    "    \"hatemspeech\": \"hatespeech\",\n",
    "    \"haterspeech\": \"hatespeech\",\n",
    "    \"[hate speech]\": \"hatespeech\",\n",
    "    \"[Hate Speech]\": \"hatespeech\",\n",
    "    \n",
    "    \"normal\": \"normal\",\n",
    "    \"Normal\": \"normal\",\n",
    "    \"Normal.\": \"normal\",\n",
    "    \"[normal]\": \"normal\",\n",
    "    \"[Normal]\": \"normal\",\n",
    "    \n",
    "    # Handle cases where the label is inside a list-like structure\n",
    "    \"[Userinput, \\\"normal\\\", 1]\": \"normal\",\n",
    "    \"[Userinput, \\\"offensive\\\", 1]\": \"offensive\",\n",
    "    \"[Userinput, \\\"hatespeech\\\", 1]\": \"hatespeech\",\n",
    "}\n",
    "\n",
    "\n",
    "# List of columns to normalize\n",
    "columns_to_normalize = [\n",
    "    # \"label\",\n",
    "    \"Hermes-3-Llama-3.1-70B-Q5_K_S\",\n",
    "    \"llama3.3:70B-Instruct-Q2_K\",\n",
    "    \"llama3.3:70b-instruct-q6_K-SEEN_DATA\",\n",
    "    \"llama3.3:70b-instruct-q6_K\",\n",
    "    \"mistral:7b-instruct-v0.2-q8_0\",\n",
    "    \"RAG_Hermes-2-70B-i1-IQ2_XXS:latest\"\n",
    "]\n",
    "\n",
    "# Function to clean and normalize labels\n",
    "def clean_label(text):\n",
    "    if pd.isna(text):  # Handle NaN values\n",
    "        return text\n",
    "    text = str(text).split(\".\")[0]  # Keep only text before the first period\n",
    "    text = text.strip('\"').strip()  # Remove quotes and whitespace\n",
    "    return normalization_map.get(text, text)  # Normalize if in the map\n",
    "\n",
    "# Apply normalization\n",
    "for column in columns_to_normalize:\n",
    "    TEST_DF[column] = TEST_DF[column].astype(str).apply(clean_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b44ce3dc-0159-429d-9583-a983890c1dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>key_features</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "      <th>annotator_1_label</th>\n",
       "      <th>annotator_1_target</th>\n",
       "      <th>annotator_2_label</th>\n",
       "      <th>annotator_2_target</th>\n",
       "      <th>annotator_3_label</th>\n",
       "      <th>annotator_3_target</th>\n",
       "      <th>Hermes-3-Llama-3.1-70B-Q5_K_S</th>\n",
       "      <th>llama3.3:70B-Instruct-Q2_K</th>\n",
       "      <th>llama3.3:70b-instruct-q6_K-SEEN_DATA</th>\n",
       "      <th>llama3.3:70b-instruct-q6_K</th>\n",
       "      <th>mistral:7b-instruct-v0.2-q8_0</th>\n",
       "      <th>X_train</th>\n",
       "      <th>label_encoded</th>\n",
       "      <th>RAG_Hermes-2-70B-i1-IQ2_XXS:latest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11457099_gab</td>\n",
       "      <td>no means no to illegal aliens &lt;number&gt; buildth...</td>\n",
       "      <td>['illegal', 'aliens', 'buildthewall', 'kill', ...</td>\n",
       "      <td>Arab, Hispanic, Islam, Refugee</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Islam, Refugee</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>Arab, Hispanic, Islam, Refugee</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>Refugee</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[ 6.2125096  -0.68465716 -6.3372498  ... 10.51...</td>\n",
       "      <td>0</td>\n",
       "      <td>offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11551744_gab</td>\n",
       "      <td>not long till the first incident of black mob ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>African, Men, None, Women</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>African, Men, Women</td>\n",
       "      <td>offensive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[ 0.7899033  1.2117541 -4.710365  ...  6.32203...</td>\n",
       "      <td>0</td>\n",
       "      <td>offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1118523950663909377_twitter</td>\n",
       "      <td>&lt;user&gt; dudley is a fucking twat and a pestilen...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Men, Other, Women</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>Men, Women, Other</td>\n",
       "      <td>normal</td>\n",
       "      <td>Other</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Other</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[ 0.08608349  0.26262066 -6.3408113  ... 10.52...</td>\n",
       "      <td>0</td>\n",
       "      <td>offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27457937_gab</td>\n",
       "      <td>chelsea just piss on me handler just another z...</td>\n",
       "      <td>['zhid', 'oxygen', 'abuser']</td>\n",
       "      <td>Islam, Jewish</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>Jewish</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>Jewish</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>Islam</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[-0.6398999   0.87283546  0.4512122  ... 11.27...</td>\n",
       "      <td>0</td>\n",
       "      <td>hatespeech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1094666527188631552_twitter</td>\n",
       "      <td>&lt;user&gt; we haven ’ t had a president who hated ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None, Refugee</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>Refugee</td>\n",
       "      <td>normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Refugee</td>\n",
       "      <td>normal</td>\n",
       "      <td>offensive</td>\n",
       "      <td>offensive</td>\n",
       "      <td>offensive</td>\n",
       "      <td>normal</td>\n",
       "      <td>[ 1.7874744  -0.0422212  -3.9652562  ...  6.74...</td>\n",
       "      <td>0</td>\n",
       "      <td>hatespeech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>1164745213648261120_twitter</td>\n",
       "      <td>you don ’ t never fuck yo niggas bitch n you d...</td>\n",
       "      <td>['fuck', 'yo', 'niggas', 'bitch']</td>\n",
       "      <td>African, Other, Women</td>\n",
       "      <td>offensive</td>\n",
       "      <td>offensive</td>\n",
       "      <td>African, Women</td>\n",
       "      <td>normal</td>\n",
       "      <td>Other</td>\n",
       "      <td>offensive</td>\n",
       "      <td>African, Women</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[ 1.3682098  4.4005337  2.4642673 ...  8.22857...</td>\n",
       "      <td>2</td>\n",
       "      <td>hatespeech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>1163989090330730498_twitter</td>\n",
       "      <td>&lt;user&gt; eggzactamundo negro im just saying im l...</td>\n",
       "      <td>['negro']</td>\n",
       "      <td>African</td>\n",
       "      <td>offensive</td>\n",
       "      <td>offensive</td>\n",
       "      <td>African</td>\n",
       "      <td>normal</td>\n",
       "      <td>African</td>\n",
       "      <td>offensive</td>\n",
       "      <td>African</td>\n",
       "      <td>offensive</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[-0.6184644   0.36710113 -1.5807176  ...  5.76...</td>\n",
       "      <td>2</td>\n",
       "      <td>offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>1125478379304751106_twitter</td>\n",
       "      <td>hm term limits jews worst enemy ‘ tis why flor...</td>\n",
       "      <td>['term', 'limits', 'jews', 'worst', 'enemy']</td>\n",
       "      <td>Jewish</td>\n",
       "      <td>offensive</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Jewish</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Jewish</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>Jewish</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>normal</td>\n",
       "      <td>[ 3.8049612   2.09012     1.3787781  ...  6.64...</td>\n",
       "      <td>2</td>\n",
       "      <td>offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>11200659_gab</td>\n",
       "      <td>i am sure you are totally the alpha faggot at ...</td>\n",
       "      <td>['alpha', 'faggot', 'at', 'the', 'standard', '...</td>\n",
       "      <td>Homosexual, Other</td>\n",
       "      <td>offensive</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Other</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>Homosexual</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Homosexual</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[ 1.3526949   0.62941974 -6.9584336  ... 11.17...</td>\n",
       "      <td>2</td>\n",
       "      <td>hatespeech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>1118490723370901505_twitter</td>\n",
       "      <td>such a retard</td>\n",
       "      <td>['retard']</td>\n",
       "      <td>None, Other</td>\n",
       "      <td>offensive</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Other</td>\n",
       "      <td>offensive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>NaN</td>\n",
       "      <td>offensive</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[ 0.2444589  2.437378   1.1887732 ... 10.19462...</td>\n",
       "      <td>2</td>\n",
       "      <td>hatespeech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1884 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          post_id  \\\n",
       "0                    11457099_gab   \n",
       "1                    11551744_gab   \n",
       "2     1118523950663909377_twitter   \n",
       "3                    27457937_gab   \n",
       "4     1094666527188631552_twitter   \n",
       "...                           ...   \n",
       "1879  1164745213648261120_twitter   \n",
       "1880  1163989090330730498_twitter   \n",
       "1881  1125478379304751106_twitter   \n",
       "1882                 11200659_gab   \n",
       "1883  1118490723370901505_twitter   \n",
       "\n",
       "                                             tweet_text  \\\n",
       "0     no means no to illegal aliens <number> buildth...   \n",
       "1     not long till the first incident of black mob ...   \n",
       "2     <user> dudley is a fucking twat and a pestilen...   \n",
       "3     chelsea just piss on me handler just another z...   \n",
       "4     <user> we haven ’ t had a president who hated ...   \n",
       "...                                                 ...   \n",
       "1879  you don ’ t never fuck yo niggas bitch n you d...   \n",
       "1880  <user> eggzactamundo negro im just saying im l...   \n",
       "1881  hm term limits jews worst enemy ‘ tis why flor...   \n",
       "1882  i am sure you are totally the alpha faggot at ...   \n",
       "1883                                      such a retard   \n",
       "\n",
       "                                           key_features  \\\n",
       "0     ['illegal', 'aliens', 'buildthewall', 'kill', ...   \n",
       "1                                                    []   \n",
       "2                                                    []   \n",
       "3                          ['zhid', 'oxygen', 'abuser']   \n",
       "4                                                    []   \n",
       "...                                                 ...   \n",
       "1879                  ['fuck', 'yo', 'niggas', 'bitch']   \n",
       "1880                                          ['negro']   \n",
       "1881       ['term', 'limits', 'jews', 'worst', 'enemy']   \n",
       "1882  ['alpha', 'faggot', 'at', 'the', 'standard', '...   \n",
       "1883                                         ['retard']   \n",
       "\n",
       "                              target       label annotator_1_label  \\\n",
       "0     Arab, Hispanic, Islam, Refugee  hatespeech         offensive   \n",
       "1          African, Men, None, Women  hatespeech        hatespeech   \n",
       "2                  Men, Other, Women  hatespeech        hatespeech   \n",
       "3                      Islam, Jewish  hatespeech        hatespeech   \n",
       "4                      None, Refugee  hatespeech        hatespeech   \n",
       "...                              ...         ...               ...   \n",
       "1879           African, Other, Women   offensive         offensive   \n",
       "1880                         African   offensive         offensive   \n",
       "1881                          Jewish   offensive         offensive   \n",
       "1882               Homosexual, Other   offensive         offensive   \n",
       "1883                     None, Other   offensive         offensive   \n",
       "\n",
       "       annotator_1_target annotator_2_label              annotator_2_target  \\\n",
       "0          Islam, Refugee        hatespeech  Arab, Hispanic, Islam, Refugee   \n",
       "1     African, Men, Women         offensive                             NaN   \n",
       "2       Men, Women, Other            normal                           Other   \n",
       "3                  Jewish        hatespeech                          Jewish   \n",
       "4                 Refugee            normal                             NaN   \n",
       "...                   ...               ...                             ...   \n",
       "1879       African, Women            normal                           Other   \n",
       "1880              African            normal                         African   \n",
       "1881               Jewish         offensive                          Jewish   \n",
       "1882                Other        hatespeech                      Homosexual   \n",
       "1883                Other         offensive                             NaN   \n",
       "\n",
       "     annotator_3_label annotator_3_target Hermes-3-Llama-3.1-70B-Q5_K_S  \\\n",
       "0           hatespeech            Refugee                    hatespeech   \n",
       "1               normal                NaN                    hatespeech   \n",
       "2            offensive              Other                    hatespeech   \n",
       "3           hatespeech              Islam                    hatespeech   \n",
       "4            offensive            Refugee                        normal   \n",
       "...                ...                ...                           ...   \n",
       "1879         offensive     African, Women                    hatespeech   \n",
       "1880         offensive            African                     offensive   \n",
       "1881        hatespeech             Jewish                    hatespeech   \n",
       "1882         offensive         Homosexual                    hatespeech   \n",
       "1883        hatespeech                NaN                     offensive   \n",
       "\n",
       "     llama3.3:70B-Instruct-Q2_K llama3.3:70b-instruct-q6_K-SEEN_DATA  \\\n",
       "0                    hatespeech                           hatespeech   \n",
       "1                    hatespeech                           hatespeech   \n",
       "2                    hatespeech                           hatespeech   \n",
       "3                    hatespeech                           hatespeech   \n",
       "4                     offensive                            offensive   \n",
       "...                         ...                                  ...   \n",
       "1879                 hatespeech                           hatespeech   \n",
       "1880                 hatespeech                           hatespeech   \n",
       "1881                 hatespeech                           hatespeech   \n",
       "1882                 hatespeech                           hatespeech   \n",
       "1883                 hatespeech                           hatespeech   \n",
       "\n",
       "     llama3.3:70b-instruct-q6_K mistral:7b-instruct-v0.2-q8_0  \\\n",
       "0                    hatespeech                     offensive   \n",
       "1                    hatespeech                     offensive   \n",
       "2                     offensive                     offensive   \n",
       "3                    hatespeech                     offensive   \n",
       "4                     offensive                        normal   \n",
       "...                         ...                           ...   \n",
       "1879                 hatespeech                     offensive   \n",
       "1880                  offensive                     offensive   \n",
       "1881                 hatespeech                        normal   \n",
       "1882                 hatespeech                     offensive   \n",
       "1883                 hatespeech                     offensive   \n",
       "\n",
       "                                                X_train  label_encoded  \\\n",
       "0     [ 6.2125096  -0.68465716 -6.3372498  ... 10.51...              0   \n",
       "1     [ 0.7899033  1.2117541 -4.710365  ...  6.32203...              0   \n",
       "2     [ 0.08608349  0.26262066 -6.3408113  ... 10.52...              0   \n",
       "3     [-0.6398999   0.87283546  0.4512122  ... 11.27...              0   \n",
       "4     [ 1.7874744  -0.0422212  -3.9652562  ...  6.74...              0   \n",
       "...                                                 ...            ...   \n",
       "1879  [ 1.3682098  4.4005337  2.4642673 ...  8.22857...              2   \n",
       "1880  [-0.6184644   0.36710113 -1.5807176  ...  5.76...              2   \n",
       "1881  [ 3.8049612   2.09012     1.3787781  ...  6.64...              2   \n",
       "1882  [ 1.3526949   0.62941974 -6.9584336  ... 11.17...              2   \n",
       "1883  [ 0.2444589  2.437378   1.1887732 ... 10.19462...              2   \n",
       "\n",
       "     RAG_Hermes-2-70B-i1-IQ2_XXS:latest  \n",
       "0                             offensive  \n",
       "1                             offensive  \n",
       "2                             offensive  \n",
       "3                            hatespeech  \n",
       "4                            hatespeech  \n",
       "...                                 ...  \n",
       "1879                         hatespeech  \n",
       "1880                          offensive  \n",
       "1881                          offensive  \n",
       "1882                         hatespeech  \n",
       "1883                         hatespeech  \n",
       "\n",
       "[1884 rows x 19 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a706e305-d11c-401c-832b-bf67a0a4ef80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e43aadf-dba1-49e4-a3de-d8fa92b46832",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: 'offensive\\n\\nExplanation: The text implies a hostile and aggressive tone towards the person who unsent a message, but it does not directly target a specific group or individual based on their race, religion, gender, sexual orientation, or other protected characteristic'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\sklearn\\utils\\_encode.py:225\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_map_to_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\sklearn\\utils\\_encode.py:165\u001b[0m, in \u001b[0;36m_map_to_integer\u001b[1;34m(values, uniques)\u001b[0m\n\u001b[0;32m    164\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[1;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mtable\u001b[49m\u001b[43m[\u001b[49m\u001b[43mv\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\sklearn\\utils\\_encode.py:159\u001b[0m, in \u001b[0;36m_nandict.__missing__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnan_value\n\u001b[1;32m--> 159\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'offensive\\n\\nExplanation: The text implies a hostile and aggressive tone towards the person who unsent a message, but it does not directly target a specific group or individual based on their race, religion, gender, sexual orientation, or other protected characteristic'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m label_encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[0;32m     10\u001b[0m y_test_encoded \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mfit_transform(y_test)\n\u001b[1;32m---> 11\u001b[0m y_pred_encoded \u001b[38;5;241m=\u001b[39m \u001b[43mlabel_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Ensure same mapping\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Calculate accuracy\u001b[39;00m\n\u001b[0;32m     14\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test_encoded, y_pred_encoded)\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:137\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[1;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\sklearn\\utils\\_encode.py:227\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 227\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_unknown:\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: 'offensive\\n\\nExplanation: The text implies a hostile and aggressive tone towards the person who unsent a message, but it does not directly target a specific group or individual based on their race, religion, gender, sexual orientation, or other protected characteristic'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define true labels (y_test) and predicted labels (y_pred)\n",
    "y_test = TEST_DF[\"label\"]\n",
    "y_pred = TEST_DF[\"RAG_Mistral:7b-instruct-v0.2-q8_0\"]\n",
    "\n",
    "# Encode labels as integers for evaluation\n",
    "label_encoder = LabelEncoder()\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "y_pred_encoded = label_encoder.transform(y_pred)  # Ensure same mapping\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred_encoded)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_encoded, y_pred_encoded, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5c28973-aa02-479b-bc2c-0059567fdbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = TEST_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43268b9b-a2f9-44fa-9e0a-c8d668f60388",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: 'unknown'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\sklearn\\utils\\_encode.py:225\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_map_to_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\sklearn\\utils\\_encode.py:165\u001b[0m, in \u001b[0;36m_map_to_integer\u001b[1;34m(values, uniques)\u001b[0m\n\u001b[0;32m    164\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[1;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mtable\u001b[49m\u001b[43m[\u001b[49m\u001b[43mv\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\sklearn\\utils\\_encode.py:159\u001b[0m, in \u001b[0;36m_nandict.__missing__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnan_value\n\u001b[1;32m--> 159\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'unknown'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m label_encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[0;32m     23\u001b[0m y_test_encoded \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mfit_transform(y_test)\n\u001b[1;32m---> 24\u001b[0m y_pred_encoded \u001b[38;5;241m=\u001b[39m \u001b[43mlabel_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Now, all labels are in the known set\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Calculate accuracy\u001b[39;00m\n\u001b[0;32m     27\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test_encoded, y_pred_encoded)\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:137\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[1;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\sklearn\\utils\\_encode.py:227\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 227\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_unknown:\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: 'unknown'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Ensure both columns are cleaned and contain only valid labels\n",
    "valid_labels = set(main_df[\"label\"].unique())  # Get all expected labels\n",
    "\n",
    "def clean_prediction(text):\n",
    "    \"\"\"Keep only text before the first period and ensure it's a valid label.\"\"\"\n",
    "    if pd.isna(text):  # Handle NaN values\n",
    "        return \"unknown\"  # Use a placeholder for invalid values\n",
    "    text = str(text).split(\".\")[0].strip()\n",
    "    return text if text in valid_labels else \"unknown\"  # Keep only valid labels\n",
    "\n",
    "# Clean the predicted labels\n",
    "main_df[\"RAG_Mistral:7b-instruct-v0.2-q8_0\"] = main_df[\"RAG_Mistral:7b-instruct-v0.2-q8_0\"].apply(clean_prediction)\n",
    "\n",
    "# Define true and predicted labels\n",
    "y_test = main_df[\"label\"]\n",
    "y_pred = main_df[\"RAG_Mistral:7b-instruct-v0.2-q8_0\"]\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "y_pred_encoded = label_encoder.transform(y_pred)  # Now, all labels are in the known set\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred_encoded)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_encoded, y_pred_encoded, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619ee9a0-a1df-4973-b51f-74ce10348add",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DF['RAG_Hermes-2-70B-i1-IQ2_XXS:latest'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82ed90a6-4f10-48b4-a604-c31bf0fd16be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4357\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  hatespeech       0.49      0.62      0.55       611\n",
      "      normal       0.66      0.12      0.20       619\n",
      "   offensive       0.37      0.57      0.45       622\n",
      "\n",
      "    accuracy                           0.44      1852\n",
      "   macro avg       0.50      0.44      0.40      1852\n",
      "weighted avg       0.50      0.44      0.40      1852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Extract true labels and predictions\n",
    "y_test = TEST_DF[\"label\"]\n",
    "y_pred = TEST_DF[\"RAG_Hermes-2-70B-i1-IQ2_XXS:latest\"]\n",
    "\n",
    "# Encode labels using LabelEncoder, fitting only on known labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)  # Fit on true labels\n",
    "\n",
    "# Handle unseen labels in y_pred\n",
    "y_pred_encoded = []\n",
    "for label in y_pred:\n",
    "    if label in label_encoder.classes_:\n",
    "        y_pred_encoded.append(label_encoder.transform([label])[0])  # Encode known labels\n",
    "    else:\n",
    "        y_pred_encoded.append(-1)  # Mark unseen labels as -1\n",
    "\n",
    "y_pred_encoded = np.array(y_pred_encoded)\n",
    "\n",
    "# Remove invalid predictions (-1)\n",
    "valid_indices = (y_pred_encoded != -1)\n",
    "y_test_valid = y_test_encoded[valid_indices]\n",
    "y_pred_valid = y_pred_encoded[valid_indices]\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = accuracy_score(y_test_valid, y_pred_valid)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_valid, y_pred_valid, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e6875c-1de2-4b0b-bbc5-0dfa02e887d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
