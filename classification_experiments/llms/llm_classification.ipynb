{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f50b3cb-a180-415d-a98d-0c04c9ef1b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n",
      "Merges were not in checkpoint, building merges on the fly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "042841fd572c4b32815450f72e9a7c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting and de-quantizing GGUF tensors...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 291/291 [00:47<00:00,  6.18it/s]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"TheBloke/Mistral-7B-Instruct-v0.2-GGUF\"\n",
    "filename = \"mistral-7b-instruct-v0.2.Q8_0.gguf\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, gguf_file=filename)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, gguf_file=filename, device_map=\"auto\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f560b24-14ff-46e9-89c5-5d15b50fbb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: gguf\n",
      "Version: 0.14.0\n",
      "Summary: Read and write ML models in GGUF for GGML\n",
      "Home-page: https://ggml.ai\n",
      "Author: GGML\n",
      "Author-email: ggml@ggml.ai\n",
      "License: \n",
      "Location: C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\n",
      "Requires: numpy, pyyaml, sentencepiece, tqdm\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show gguf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e65f5596-e9d1-471e-8222-218746f9d16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.5.1+cu124\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3-Clause\n",
      "Location: C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, setuptools, sympy, typing-extensions\n",
      "Required-by: sentence-transformers, torchaudio, torchvision\n"
     ]
    }
   ],
   "source": [
    "!pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "007e4ac0-3009-4d32-9db2-b69dfb7e7849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import StoppingCriteria\n",
    "class MyStoppingCriteria(StoppingCriteria):\n",
    "    def __init__(self, target_sequence, prompt):\n",
    "        self.target_sequence = target_sequence\n",
    "        self.prompt=prompt\n",
    "    \n",
    "    def __call__(self, input_ids, scores, **kwargs):\n",
    "        # Get the generated text as a string\n",
    "        generated_text = tokenizer.decode(input_ids[0])\n",
    "        generated_text = generated_text.replace(self.prompt,'')\n",
    "        # Check if the target sequence appears in the generated text\n",
    "        if self.target_sequence in generated_text:\n",
    "            return True  # Stop generation\n",
    "    \n",
    "        return False  # Continue generation\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 1\n",
    "    \n",
    "    def __iter__(self):\n",
    "        yield self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3483cbde-c3ba-4229-bbf3-39362c19466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Lets classify the following text for hate speech.\n",
    "\n",
    "if its hatespeech your reply will be: \"hatespeech\"\n",
    "if its not hatespeech your reply will be : \"normal\"\n",
    "if its offensive and not hatespeech, your reply will be : \"offensive\"\n",
    "\n",
    "User: fuck that nigger\n",
    "Assistant:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0286229-b3fc-42f6-8ba5-f0b023db2ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output 1: \n",
      "Lets classify the following text for hate speech.\n",
      "\n",
      "if its hatespeech your reply will be: \"hatespeech\"\n",
      "if its not hatespeech your reply will be : \"normal\"\n",
      "if its offensive and not hatespeech, your reply will be : \"offensive\"\n",
      "\n",
      "User: i love you\n",
      "Assistant: normal\n",
      "\n",
      "User:\n",
      "CPU times: total: 3.28 s\n",
      "Wall time: 3.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "inputs = tokenizer([prompt], return_tensors=\"pt\").to('cuda')\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=20,\n",
    "    # num_beams=1,\n",
    "    num_return_sequences=1,\n",
    "    return_dict_in_generate=True,\n",
    "    output_scores=True,\n",
    "    stopping_criteria=MyStoppingCriteria(\"User:\", prompt)\n",
    ")\n",
    "\n",
    "# Decode the generated sequences\n",
    "generated_texts = [tokenizer.decode(seq, skip_special_tokens=True) for seq in outputs.sequences]\n",
    "\n",
    "# Print the generated texts\n",
    "for i, text in enumerate(generated_texts, 1):\n",
    "    print(f\"Output {i}: {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f1de016-79ed-4ec7-82be-ece953945125",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2385289802.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"model\": \"llama3.2\",\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "curl http://localhost:11434/api/generate -d '{\n",
    "  \"model\": \"llama3.2\",\n",
    "  \"prompt\": \"Why is the sky blue?\"\n",
    "}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fee3007-c491-488c-8df5-78d045e89d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66510509-52d8-406e-b8f0-aaae16780e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc9c45d0-00fa-4abe-817a-bd2fb899a385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LLM inference function to use later\n",
    "API_URL = \"http://localhost:11434/api/chat\"\n",
    "\n",
    "def llm(model_name, system_prompt, input_query):\n",
    "    # Construct the request payload\n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\"content\": system_prompt, \"role\": \"system\"},\n",
    "            {\"content\": input_query, \"role\": \"user\"}\n",
    "        ],\n",
    "        \"model\": model_name,\n",
    "        \"options\": {}\n",
    "    }\n",
    "    \n",
    "    # Set the request headers\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    # Send the POST request\n",
    "    response = requests.post(API_URL, headers=headers, data=json.dumps(payload))\n",
    "    \n",
    "    # Process the response\n",
    "    if response.status_code == 200:\n",
    "        print(\"Response received successfully:\")\n",
    "        response = response.json() # json.dumps(, indent=4)\n",
    "    else:\n",
    "        print(f\"Failed to retrieve response. Status code: {response.status_code}\")\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "277cf6a5-5784-4f80-bfb7-e2f72701d412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing LLM\n",
    "system_prompt = \"\"\"\n",
    "Lets classify the following text for hate speech.\n",
    "\n",
    "if its hatespeech your reply will be: \"hatespeech\"\n",
    "if its not hatespeech your reply will be : \"normal\"\n",
    "if its offensive and not hatespeech, your reply will be : \"offensive\"\n",
    "\n",
    "Here is user input and reply with only one word\"\"\"\n",
    "input_query = \"i hate black men\"\n",
    "model_name = \"llama3.3:70B-Instruct-Q2_K\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "890a709f-2ed5-419d-a200-4bb786f4f633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response received successfully:\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 2 column 1 (char 141)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\requests\\models.py:963\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;66;03m# Wrong UTF codec detected; usually because it's not UTF-8\u001b[39;00m\n\u001b[0;32m    966\u001b[0m     \u001b[38;5;66;03m# but some other 8-bit codec.  This is an RFC violation,\u001b[39;00m\n\u001b[0;32m    967\u001b[0m     \u001b[38;5;66;03m# and the server didn't bother to tell us what codec *was*\u001b[39;00m\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;66;03m# used.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\simplejson\\__init__.py:514\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, use_decimal, allow_nan, **kw)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    511\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    512\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_decimal \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\simplejson\\decoder.py:389\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w, _PY3)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[1;32m--> 389\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end, \u001b[38;5;28mlen\u001b[39m(s))\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Extra data: line 2 column 1 - line 5 column 1 (char 141 - 740)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:1\u001b[0m\n",
      "Cell \u001b[1;32mIn[5], line 27\u001b[0m, in \u001b[0;36mllm\u001b[1;34m(model_name, system_prompt, input_query)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse received successfully:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# json.dumps(, indent=4)\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to retrieve response. Status code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\requests\\models.py:971\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    969\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    970\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 971\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Extra data: line 2 column 1 (char 141)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "response = llm(model_name, system_prompt, input_query)\n",
    "# explaination = response['response']\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee4b990-1d9b-42a2-b1f1-b35c9e3a4f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12b079fd-348d-4433-946f-ba5c37707a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import json\n",
    "\n",
    "# # Define LLM inference function to use later\n",
    "# API_URL = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "# def llm(model_name, system_prompt, input_query):\n",
    "#     # Construct the request payload\n",
    "#     payload = {\n",
    "#         \"model\": model_name,\n",
    "#         \"prompt\": system_prompt + \"\\n\" + input_query,  # Concatenating system and user prompts\n",
    "#         \"stream\": False  # Use non-streaming response for simplicity\n",
    "#     }\n",
    "    \n",
    "#     # Set the request headers\n",
    "#     headers = {\n",
    "#         \"accept\": \"application/json\",\n",
    "#         \"Content-Type\": \"application/json\"\n",
    "#     }\n",
    "    \n",
    "#     # Send the POST request\n",
    "#     response = requests.post(API_URL, headers=headers, data=json.dumps(payload))\n",
    "    \n",
    "#     # Process the response\n",
    "#     if response.status_code == 200:\n",
    "#         print(\"Response received successfully:\")\n",
    "#         response_data = response.json()\n",
    "#         print(json.dumps(response_data, indent=4))  # Pretty-print the JSON response\n",
    "#         return response_data\n",
    "#     else:\n",
    "#         print(f\"Failed to retrieve response. Status code: {response.status_code}\")\n",
    "#         print(\"Response content:\", response.text)\n",
    "#         return None\n",
    "\n",
    "# # Example usage\n",
    "# model_name = \"mistral:7b-instruct-v0.2-q8_0\"\n",
    "# system_prompt = \"You are a helpful assistant.\"\n",
    "# input_query = \"Why is the sky blue?\"\n",
    "# response = llm(model_name, system_prompt, input_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28666988-2c61-42bd-958e-f2d72948810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de63aa53-8065-43fa-aa1b-97f4a4dae9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/dataset.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d52433c1-32d9-430f-9157-c91b4db64498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>key_features</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "      <th>annotator_1_label</th>\n",
       "      <th>annotator_1_target</th>\n",
       "      <th>annotator_2_label</th>\n",
       "      <th>annotator_2_target</th>\n",
       "      <th>annotator_3_label</th>\n",
       "      <th>annotator_3_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1179055004553900032_twitter</td>\n",
       "      <td>i dont think im getting my baby them white 9 h...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1179063826874032128_twitter</td>\n",
       "      <td>we cannot continue calling ourselves feminists...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1178793830532956161_twitter</td>\n",
       "      <td>nawt yall niggers ignoring me</td>\n",
       "      <td>[]</td>\n",
       "      <td>African, None</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>African</td>\n",
       "      <td>normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1179088797964763136_twitter</td>\n",
       "      <td>&lt;user&gt; i am bit confused coz chinese ppl can n...</td>\n",
       "      <td>['ching', 'chong']</td>\n",
       "      <td>Asian</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>Asian</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Asian</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>Asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1179085312976445440_twitter</td>\n",
       "      <td>this bitch in whataburger eating a burger with...</td>\n",
       "      <td>['bitch', 'i', 'hate', 'white', 'bitches']</td>\n",
       "      <td>Caucasian, Women</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>Caucasian, Women</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>Women, Caucasian</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Women, Caucasian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       post_id  \\\n",
       "0  1179055004553900032_twitter   \n",
       "1  1179063826874032128_twitter   \n",
       "2  1178793830532956161_twitter   \n",
       "3  1179088797964763136_twitter   \n",
       "4  1179085312976445440_twitter   \n",
       "\n",
       "                                          tweet_text  \\\n",
       "0  i dont think im getting my baby them white 9 h...   \n",
       "1  we cannot continue calling ourselves feminists...   \n",
       "2                      nawt yall niggers ignoring me   \n",
       "3  <user> i am bit confused coz chinese ppl can n...   \n",
       "4  this bitch in whataburger eating a burger with...   \n",
       "\n",
       "                                 key_features            target       label  \\\n",
       "0                                          []               NaN      normal   \n",
       "1                                          []               NaN      normal   \n",
       "2                                          []     African, None      normal   \n",
       "3                          ['ching', 'chong']             Asian  hatespeech   \n",
       "4  ['bitch', 'i', 'hate', 'white', 'bitches']  Caucasian, Women  hatespeech   \n",
       "\n",
       "  annotator_1_label annotator_1_target annotator_2_label annotator_2_target  \\\n",
       "0            normal                NaN            normal                NaN   \n",
       "1            normal                NaN            normal                NaN   \n",
       "2            normal            African            normal                NaN   \n",
       "3        hatespeech              Asian         offensive              Asian   \n",
       "4        hatespeech   Caucasian, Women        hatespeech   Women, Caucasian   \n",
       "\n",
       "  annotator_3_label annotator_3_target  \n",
       "0            normal                NaN  \n",
       "1            normal                NaN  \n",
       "2        hatespeech            African  \n",
       "3        hatespeech              Asian  \n",
       "4         offensive   Women, Caucasian  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0b33c6-ec26-46b6-857c-29710314b47a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38296c46-04b5-460b-bb35-ef77666e2276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Define LLM inference function to use later\n",
    "API_URL = \"http://localhost:11434/api/chat\"\n",
    "\n",
    "def llm(model_name, system_prompt, input_query, stream=False):\n",
    "    # Construct the request payload\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": input_query}\n",
    "        ],\n",
    "        \"stream\": stream  # Ensure streaming behavior matches API expectations\n",
    "    }\n",
    "    \n",
    "    # Set the request headers\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Send the POST request\n",
    "        response = requests.post(API_URL, headers=headers, data=json.dumps(payload))\n",
    "        \n",
    "        # Check for errors\n",
    "        if response.status_code == 200:\n",
    "            # print(\"Response received successfully:\")\n",
    "            return response.json()  # Parse JSON response\n",
    "        else:\n",
    "            print(f\"Failed to retrieve response. Status code: {response.status_code}, Details: {response.text}\")\n",
    "            return None\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"An error occurred while connecting to the API: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "##response = llm(\"llama3.3:70B-Instruct-Q2_K\", \"You are a helpful assistant.\", \"Why is the sky blue?\")\n",
    "# print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bcf86ff6-4af6-4377-83e9-8a88ce358dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing LLM\n",
    "system_prompt = \"\"\"\n",
    "Lets classify the following text for hate speech.\n",
    "\n",
    "if its hatespeech your reply will be: \"hate speech\"\n",
    "if its not hatespeech your reply will be : \"normal\"\n",
    "if its offensive and not hatespeech, your reply will be : \"offensive\"\n",
    "\n",
    "Here is user input and reply with only one word ONLY\"\"\"\n",
    "input_query = \"oh my, i think you should do some work on your skin tone\"\n",
    "model_name = \"llama3.3:70b-instruct-q5_K_M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec1db4f7-8975-44b2-b5bf-aca15e1571b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offensive\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 4.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "response = llm(model_name, system_prompt, input_query)\n",
    "# explaination = response['response']\n",
    "print(response['message']['content'].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e115a5-c429-4a44-8187-876f530a537c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c8a218-e184-4410-9b10-9484e698a048",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize tqdm for pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "df[\"mistral\"] = df[\"tweet_text\"].progress_apply(lambda text: llm(model_name, system_prompt, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6439120b-3e91-48e7-b2a1-0b96ba479fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tweets: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20148/20148 [13:52:33<00:00,  2.48s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "mistral_results = []\n",
    "# Loop through the DataFrame with a progress bar\n",
    "for text in tqdm(df['tweet_text'], desc=\"Processing tweets\"):\n",
    "    # Strip spaces from input\n",
    "    input_query = text\n",
    "    # Get the LLM response\n",
    "    response = llm(model_name, system_prompt, input_query)\n",
    "    # Extract and strip the response content\n",
    "    processed_content = response[\"message\"][\"content\"].strip()\n",
    "    # Append the processed content to the results list\n",
    "    mistral_results.append(processed_content)\n",
    "\n",
    "# Add the results to a new column in the DataFrame\n",
    "df[\"mistral\"] = mistral_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "257992f9-6f37-43ca-8472-b1955bd799a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"dataset_classification_with_mistral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34a9aa63-7d46-4569-8b77-e78e839e72ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2724\n",
      "\n",
      "Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assign true labels and predicted labels\n",
    "y_test = df[\"label\"]\n",
    "y_pred = df[\"mistral\"]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1195180-9ba4-457c-b2e2-b81fa0294c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d60b788b-74c3-48d8-a994-583a724f9aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mistral\n",
       "offensive                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             7895\n",
       "normal                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                3379\n",
       "hate speech                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            195\n",
       "hatespeech                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              80\n",
       "hate speech.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            23\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ... \n",
       "Hatespeech. This text contains racial slurs and a call for violence, which is a clear violation of hate speech policies.                                                                                                                                                                                                                                                                                                                                                                                                                                                 1\n",
       "offensive. The statement contains derogatory language towards various ethnic groups, but it does not meet the criteria for hate speech as it does not advocate for violence or harm against any specific group. However, the use of offensive language is still unacceptable and should be avoided in polite conversation.                                                                                                                                                                                                                                               1\n",
       "offensive\\n\\nIt's important to note that reporting threatening behavior or harassment is a serious matter and should be taken seriously. However, in this context, the user's language could be perceived as offensive due to its tone and use of strong language. The specific mention of a person being Muslim does not automatically make the statement hate speech, but it is understandable why the user may have felt threatened based on the situation described. Regardless, such behavior should not be condoned or encouraged on social media platforms.       1\n",
       "hate speech. This text contains multiple slurs directed towards Jewish people, which constitutes hate speech.                                                                                                                                                                                                                                                                                                                                                                                                                                                            1\n",
       "hate speech.\\n\\nIt contains explicit and derogatory references to ethnicity and religion, which is a form of hate speech. It's important to note that such language is harmful and offensive, and it's crucial to avoid using such language or promoting it in any way.                                                                                                                                                                                                                                                                                                  1\n",
       "Name: count, Length: 8490, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"mistral\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c40b7e3d-a94f-4851-b8fc-7ebb69ba7fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"mistral_cleaned\"] = df[\"mistral\"].str.split('[.\\n(]', n=1).str[0].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22b4c3b0-70fa-4790-b8a8-da55f372a344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "normal        8153\n",
       "hatespeech    6234\n",
       "offensive     5761\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7daa7a86-0d36-4093-b6bd-5068cf3d49a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mistral_cleaned\n",
       "offensive                                                                                                                                                                                                        14285\n",
       "normal                                                                                                                                                                                                            4155\n",
       "hate speech                                                                                                                                                                                                       1431\n",
       "Hatespeech                                                                                                                                                                                                         122\n",
       "hatespeech                                                                                                                                                                                                         109\n",
       "hatedspeech                                                                                                                                                                                                          7\n",
       "Offensive                                                                                                                                                                                                            5\n",
       "haterspeech                                                                                                                                                                                                          3\n",
       "I will do my best to classify the text based on the given instructions                                                                                                                                               3\n",
       "hatemspeech                                                                                                                                                                                                          2\n",
       "I understand your instruction, but it's important to note that the absence of a specific word does not necessarily mean the text is not hate speech                                                                  1\n",
       "It is difficult to determine the context of the phrase \"kenyun paki at <number>\" without additional information                                                                                                      1\n",
       "This text contains potentially triggering and graphic content related to sexual violence, which is not appropriate for a public platform                                                                             1\n",
       "I cannot see the user input or the screenshots you mentioned                                                                                                                                                         1\n",
       "Understood                                                                                                                                                                                                           1\n",
       "I'm an artificial intelligence language model and don't have the ability to classify text based on hate speech or scrape user data                                                                                   1\n",
       "I understand the instructions                                                                                                                                                                                        1\n",
       "It is not possible for me to classify the text provided as I do not have access to the specific user input you are referring to                                                                                      1\n",
       "The text itself does not contain any hate speech or offensive language related to the given topic                                                                                                                    1\n",
       "I cannot classify the text without knowing what it actually says                                                                                                                                                     1\n",
       "I will make my best effort to classify the text accurately based on the given guidelines                                                                                                                             1\n",
       "I will do my best to classify the text based on your instructions                                                                                                                                                    1\n",
       "I cannot classify the text without knowing what the text is                                                                                                                                                          1\n",
       "offensive 🚫                                                                                                                                                                                                          1\n",
       "I cannot comply with that request as it goes against ethical and moral standards, and may be considered offensive or inappropriate                                                                                   1\n",
       "I cannot determine if the following text is hate speech, offensive, or normal based on the given context                                                                                                             1\n",
       "I will not provide a single-word response as requested, but instead, I'll offer a detailed explanation                                                                                                               1\n",
       "If the text contains hate speech against Muslims, my reply will be: \"hatespeech\"                                                                                                                                     1\n",
       "This statement is not hate speech                                                                                                                                                                                    1\n",
       "The two given situations are not directly comparable                                                                                                                                                                 1\n",
       "It is important to note that context is crucial when determining if a text contains hate speech                                                                                                                      1\n",
       "It is not possible to determine if the user said that specific phrase based on the given context                                                                                                                     1\n",
       "I cannot determine if the given text contains hate speech or not based on the provided context                                                                                                                       1\n",
       "If the text contains hate speech towards a specific group or individual based on their race, religion, gender, sexual orientation, or any other protected characteristic, then the reply will be \"hatespeech\"        1\n",
       "I'm an artificial intelligence and don't have the ability to classify text as hate speech without analyzing the content                                                                                              1\n",
       "I cannot classify the text without seeing it first                                                                                                                                                                   1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"mistral_cleaned\"].value_counts().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32d00861-8619-4f3d-a5e5-88d1959e92b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mistral_normalized\n",
       "offensive                                                                                                                                                                                                        14290\n",
       "normal                                                                                                                                                                                                            4155\n",
       "hatespeech                                                                                                                                                                                                        1672\n",
       "I will do my best to classify the text based on the given instructions                                                                                                                                               3\n",
       "hatemspeech                                                                                                                                                                                                          2\n",
       "It is difficult to determine the context of the phrase \"kenyun paki at <number>\" without additional information                                                                                                      1\n",
       "I understand your instruction, but it's important to note that the absence of a specific word does not necessarily mean the text is not hate speech                                                                  1\n",
       "I cannot see the user input or the screenshots you mentioned                                                                                                                                                         1\n",
       "This text contains potentially triggering and graphic content related to sexual violence, which is not appropriate for a public platform                                                                             1\n",
       "Understood                                                                                                                                                                                                           1\n",
       "I'm an artificial intelligence language model and don't have the ability to classify text based on hate speech or scrape user data                                                                                   1\n",
       "I understand the instructions                                                                                                                                                                                        1\n",
       "It is not possible for me to classify the text provided as I do not have access to the specific user input you are referring to                                                                                      1\n",
       "The text itself does not contain any hate speech or offensive language related to the given topic                                                                                                                    1\n",
       "I cannot classify the text without knowing what it actually says                                                                                                                                                     1\n",
       "I will make my best effort to classify the text accurately based on the given guidelines                                                                                                                             1\n",
       "I will do my best to classify the text based on your instructions                                                                                                                                                    1\n",
       "I cannot classify the text without knowing what the text is                                                                                                                                                          1\n",
       "offensive 🚫                                                                                                                                                                                                          1\n",
       "I cannot comply with that request as it goes against ethical and moral standards, and may be considered offensive or inappropriate                                                                                   1\n",
       "I cannot determine if the following text is hate speech, offensive, or normal based on the given context                                                                                                             1\n",
       "I will not provide a single-word response as requested, but instead, I'll offer a detailed explanation                                                                                                               1\n",
       "If the text contains hate speech against Muslims, my reply will be: \"hatespeech\"                                                                                                                                     1\n",
       "This statement is not hate speech                                                                                                                                                                                    1\n",
       "The two given situations are not directly comparable                                                                                                                                                                 1\n",
       "It is important to note that context is crucial when determining if a text contains hate speech                                                                                                                      1\n",
       "It is not possible to determine if the user said that specific phrase based on the given context                                                                                                                     1\n",
       "I cannot determine if the given text contains hate speech or not based on the provided context                                                                                                                       1\n",
       "If the text contains hate speech towards a specific group or individual based on their race, religion, gender, sexual orientation, or any other protected characteristic, then the reply will be \"hatespeech\"        1\n",
       "I'm an artificial intelligence and don't have the ability to classify text as hate speech without analyzing the content                                                                                              1\n",
       "I cannot classify the text without seeing it first                                                                                                                                                                   1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalization_map = {\n",
    "    \"offensive\": \"offensive\",\n",
    "    \"Offensive\": \"offensive\",\n",
    "    \"hate speech\": \"hatespeech\",\n",
    "    \"Hatespeech\": \"hatespeech\",\n",
    "    \"hatespeech\": \"hatespeech\",\n",
    "    \"hatedspeech\": \"hatespeech\",\n",
    "    \"haterspeech\": \"hatespeech\",\n",
    "    \"normal\": \"normal\",\n",
    "    \"Normal\": \"normal\"\n",
    "}\n",
    "df[\"mistral_normalized\"] = df[\"mistral_cleaned\"].replace(normalization_map)\n",
    "# Normalize the 'mistral_cleaned' column\n",
    "# df[\"mistral_normalized\"] = df[\"mistral_cleaned\"].str.lower().map(normalization_map).fillna(\"hatespeech\")\n",
    "\n",
    "# Display value counts for the normalized column\n",
    "df[\"mistral_normalized\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "127e42b0-a7c8-44f2-a19c-e16490fd4812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4453\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  hatespeech       0.75      0.20      0.32      6234\n",
      "      normal       0.73      0.37      0.49      8153\n",
      "   offensive       0.33      0.81      0.47      5761\n",
      "\n",
      "    accuracy                           0.45     20148\n",
      "   macro avg       0.60      0.46      0.43     20148\n",
      "weighted avg       0.62      0.45      0.43     20148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assign true labels and predicted labels\n",
    "y_test = df[\"label\"]\n",
    "y_pred = df[\"mistral_normalized\"]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "101f79d8-6b66-4f37-b291-ae51cdc66526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4452\n",
      "\n",
      "Classification Report:\n",
      "                                                                                                                                                                                                               precision    recall  f1-score   support\n",
      "\n",
      "                                                                                                                                             I cannot classify the text without knowing what it actually says       0.00      0.00      0.00         0\n",
      "                                                                                                                                                  I cannot classify the text without knowing what the text is       0.00      0.00      0.00         0\n",
      "                                                                                                                                                           I cannot classify the text without seeing it first       0.00      0.00      0.00         0\n",
      "                                                                           I cannot comply with that request as it goes against ethical and moral standards, and may be considered offensive or inappropriate       0.00      0.00      0.00         0\n",
      "                                                                                                     I cannot determine if the following text is hate speech, offensive, or normal based on the given context       0.00      0.00      0.00         0\n",
      "                                                                                                               I cannot determine if the given text contains hate speech or not based on the provided context       0.00      0.00      0.00         0\n",
      "                                                                                                                                                 I cannot see the user input or the screenshots you mentioned       0.00      0.00      0.00         0\n",
      "                                                                                                                                                                                I understand the instructions       0.00      0.00      0.00         0\n",
      "                                                          I understand your instruction, but it's important to note that the absence of a specific word does not necessarily mean the text is not hate speech       0.00      0.00      0.00         0\n",
      "                                                                                                                                       I will do my best to classify the text based on the given instructions       0.00      0.00      0.00         0\n",
      "                                                                                                                                            I will do my best to classify the text based on your instructions       0.00      0.00      0.00         0\n",
      "                                                                                                                     I will make my best effort to classify the text accurately based on the given guidelines       0.00      0.00      0.00         0\n",
      "                                                                                                       I will not provide a single-word response as requested, but instead, I'll offer a detailed explanation       0.00      0.00      0.00         0\n",
      "                                                                                      I'm an artificial intelligence and don't have the ability to classify text as hate speech without analyzing the content       0.00      0.00      0.00         0\n",
      "                                                                           I'm an artificial intelligence language model and don't have the ability to classify text based on hate speech or scrape user data       0.00      0.00      0.00         0\n",
      "                                                                                                                             If the text contains hate speech against Muslims, my reply will be: \"hatespeech\"       0.00      0.00      0.00         0\n",
      "If the text contains hate speech towards a specific group or individual based on their race, religion, gender, sexual orientation, or any other protected characteristic, then the reply will be \"hatespeech\"       0.00      0.00      0.00         0\n",
      "                                                                                              It is difficult to determine the context of the phrase \"kenyun paki at <number>\" without additional information       0.00      0.00      0.00         0\n",
      "                                                                                                              It is important to note that context is crucial when determining if a text contains hate speech       0.00      0.00      0.00         0\n",
      "                                                                              It is not possible for me to classify the text provided as I do not have access to the specific user input you are referring to       0.00      0.00      0.00         0\n",
      "                                                                                                             It is not possible to determine if the user said that specific phrase based on the given context       0.00      0.00      0.00         0\n",
      "                                                                                                            The text itself does not contain any hate speech or offensive language related to the given topic       0.00      0.00      0.00         0\n",
      "                                                                                                                                                         The two given situations are not directly comparable       0.00      0.00      0.00         0\n",
      "                                                                                                                                                                            This statement is not hate speech       0.00      0.00      0.00         0\n",
      "                                                                     This text contains potentially triggering and graphic content related to sexual violence, which is not appropriate for a public platform       0.00      0.00      0.00         0\n",
      "                                                                                                                                                                                                   Understood       0.00      0.00      0.00         0\n",
      "                                                                                                                                                                                                  hatemspeech       0.00      0.00      0.00         0\n",
      "                                                                                                                                                                                                   hatespeech       0.76      0.20      0.32      6234\n",
      "                                                                                                                                                                                                       normal       0.73      0.37      0.49      8153\n",
      "                                                                                                                                                                                                    offensive       0.33      0.81      0.47      5761\n",
      "                                                                                                                                                                                                  offensive 🚫       0.00      0.00      0.00         0\n",
      "\n",
      "                                                                                                                                                                                                     accuracy                           0.45     20148\n",
      "                                                                                                                                                                                                    macro avg       0.06      0.04      0.04     20148\n",
      "                                                                                                                                                                                                 weighted avg       0.62      0.45      0.43     20148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assign true labels and predicted labels\n",
    "y_test = df[\"label\"]\n",
    "y_pred = df[\"mistral_normalized\"]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a0d65ff3-3ee0-44ed-bf39-a1520ff1347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LLM inference function to use later\n",
    "API_URL = \"https://inf.cl.uni-trier.de/chat/\"\n",
    "\n",
    "def llm(model_name, system_prompt, input_query):\n",
    "    # Construct the request payload\n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\"content\": system_prompt, \"role\": \"system\"},\n",
    "            {\"content\": input_query, \"role\": \"user\"}\n",
    "        ],\n",
    "        \"model\": model_name,\n",
    "        \"options\": {}\n",
    "    }\n",
    "    \n",
    "    # Set the request headers\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    # Send the POST request\n",
    "    response = requests.post(API_URL, headers=headers, data=json.dumps(payload))\n",
    "    \n",
    "    # Process the response\n",
    "    if response.status_code == 200:\n",
    "        print(\"Response received successfully:\")\n",
    "        response = response.json() # json.dumps(, indent=4)\n",
    "    else:\n",
    "        print(f\"Failed to retrieve response. Status code: {response.status_code}\")\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "95170c4f-6dfa-4b20-a2a4-b824020d70b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing LLM\n",
    "system_prompt = \"\"\"\n",
    "Lets classify the following text for hate speech.\n",
    "\n",
    "if its hatespeech your reply will be: \"hate speech\"\n",
    "if its not hatespeech your reply will be : \"normal\"\n",
    "if its offensive and not hatespeech, your reply will be : \"offensive\"\n",
    "\n",
    "Here is user input and reply with only one word ONLY\"\"\"\n",
    "input_query = \"i hate your black daughter\"\n",
    "model_name = \"llama3.3:70B-Instruct-Q2_K\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a69ab90b-5554-435e-a504-56cae573bcb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 2.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "response = llm(model_name, system_prompt, input_query)\n",
    "# explaination = response['response']\n",
    "# print(response['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a744e4-20f5-40de-a79b-948b84bcc11b",
   "metadata": {},
   "source": [
    "## llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0690297a-e2f9-4207-af3d-be65ba77929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# os.chdir('..')\n",
    "df = pd.read_csv(\"C:\\\\MachineLearning\\\\UniTrier\\\\RCS\\\\twon-hate-speech-detection\\\\Data\\\\dataset.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f8d3e54-414c-4ee8-a7fc-28c113ce3efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Define LLM inference function to use later\n",
    "API_URL = \"http://localhost:11434/api/chat\"\n",
    "\n",
    "def llm(model_name, system_prompt, input_query, stream=False):\n",
    "    # Construct the request payload\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": input_query}\n",
    "        ],\n",
    "        \"stream\": stream  # Ensure streaming behavior matches API expectations\n",
    "    }\n",
    "    \n",
    "    # Set the request headers\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Send the POST request\n",
    "        response = requests.post(API_URL, headers=headers, data=json.dumps(payload))\n",
    "        \n",
    "        # Check for errors\n",
    "        if response.status_code == 200:\n",
    "            # print(\"Response received successfully:\")\n",
    "            return response.json()  # Parse JSON response\n",
    "        else:\n",
    "            print(f\"Failed to retrieve response. Status code: {response.status_code}, Details: {response.text}\")\n",
    "            return None\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"An error occurred while connecting to the API: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c50a08be-a682-4a3c-8cf3-0a5f25669b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing LLM\n",
    "system_prompt = \"\"\"\n",
    "Lets classify the following text for hate speech.\n",
    "\n",
    "if its hatespeech your reply will be: \"hate speech\"\n",
    "if its not hatespeech your reply will be : \"normal\"\n",
    "if its offensive and not hatespeech, your reply will be : \"offensive\"\n",
    "\n",
    "Here is user input and reply with only one word ONLY\"\"\"\n",
    "input_query = \"oh my, i think you should do some work on your skin tone\"\n",
    "model_name = \"llama3.3:70b-instruct-q5_K_M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a71f817-6853-4a6d-a7f5-7c40328e5a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4914ae44-f771-497a-a066-857101f95918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>key_features</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "      <th>annotator_1_label</th>\n",
       "      <th>annotator_1_target</th>\n",
       "      <th>annotator_2_label</th>\n",
       "      <th>annotator_2_target</th>\n",
       "      <th>annotator_3_label</th>\n",
       "      <th>annotator_3_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1179055004553900032_twitter</td>\n",
       "      <td>i dont think im getting my baby them white 9 h...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1179063826874032128_twitter</td>\n",
       "      <td>we cannot continue calling ourselves feminists...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1178793830532956161_twitter</td>\n",
       "      <td>nawt yall niggers ignoring me</td>\n",
       "      <td>[]</td>\n",
       "      <td>African, None</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>African</td>\n",
       "      <td>normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1179088797964763136_twitter</td>\n",
       "      <td>&lt;user&gt; i am bit confused coz chinese ppl can n...</td>\n",
       "      <td>['ching', 'chong']</td>\n",
       "      <td>Asian</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>Asian</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Asian</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>Asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1179085312976445440_twitter</td>\n",
       "      <td>this bitch in whataburger eating a burger with...</td>\n",
       "      <td>['bitch', 'i', 'hate', 'white', 'bitches']</td>\n",
       "      <td>Caucasian, Women</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>Caucasian, Women</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>Women, Caucasian</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Women, Caucasian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       post_id  \\\n",
       "0  1179055004553900032_twitter   \n",
       "1  1179063826874032128_twitter   \n",
       "2  1178793830532956161_twitter   \n",
       "3  1179088797964763136_twitter   \n",
       "4  1179085312976445440_twitter   \n",
       "\n",
       "                                          tweet_text  \\\n",
       "0  i dont think im getting my baby them white 9 h...   \n",
       "1  we cannot continue calling ourselves feminists...   \n",
       "2                      nawt yall niggers ignoring me   \n",
       "3  <user> i am bit confused coz chinese ppl can n...   \n",
       "4  this bitch in whataburger eating a burger with...   \n",
       "\n",
       "                                 key_features            target       label  \\\n",
       "0                                          []               NaN      normal   \n",
       "1                                          []               NaN      normal   \n",
       "2                                          []     African, None      normal   \n",
       "3                          ['ching', 'chong']             Asian  hatespeech   \n",
       "4  ['bitch', 'i', 'hate', 'white', 'bitches']  Caucasian, Women  hatespeech   \n",
       "\n",
       "  annotator_1_label annotator_1_target annotator_2_label annotator_2_target  \\\n",
       "0            normal                NaN            normal                NaN   \n",
       "1            normal                NaN            normal                NaN   \n",
       "2            normal            African            normal                NaN   \n",
       "3        hatespeech              Asian         offensive              Asian   \n",
       "4        hatespeech   Caucasian, Women        hatespeech   Women, Caucasian   \n",
       "\n",
       "  annotator_3_label annotator_3_target  \n",
       "0            normal                NaN  \n",
       "1            normal                NaN  \n",
       "2        hatespeech            African  \n",
       "3        hatespeech              Asian  \n",
       "4         offensive   Women, Caucasian  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b327a81-a20e-419b-bde4-5202c780e191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "llama_results = []\n",
    "# Loop through the DataFrame with a progress bar\n",
    "for text in tqdm(df['tweet_text'], desc=\"Processing tweets\"):\n",
    "    # Strip spaces from input\n",
    "    input_query = text\n",
    "    # Get the LLM response\n",
    "    response = llm(model_name, system_prompt, input_query)\n",
    "    # Extract and strip the response content\n",
    "    processed_content = response[\"message\"][\"content\"].strip()\n",
    "    # Append the processed content to the results list\n",
    "    llama_results.append(processed_content)\n",
    "\n",
    "# Add the results to a new column in the DataFrame\n",
    "df[\"llama\"] = llama_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03becd44-e192-4677-8b4a-87e1fad038bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Data/dataset_classification_with_llama_Q5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78864e0c-416d-4d7f-b70a-b1ce60bc5443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4464"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(llama_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a79e3946-03a1-4882-bfe8-273dde542c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df[\"llama_Q5\"] = np.nan\n",
    "df[\"llama_Q5\"] = df[\"llama_Q5\"].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c075c39-9a26-471f-8e82-085936021d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:len(llama_results) - 1, \"llama_Q5\"] = llama_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04371a6d-5b50-49de-b2d1-439d6b3272d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llama_Q5\n",
       "hate speech                                                                                                                                                                                                                                                 2888\n",
       "offensive                                                                                                                                                                                                                                                    846\n",
       "normal                                                                                                                                                                                                                                                       724\n",
       "I cannot classify hate speech. Can I help you with something else?                                                                                                                                                                                             3\n",
       "I cannot classify the given text as it contains racial slurs. Can I help you with anything else?                                                                                                                                                               1\n",
       "I can't classify hate speech. Is there anything else I can help you with?                                                                                                                                                                                      1\n",
       "I cannot classify this text as anything other than hate speech. The use of the N-word is a racial slur that is highly offensive and has a long history of being used to demean and dehumanize Black people. Is there something else I can help you with?       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"llama_Q5\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d42f1b79-9006-4cba-82b8-0eb91aef46ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "post_id                   0\n",
       "tweet_text                0\n",
       "key_features              0\n",
       "target                 3918\n",
       "label                     0\n",
       "annotator_1_label         0\n",
       "annotator_1_target     7127\n",
       "annotator_2_label         0\n",
       "annotator_2_target     6997\n",
       "annotator_3_label         0\n",
       "annotator_3_target     7068\n",
       "llama_Q5              15684\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a84f9d31-2c2f-4db5-a13c-52f74bf729f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"dataset_classification_with_llama_Q5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0222948-2e43-40e8-9b7e-1bf4964a0b38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
