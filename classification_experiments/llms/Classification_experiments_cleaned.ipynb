{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe888f54-7859-42f8-8d86-de23e5e726f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5d2dadbb-9dff-4acd-aecd-f131d81bcb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the main dataset\n",
    "main_df = pd.read_csv(\"dataset.csv\", index_col=0)\n",
    "\n",
    "# Load and process dataset_classification_with_hermes.csv\n",
    "df_hermes = pd.read_csv(\"dataset_classification_with_hermes.csv\")\n",
    "df_hermes.rename(columns={\"llama\": \"Hermes-3-Llama-3.1-70B-Q5_K_S\"}, inplace=True)\n",
    "\n",
    "# Load and process dataset_classification_with_llama.csv\n",
    "df_llama = pd.read_csv(\"dataset_classification_with_llama.csv\")\n",
    "df_llama.rename(columns={\"llama\": \"llama3.3:70B-Instruct-Q2_K\"}, inplace=True)\n",
    "\n",
    "# Load and process dataset_classification_with_llama_Q6.csv\n",
    "df_llama_q6 = pd.read_csv(\"dataset_classification_with_llama_Q6.csv\")\n",
    "df_llama_q6.rename(columns={\n",
    "    \"llama_aman\": \"llama3.3:70b-instruct-q6_K-SEEN_DATA\",\n",
    "    \"llama_Q6\": \"llama3.3:70b-instruct-q6_K\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Keep only the renamed columns in df_llama_q6\n",
    "df_llama_q6 = df_llama_q6[[\"llama3.3:70b-instruct-q6_K-SEEN_DATA\", \"llama3.3:70b-instruct-q6_K\"]]\n",
    "\n",
    "# Load and process dataset_classification_with_mistral.csv\n",
    "df_mistral = pd.read_csv(\"dataset_classification_with_mistral.csv\")\n",
    "df_mistral.rename(columns={\"mistral_cleaned\": \"mistral:7b-instruct-v0.2-q8_0\"}, inplace=True)\n",
    "\n",
    "# Merge datasets with the main dataset in the specified order\n",
    "main_df = main_df.join(df_hermes[\"Hermes-3-Llama-3.1-70B-Q5_K_S\"], how=\"left\")\n",
    "main_df = main_df.join(df_llama[\"llama3.3:70B-Instruct-Q2_K\"], how=\"left\")\n",
    "main_df = main_df.join(df_llama_q6, how=\"left\")\n",
    "main_df = main_df.join(df_mistral[\"mistral:7b-instruct-v0.2-q8_0\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "359b7749-7056-431f-8515-6e3f89092eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 20148 entries, 0 to 20147\n",
      "Data columns (total 16 columns):\n",
      " #   Column                                Non-Null Count  Dtype \n",
      "---  ------                                --------------  ----- \n",
      " 0   post_id                               20148 non-null  object\n",
      " 1   tweet_text                            20148 non-null  object\n",
      " 2   key_features                          20148 non-null  object\n",
      " 3   target                                16230 non-null  object\n",
      " 4   label                                 20148 non-null  object\n",
      " 5   annotator_1_label                     20148 non-null  object\n",
      " 6   annotator_1_target                    13021 non-null  object\n",
      " 7   annotator_2_label                     20148 non-null  object\n",
      " 8   annotator_2_target                    13151 non-null  object\n",
      " 9   annotator_3_label                     20148 non-null  object\n",
      " 10  annotator_3_target                    13080 non-null  object\n",
      " 11  Hermes-3-Llama-3.1-70B-Q5_K_S         20148 non-null  object\n",
      " 12  llama3.3:70B-Instruct-Q2_K            20148 non-null  object\n",
      " 13  llama3.3:70b-instruct-q6_K-SEEN_DATA  20148 non-null  object\n",
      " 14  llama3.3:70b-instruct-q6_K            20148 non-null  object\n",
      " 15  mistral:7b-instruct-v0.2-q8_0         20148 non-null  object\n",
      "dtypes: object(16)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "main_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3fccc13a-029f-4a84-a50d-6a27396896f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    \"annotator_1_label\", \"annotator_1_target\",\n",
    "    \"annotator_2_label\", \"annotator_2_target\",\n",
    "    \"annotator_3_label\", \"annotator_3_target\"\n",
    "]\n",
    "\n",
    "# Drop the specified columns\n",
    "main_df = main_df.drop(columns=columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "52249f34-f7cc-4db5-9285-f5baf7adc058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>key_features</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "      <th>Hermes-3-Llama-3.1-70B-Q5_K_S</th>\n",
       "      <th>llama3.3:70B-Instruct-Q2_K</th>\n",
       "      <th>llama3.3:70b-instruct-q6_K-SEEN_DATA</th>\n",
       "      <th>llama3.3:70b-instruct-q6_K</th>\n",
       "      <th>mistral:7b-instruct-v0.2-q8_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1179055004553900032_twitter</td>\n",
       "      <td>i dont think im getting my baby them white 9 h...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1179063826874032128_twitter</td>\n",
       "      <td>we cannot continue calling ourselves feminists...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1178793830532956161_twitter</td>\n",
       "      <td>nawt yall niggers ignoring me</td>\n",
       "      <td>[]</td>\n",
       "      <td>African, None</td>\n",
       "      <td>normal</td>\n",
       "      <td>hate speech</td>\n",
       "      <td>hate speech</td>\n",
       "      <td>hate speech</td>\n",
       "      <td>hate speech</td>\n",
       "      <td>offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1179088797964763136_twitter</td>\n",
       "      <td>&lt;user&gt; i am bit confused coz chinese ppl can n...</td>\n",
       "      <td>['ching', 'chong']</td>\n",
       "      <td>Asian</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>hate speech</td>\n",
       "      <td>Hate speech</td>\n",
       "      <td>hate speech</td>\n",
       "      <td>offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1179085312976445440_twitter</td>\n",
       "      <td>this bitch in whataburger eating a burger with...</td>\n",
       "      <td>['bitch', 'i', 'hate', 'white', 'bitches']</td>\n",
       "      <td>Caucasian, Women</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hate speech</td>\n",
       "      <td>hate speech</td>\n",
       "      <td>Hate Speech</td>\n",
       "      <td>hate speech</td>\n",
       "      <td>offensive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       post_id  \\\n",
       "0  1179055004553900032_twitter   \n",
       "1  1179063826874032128_twitter   \n",
       "2  1178793830532956161_twitter   \n",
       "3  1179088797964763136_twitter   \n",
       "4  1179085312976445440_twitter   \n",
       "\n",
       "                                          tweet_text  \\\n",
       "0  i dont think im getting my baby them white 9 h...   \n",
       "1  we cannot continue calling ourselves feminists...   \n",
       "2                      nawt yall niggers ignoring me   \n",
       "3  <user> i am bit confused coz chinese ppl can n...   \n",
       "4  this bitch in whataburger eating a burger with...   \n",
       "\n",
       "                                 key_features            target       label  \\\n",
       "0                                          []               NaN      normal   \n",
       "1                                          []               NaN      normal   \n",
       "2                                          []     African, None      normal   \n",
       "3                          ['ching', 'chong']             Asian  hatespeech   \n",
       "4  ['bitch', 'i', 'hate', 'white', 'bitches']  Caucasian, Women  hatespeech   \n",
       "\n",
       "  Hermes-3-Llama-3.1-70B-Q5_K_S llama3.3:70B-Instruct-Q2_K  \\\n",
       "0                     offensive                     Normal   \n",
       "1                        normal                     normal   \n",
       "2                   hate speech                hate speech   \n",
       "3                     offensive                hate speech   \n",
       "4                   hate speech                hate speech   \n",
       "\n",
       "  llama3.3:70b-instruct-q6_K-SEEN_DATA llama3.3:70b-instruct-q6_K  \\\n",
       "0                               Normal                     normal   \n",
       "1                               normal                     normal   \n",
       "2                          hate speech                hate speech   \n",
       "3                          Hate speech                hate speech   \n",
       "4                          Hate Speech                hate speech   \n",
       "\n",
       "  mistral:7b-instruct-v0.2-q8_0  \n",
       "0                        normal  \n",
       "1                     offensive  \n",
       "2                     offensive  \n",
       "3                     offensive  \n",
       "4                     offensive  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "955f4f53-5057-46d9-a6db-d54ef63df152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize labels for all models and the label column\n",
    "normalization_map = {\n",
    "    \"offensive\": \"offensive\",\n",
    "    \"Offensive\": \"offensive\",\n",
    "    \"hate speech\": \"hatespeech\",\n",
    "    \"Hatespeech\": \"hatespeech\",\n",
    "    \"hatespeech\": \"hatespeech\",\n",
    "    \"Hate Speech\": \"hatespeech\",\n",
    "    \"Hate speech\": \"hatespeech\",\n",
    "    \"normal\": \"normal\",\n",
    "    \"Normal\": \"normal\",\n",
    "    \"Normal.\": \"normal\",\n",
    "    \"Hate speech.\": \"hatespeech\",\n",
    "    \"hate speech.\": \"hatespeech\",\n",
    "    \"hatedspeech\": \"hatespeech\",\n",
    "    \"hatemspeech\": \"hatespeech\",\n",
    "    \"haterspeech\": \"hatespeech\",\n",
    "}\n",
    "\n",
    "columns_to_normalize = [\n",
    "    \"label\",\n",
    "    \"Hermes-3-Llama-3.1-70B-Q5_K_S\",\n",
    "    \"llama3.3:70B-Instruct-Q2_K\",\n",
    "    \"llama3.3:70b-instruct-q6_K-SEEN_DATA\",\n",
    "    \"llama3.3:70b-instruct-q6_K\",\n",
    "    \"mistral:7b-instruct-v0.2-q8_0\"\n",
    "]\n",
    "\n",
    "for column in columns_to_normalize:\n",
    "    main_df[column] = main_df[column].str.strip('\"').replace(normalization_map)\n",
    "    main_df[column] = main_df[column].replace(normalization_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "17f63d96-d35d-4af9-b339-027b2d1d38ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if data is clean and normalized\n",
    "# for column in columns_to_normalize:\n",
    "#     print(f\"Value counts for {column}:\")\n",
    "#     print(main_df[column].value_counts().head(6))\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "50865ca1-9b11-4e9e-ad52-640c890d5847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Hermes-3-Llama-3.1-70B-Q5_K_S: 50.47%\n",
      "Accuracy for llama3.3:70B-Instruct-Q2_K: 43.48%\n",
      "Accuracy for llama3.3:70b-instruct-q6_K-SEEN_DATA: 43.15%\n",
      "Accuracy for llama3.3:70b-instruct-q6_K: 49.32%\n",
      "Accuracy for mistral:7b-instruct-v0.2-q8_0: 44.52%\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print accuracy for each model\n",
    "label_column = \"label\"\n",
    "models = [\n",
    "    \"Hermes-3-Llama-3.1-70B-Q5_K_S\",\n",
    "    \"llama3.3:70B-Instruct-Q2_K\",\n",
    "    \"llama3.3:70b-instruct-q6_K-SEEN_DATA\",\n",
    "    \"llama3.3:70b-instruct-q6_K\",\n",
    "    \"mistral:7b-instruct-v0.2-q8_0\"\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    accuracy = (main_df[label_column] == main_df[model]).mean() * 100\n",
    "    print(f\"Accuracy for {model}: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8660c406-f6e6-4b49-9706-34dbf305f6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load using pickle\n",
    "with open(\"C:\\\\MachineLearning\\\\UniTrier\\\\RCS\\\\dataset_mit_embeddings_sfr.pkl\", \"rb\") as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1ae24b1a-027e-43c8-8089-e64d82c9c7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = main_df.join(df[\"X_train\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ea2f9649-c545-477d-97b7-20c0053d1281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 20148 entries, 0 to 20147\n",
      "Data columns (total 11 columns):\n",
      " #   Column                                Non-Null Count  Dtype \n",
      "---  ------                                --------------  ----- \n",
      " 0   post_id                               20148 non-null  object\n",
      " 1   tweet_text                            20148 non-null  object\n",
      " 2   key_features                          20148 non-null  object\n",
      " 3   target                                16230 non-null  object\n",
      " 4   label                                 20148 non-null  object\n",
      " 5   Hermes-3-Llama-3.1-70B-Q5_K_S         20148 non-null  object\n",
      " 6   llama3.3:70B-Instruct-Q2_K            20148 non-null  object\n",
      " 7   llama3.3:70b-instruct-q6_K-SEEN_DATA  20148 non-null  object\n",
      " 8   llama3.3:70b-instruct-q6_K            20148 non-null  object\n",
      " 9   mistral:7b-instruct-v0.2-q8_0         20148 non-null  object\n",
      " 10  X_train                               20148 non-null  object\n",
      "dtypes: object(11)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "main_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "10a913b4-f5f2-46a7-a8b0-d8ed0cfab21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "47520229-0def-43f7-a5d3-2a2b227c4171",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [10:58:12] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6531\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  hatespeech       0.73      0.73      0.73      1285\n",
      "      normal       0.66      0.77      0.71      1610\n",
      "   offensive       0.52      0.40      0.45      1135\n",
      "\n",
      "    accuracy                           0.65      4030\n",
      "   macro avg       0.64      0.63      0.63      4030\n",
      "weighted avg       0.64      0.65      0.64      4030\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['label_encoded'] = label_encoder.fit_transform(df['label'])\n",
    "\n",
    "# Convert 'X_train' column to a list of embeddings\n",
    "X = df['X_train'].tolist()\n",
    "y = df['label_encoded'].tolist()\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective='multi:softmax',  # Use 'multi:softmax' for multi-class classification\n",
    "    num_class=len(label_encoder.classes_),  # Number of classes\n",
    "    eval_metric='mlogloss',  # Multi-class log loss\n",
    "    use_label_encoder=False  # Avoid warnings about label encoding\n",
    ")\n",
    "\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "38d5dbf5-a1ef-4a75-b91d-aedee1627478",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:14:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.6531\n",
      "\n",
      "XGBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  hatespeech       0.73      0.73      0.73      1285\n",
      "      normal       0.66      0.77      0.71      1610\n",
      "   offensive       0.52      0.40      0.45      1135\n",
      "\n",
      "    accuracy                           0.65      4030\n",
      "   macro avg       0.64      0.63      0.63      4030\n",
      "weighted avg       0.64      0.65      0.64      4030\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: 'confused'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\sklearn\\utils\\_encode.py:225\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_map_to_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\sklearn\\utils\\_encode.py:165\u001b[0m, in \u001b[0;36m_map_to_integer\u001b[1;34m(values, uniques)\u001b[0m\n\u001b[0;32m    164\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[1;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mtable\u001b[49m\u001b[43m[\u001b[49m\u001b[43mv\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\sklearn\\utils\\_encode.py:159\u001b[0m, in \u001b[0;36m_nandict.__missing__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnan_value\n\u001b[1;32m--> 159\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'confused'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 57\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Convert string predictions from other classifiers to label-encoded integers\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m other_classifier_columns:\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Label encode the predicted string values\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     y_pred_other \u001b[38;5;241m=\u001b[39m \u001b[43mlabel_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTEST_DF\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# Accuracy for this classifier's predictions\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     accuracy_other \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred_other)\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:137\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[1;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\sklearn\\utils\\_encode.py:227\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 227\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_unknown:\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: 'confused'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming `df` is your main DataFrame\n",
    "\n",
    "# Step 1: Train-test split (whole dataset)\n",
    "TRAIN_DF, TEST_DF = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Prepare the labels (encoded labels for classification)\n",
    "label_encoder = LabelEncoder()\n",
    "TRAIN_DF['label_encoded'] = label_encoder.fit_transform(TRAIN_DF['label'])\n",
    "TEST_DF['label_encoded'] = label_encoder.transform(TEST_DF['label'])\n",
    "\n",
    "# Step 3: Convert 'X_train' column to a list of embeddings\n",
    "X_train = TRAIN_DF['X_train'].tolist()\n",
    "X_test = TEST_DF['X_train'].tolist()\n",
    "y_train = TRAIN_DF['label_encoded'].tolist()\n",
    "y_test = TEST_DF['label_encoded'].tolist()\n",
    "\n",
    "# Step 4: Initialize and train XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective='multi:softmax',  # Use 'multi:softmax' for multi-class classification\n",
    "    num_class=len(label_encoder.classes_),  # Number of classes\n",
    "    eval_metric='mlogloss',  # Multi-class log loss\n",
    "    use_label_encoder=False  # Avoid warnings about label encoding\n",
    ")\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Make predictions with XGBoost\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Step 6: Evaluate the XGBoost model\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost Accuracy: {accuracy_xgb:.4f}\")\n",
    "\n",
    "# Detailed classification report for XGBoost\n",
    "print(\"\\nXGBoost Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb, target_names=label_encoder.classes_))\n",
    "\n",
    "# Step 7: Evaluate other classifiers' predictions against 'label'\n",
    "other_classifier_columns = [\n",
    "    \"Hermes-3-Llama-3.1-70B-Q5_K_S\",\n",
    "    \"llama3.3:70B-Instruct-Q2_K\",\n",
    "    \"llama3.3:70b-instruct-q6_K-SEEN_DATA\",\n",
    "    \"llama3.3:70b-instruct-q6_K\",\n",
    "    \"mistral:7b-instruct-v0.2-q8_0\"\n",
    "]\n",
    "\n",
    "# Convert string predictions from other classifiers to label-encoded integers\n",
    "for column in other_classifier_columns:\n",
    "    # Label encode the predicted string values\n",
    "    y_pred_other = label_encoder.transform(TEST_DF[column].astype(str))\n",
    "\n",
    "    # Accuracy for this classifier's predictions\n",
    "    accuracy_other = accuracy_score(y_test, y_pred_other)\n",
    "    print(f\"\\nAccuracy for {column}: {accuracy_other:.4f}\")\n",
    "\n",
    "    # Detailed classification report for each other classifier\n",
    "    print(f\"\\n{column} Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred_other, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "aa0a7b30-3f23-4615-b4db-7e94a4c860f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for Hermes-3-Llama-3.1-70B-Q5_K_S: 0.5062\n",
      "\n",
      "Hermes-3-Llama-3.1-70B-Q5_K_S Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  hatespeech       0.48      0.89      0.62      1285\n",
      "      normal       0.76      0.38      0.50      1608\n",
      "   offensive       0.34      0.26      0.30      1135\n",
      "\n",
      "    accuracy                           0.51      4028\n",
      "   macro avg       0.53      0.51      0.47      4028\n",
      "weighted avg       0.55      0.51      0.48      4028\n",
      "\n",
      "\n",
      "Accuracy for llama3.3:70B-Instruct-Q2_K: 0.4461\n",
      "\n",
      "llama3.3:70B-Instruct-Q2_K Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  hatespeech       0.42      0.95      0.58      1284\n",
      "      normal       0.88      0.23      0.36      1609\n",
      "   offensive       0.31      0.19      0.23      1135\n",
      "\n",
      "    accuracy                           0.45      4028\n",
      "   macro avg       0.53      0.45      0.39      4028\n",
      "weighted avg       0.57      0.45      0.39      4028\n",
      "\n",
      "\n",
      "Accuracy for llama3.3:70b-instruct-q6_K-SEEN_DATA: 0.4355\n",
      "\n",
      "llama3.3:70b-instruct-q6_K-SEEN_DATA Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  hatespeech       0.43      0.98      0.59      1285\n",
      "      normal       0.93      0.22      0.36      1610\n",
      "   offensive       0.20      0.12      0.15      1135\n",
      "\n",
      "    accuracy                           0.44      4030\n",
      "   macro avg       0.52      0.44      0.37      4030\n",
      "weighted avg       0.56      0.44      0.37      4030\n",
      "\n",
      "\n",
      "Accuracy for llama3.3:70b-instruct-q6_K: 0.4998\n",
      "\n",
      "llama3.3:70b-instruct-q6_K Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  hatespeech       0.48      0.96      0.64      1285\n",
      "      normal       0.91      0.27      0.42      1610\n",
      "   offensive       0.35      0.30      0.32      1135\n",
      "\n",
      "    accuracy                           0.50      4030\n",
      "   macro avg       0.58      0.51      0.46      4030\n",
      "weighted avg       0.61      0.50      0.46      4030\n",
      "\n",
      "\n",
      "Accuracy for mistral:7b-instruct-v0.2-q8_0: 0.4458\n",
      "\n",
      "mistral:7b-instruct-v0.2-q8_0 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  hatespeech       0.74      0.21      0.32      1284\n",
      "      normal       0.73      0.38      0.50      1605\n",
      "   offensive       0.33      0.82      0.47      1133\n",
      "\n",
      "    accuracy                           0.45      4022\n",
      "   macro avg       0.60      0.47      0.43      4022\n",
      "weighted avg       0.62      0.45      0.43      4022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert string predictions from other classifiers to label-encoded integers\n",
    "for column in other_classifier_columns:\n",
    "    # Initialize a list to hold the valid label-encoded predictions\n",
    "    y_pred_other = []\n",
    "\n",
    "    for pred in TEST_DF[column].astype(str):\n",
    "        try:\n",
    "            # Try to transform the prediction into an encoded label\n",
    "            y_pred_other.append(label_encoder.transform([pred])[0])\n",
    "        except ValueError:\n",
    "            # Handle unseen label: treat it as a default value (e.g., -1)\n",
    "            y_pred_other.append(-1)\n",
    "\n",
    "    y_pred_other = np.array(y_pred_other)\n",
    "\n",
    "    # Remove the '-1' values (unseen labels) from both y_pred_other and y_test\n",
    "    valid_indices = (y_pred_other != -1) & (y_test != -1)\n",
    "    y_pred_other_valid = y_pred_other[valid_indices]\n",
    "    y_test_valid = np.array(y_test)[valid_indices]\n",
    "\n",
    "    # Accuracy for this classifier's predictions\n",
    "    accuracy_other = accuracy_score(y_test_valid, y_pred_other_valid)\n",
    "    print(f\"\\nAccuracy for {column}: {accuracy_other:.4f}\")\n",
    "\n",
    "    # Detailed classification report for each other classifier\n",
    "    print(f\"\\n{column} Classification Report:\")\n",
    "    print(classification_report(y_test_valid, y_pred_other_valid, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3587d1b9-7a35-4c1b-917f-a59274781c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa02ad89-aff3-402b-ae9c-6df7fa3ec3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9330cb-91cc-45ba-9034-49a7f5b62bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "14a6df6a-461c-49a6-ab6c-f48fef28ac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df['label_encoded'] = label_encoder.fit_transform(main_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "15a8a776-6ad5-4662-9205-9eae817b8ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = main_df.drop(columns=['post_id', 'tweet_text', 'key_features', 'target', 'label'])\n",
    "y = main_df['label_encoded']\n",
    "\n",
    "# Train-test split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "780e0899-70d0-4fd7-bcd7-8dc82be632e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 16118 entries, 2394 to 15795\n",
      "Data columns (total 7 columns):\n",
      " #   Column                                Non-Null Count  Dtype \n",
      "---  ------                                --------------  ----- \n",
      " 0   Hermes-3-Llama-3.1-70B-Q5_K_S         16118 non-null  object\n",
      " 1   llama3.3:70B-Instruct-Q2_K            16118 non-null  object\n",
      " 2   llama3.3:70b-instruct-q6_K-SEEN_DATA  16118 non-null  object\n",
      " 3   llama3.3:70b-instruct-q6_K            16118 non-null  object\n",
      " 4   mistral:7b-instruct-v0.2-q8_0         16118 non-null  object\n",
      " 5   X_train                               16118 non-null  object\n",
      " 6   label_encoded                         16118 non-null  int64 \n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 1007.4+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "23d09bb6-94ff-4d27-a76c-0228159a74cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in training data: 20148\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END ...............eta=0.05, max_depth=5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...............eta=0.05, max_depth=5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...............eta=0.05, max_depth=5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...............eta=0.05, max_depth=5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...............eta=0.05, max_depth=5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...............eta=0.05, max_depth=6;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...............eta=0.05, max_depth=6;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...............eta=0.05, max_depth=6;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...............eta=0.05, max_depth=6;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...............eta=0.05, max_depth=6;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...............eta=0.05, max_depth=7;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...............eta=0.05, max_depth=7;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...............eta=0.05, max_depth=7;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...............eta=0.05, max_depth=7;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...............eta=0.05, max_depth=7;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...............eta=0.05, max_depth=8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...............eta=0.05, max_depth=8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...............eta=0.05, max_depth=8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...............eta=0.05, max_depth=8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...............eta=0.05, max_depth=8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ................eta=0.1, max_depth=5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ................eta=0.1, max_depth=5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ................eta=0.1, max_depth=5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ................eta=0.1, max_depth=5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ................eta=0.1, max_depth=5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ................eta=0.1, max_depth=6;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ................eta=0.1, max_depth=6;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ................eta=0.1, max_depth=6;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ................eta=0.1, max_depth=6;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ................eta=0.1, max_depth=6;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ................eta=0.1, max_depth=7;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ................eta=0.1, max_depth=7;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ................eta=0.1, max_depth=7;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ................eta=0.1, max_depth=7;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ................eta=0.1, max_depth=7;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ................eta=0.1, max_depth=8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ................eta=0.1, max_depth=8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ................eta=0.1, max_depth=8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ................eta=0.1, max_depth=8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ................eta=0.1, max_depth=8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END eta=0.15000000000000002, max_depth=5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END eta=0.15000000000000002, max_depth=5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END eta=0.15000000000000002, max_depth=5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END eta=0.15000000000000002, max_depth=5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END eta=0.15000000000000002, max_depth=5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END eta=0.15000000000000002, max_depth=6;, score=nan total time=   0.0s\n",
      "[CV 2/5] END eta=0.15000000000000002, max_depth=6;, score=nan total time=   0.0s\n",
      "[CV 3/5] END eta=0.15000000000000002, max_depth=6;, score=nan total time=   0.0s\n",
      "[CV 4/5] END eta=0.15000000000000002, max_depth=6;, score=nan total time=   0.0s\n",
      "[CV 5/5] END eta=0.15000000000000002, max_depth=6;, score=nan total time=   0.0s\n",
      "[CV 1/5] END eta=0.15000000000000002, max_depth=7;, score=nan total time=   0.0s\n",
      "[CV 2/5] END eta=0.15000000000000002, max_depth=7;, score=nan total time=   0.0s\n",
      "[CV 3/5] END eta=0.15000000000000002, max_depth=7;, score=nan total time=   0.0s\n",
      "[CV 4/5] END eta=0.15000000000000002, max_depth=7;, score=nan total time=   0.0s\n",
      "[CV 5/5] END eta=0.15000000000000002, max_depth=7;, score=nan total time=   0.0s\n",
      "[CV 1/5] END eta=0.15000000000000002, max_depth=8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END eta=0.15000000000000002, max_depth=8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END eta=0.15000000000000002, max_depth=8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END eta=0.15000000000000002, max_depth=8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END eta=0.15000000000000002, max_depth=8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ................eta=0.2, max_depth=5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ................eta=0.2, max_depth=5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ................eta=0.2, max_depth=5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ................eta=0.2, max_depth=5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ................eta=0.2, max_depth=5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ................eta=0.2, max_depth=6;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ................eta=0.2, max_depth=6;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ................eta=0.2, max_depth=6;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ................eta=0.2, max_depth=6;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ................eta=0.2, max_depth=6;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ................eta=0.2, max_depth=7;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ................eta=0.2, max_depth=7;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ................eta=0.2, max_depth=7;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ................eta=0.2, max_depth=7;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ................eta=0.2, max_depth=7;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ................eta=0.2, max_depth=8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ................eta=0.2, max_depth=8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ................eta=0.2, max_depth=8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ................eta=0.2, max_depth=8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ................eta=0.2, max_depth=8;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...............eta=0.25, max_depth=5;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...............eta=0.25, max_depth=5;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...............eta=0.25, max_depth=5;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...............eta=0.25, max_depth=5;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...............eta=0.25, max_depth=5;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...............eta=0.25, max_depth=6;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...............eta=0.25, max_depth=6;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...............eta=0.25, max_depth=6;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...............eta=0.25, max_depth=6;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...............eta=0.25, max_depth=6;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...............eta=0.25, max_depth=7;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...............eta=0.25, max_depth=7;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...............eta=0.25, max_depth=7;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...............eta=0.25, max_depth=7;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...............eta=0.25, max_depth=7;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...............eta=0.25, max_depth=8;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...............eta=0.25, max_depth=8;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...............eta=0.25, max_depth=8;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...............eta=0.25, max_depth=8;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...............eta=0.25, max_depth=8;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 100 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n20 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1491, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [   0    1    2 ... 1233 1234 1235], got [   0    1    2 ... 1382 1383 1384]\n\n--------------------------------------------------------------------------------\n20 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1491, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [   0    1    2 ... 1232 1233 1234], got [   0    1    2 ... 1382 1383 1384]\n\n--------------------------------------------------------------------------------\n20 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1491, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [   0    1    2 ... 1225 1226 1227], got [   0    1    2 ... 1382 1383 1384]\n\n--------------------------------------------------------------------------------\n20 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1491, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [   0    1    2 ... 1210 1211 1212], got [   0    1    2 ... 1382 1383 1384]\n\n--------------------------------------------------------------------------------\n20 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1491, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [   0    1    2 ... 1228 1229 1230], got [   0    1    2 ... 1382 1383 1384]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 57\u001b[0m\n\u001b[0;32m     54\u001b[0m X \u001b[38;5;241m=\u001b[39m main_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_train\u001b[39m\u001b[38;5;124m'\u001b[39m]]  \u001b[38;5;66;03m# Use the embeddings as the features\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m final_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Make predictions on test data\u001b[39;00m\n\u001b[0;32m     60\u001b[0m y_preds \u001b[38;5;241m=\u001b[39m final_model\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "Cell \u001b[1;32mIn[73], line 30\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(data, labels)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Perform hyperparameter tuning using GridSearchCV\u001b[39;00m\n\u001b[0;32m     28\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mxgb_clf, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     29\u001b[0m                            cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Get the best hyperparameters\u001b[39;00m\n\u001b[0;32m     33\u001b[0m best_max_depth \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:996\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    994\u001b[0m     )\n\u001b[1;32m--> 996\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    999\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32mC:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m     )\n\u001b[1;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    539\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 100 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n20 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1491, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [   0    1    2 ... 1233 1234 1235], got [   0    1    2 ... 1382 1383 1384]\n\n--------------------------------------------------------------------------------\n20 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1491, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [   0    1    2 ... 1232 1233 1234], got [   0    1    2 ... 1382 1383 1384]\n\n--------------------------------------------------------------------------------\n20 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1491, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [   0    1    2 ... 1225 1226 1227], got [   0    1    2 ... 1382 1383 1384]\n\n--------------------------------------------------------------------------------\n20 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1491, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [   0    1    2 ... 1210 1211 1212], got [   0    1    2 ... 1382 1383 1384]\n\n--------------------------------------------------------------------------------\n20 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1491, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [   0    1    2 ... 1228 1229 1230], got [   0    1    2 ... 1382 1383 1384]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def train_model(data: pd.DataFrame, labels: pd.Series):\n",
    "    if torch.cuda.is_available():\n",
    "        boost_device = \"cuda\"\n",
    "    else:\n",
    "        boost_device = \"cpu\"\n",
    "\n",
    "    # Initialize the XGBoost Classifier\n",
    "    xgb_clf = xgb.XGBClassifier(objective=\"binary:logistic\",\n",
    "                                device=boost_device,\n",
    "                                random_state=3137)\n",
    "\n",
    "    # Define hyperparameters and values to tune\n",
    "    param_grid = {\n",
    "        'max_depth': [5, 6, 7, 8],\n",
    "        'eta': np.arange(0.05, 0.3, 0.05)\n",
    "    }\n",
    "\n",
    "    print(f\"Number of rows in training data: {len(data)}\")\n",
    "\n",
    "    # Perform hyperparameter tuning using GridSearchCV\n",
    "    grid_search = GridSearchCV(estimator=xgb_clf, param_grid=param_grid, scoring=\"roc_auc\",\n",
    "                               cv=5, verbose=3)\n",
    "    grid_search.fit(data, labels)\n",
    "\n",
    "    # Get the best hyperparameters\n",
    "    best_max_depth = grid_search.best_params_['max_depth']\n",
    "    best_eta = grid_search.best_params_['eta']\n",
    "\n",
    "    final_xgb_clf = xgb.XGBClassifier(objective=\"binary:logistic\",\n",
    "                                      max_depth=best_max_depth,\n",
    "                                      eta=best_eta,\n",
    "                                      device=boost_device,\n",
    "                                      random_state=3137)\n",
    "    final_xgb_clf.fit(data, labels)\n",
    "\n",
    "    return final_xgb_clf\n",
    "\n",
    "# Ensure the target is numeric\n",
    "y = main_df['label_encoded']\n",
    "\n",
    "# If 'target' is categorical (strings), convert it to numeric labels\n",
    "if y.dtypes == 'object':  \n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "\n",
    "# Use the embeddings (ensure they are numeric)\n",
    "X = main_df[['X_train']]  # Use the embeddings as the features\n",
    "\n",
    "# Train the model\n",
    "final_model = train_model(X, y)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_preds = final_model.predict(X)\n",
    "\n",
    "# Accuracy of the model\n",
    "accuracy = accuracy_score(y, y_preds)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f9e7cf-4cc4-4f3c-8027-b6fc027e5d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d978c7-2666-457b-b70b-796d35368bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
