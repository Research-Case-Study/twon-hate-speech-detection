{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6087bd88-bbfc-4cf5-966e-bb52a9833d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "962c4b51-c400-4bb4-9ee3-35016b8b55c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Change to the parent directory of the notebook\n",
    "os.chdir('..')\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8096e498-b531-4112-a5fb-e84ad2b8e99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DF = pd.read_csv(\"Data/TRAIN_DF.csv\", index_col=0)\n",
    "TEST_DF = pd.read_csv(\"Data/TEST_DF.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3df122c8-2218-4dd4-9839-e98ea4168174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "normal        4287\n",
       "hatespeech    3409\n",
       "offensive     1304\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DF['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "747b0745-f483-46b9-b311-6073c82d13c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into DataFrames\n",
    "hermes_rag_df = pd.read_csv(\"classification_experiments/rag/classified_test_df_Hermes-2_Q5_top4.csv\", index_col=0)\n",
    "mistral_rag_df = pd.read_csv(\"classification_experiments/rag/classified_test_df_mistral_7b_q8_top4.csv\", index_col=0)\n",
    "llama_rag_df = pd.read_csv(\"classification_experiments/rag/classified_test_df_llama-3.3_70b_Q6_top4.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6a12cf-36fb-4595-b2a2-10b0b35b68fb",
   "metadata": {},
   "source": [
    "hermes_rag_df : RAG_Hermes-3-Llama-3.1-70B-Q5_K_S:latest\n",
    "mistral_rag_df : RAG_mistral:7b-instruct-v0.2-q8_0\n",
    "llama_rag_df : RAG_llama3.3:70b-instruct-q6_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e2e3e840-9a6c-44e7-9309-f139fd5421fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DF = TEST_DF.merge(hermes_rag_df, how='left')\n",
    "TEST_DF = TEST_DF.merge(mistral_rag_df, how='left')\n",
    "TEST_DF = TEST_DF.merge(llama_rag_df, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd89b91-5615-4521-8836-dd3ea862526c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "41c457d8-46d2-4678-a885-ed1a1e2ba821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load using pickle\n",
    "with open(\"C:\\\\MachineLearning\\\\UniTrier\\\\RCS\\\\dataset_mit_embeddings_sfr.pkl\", \"rb\") as f:\n",
    "    embeddings_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "552ef12f-5d91-42d2-b989-930401138df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DF = TRAIN_DF.join(embeddings_df[\"X_train\"], how=\"left\", rsuffix=\"_emb\")\n",
    "TEST_DF = TEST_DF.join(embeddings_df[\"X_train\"], how=\"left\", rsuffix=\"_emb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5feace4c-955b-45c8-bded-16d269cc0710",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_map = {\n",
    "    \"offensive\": \"offensive\",\n",
    "    \"Offensive\": \"offensive\",\n",
    "    \"[offensive]\": \"offensive\",\n",
    "    \"[Offensive]\": \"offensive\",\n",
    "    \"<assistant> offensitive\": \"offensive\",\n",
    "    \"offensive.\": \"offensive\",\n",
    "    \n",
    "    \"hate speech\": \"hatespeech\",\n",
    "    \"Hatespeech\": \"hatespeech\",\n",
    "    \"hate speech\"\n",
    "    \"hatespeech\": \"hatespeech\",\n",
    "    \"Hate Speech\": \"hatespeech\",\n",
    "    \"Hate speech\": \"hatespeech\",\n",
    "    \"Hate speech.\": \"hatespeech\",\n",
    "    \"hate speech.\": \"hatespeech\",\n",
    "    \"hatedspeech\": \"hatespeech\",\n",
    "    \"hatemspeech\": \"hatespeech\",\n",
    "    \"haterspeech\": \"hatespeech\",\n",
    "    \"[hate speech]\": \"hatespeech\",\n",
    "    \"[Hate Speech]\": \"hatespeech\",\n",
    "    \"<hate speech>\": \"hatespeech\",\n",
    "    \"'hatespeech'\": \"hatespeech\",\n",
    "    \"hatredspeech\": \"hatespeech\",\n",
    "    \n",
    "    \"normal\": \"normal\",\n",
    "    \"Normal\": \"normal\",\n",
    "    \"Normal.\": \"normal\",\n",
    "    \"[normal]\": \"normal\",\n",
    "    \"[Normal]\": \"normal\",\n",
    "    \n",
    "    # Handle cases where the label is inside a list-like structure\n",
    "    \"[Userinput, \\\"normal\\\", 1]\": \"normal\",\n",
    "    \"[Userinput, \\\"offensive\\\", 1]\": \"offensive\",\n",
    "    \"[Userinput, \\\"hatespeech\\\", 1]\": \"hatespeech\",\n",
    "}\n",
    "\n",
    "\n",
    "columns_to_normalize = [\n",
    "    \"label\",\n",
    "    \"Hermes-3-Llama-3.1-70B-Q5_K_S\",\n",
    "    \"llama3.3:70B-Instruct-Q2_K\",\n",
    "    \"llama3.3:70b-instruct-q6_K-SEEN_DATA\",\n",
    "    \"llama3.3:70b-instruct-q6_K\",\n",
    "    \"mistral:7b-instruct-v0.2-q8_0\",\n",
    "\n",
    "    \"RAG_llama3.3:70b-instruct-q6_K\",\n",
    "    \"RAG_mistral:7b-instruct-v0.2-q8_0\",\n",
    "    \"RAG_llama3.3:70b-instruct-q6_K\",\n",
    "]\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):  # Ensure it's a string before applying regex\n",
    "        # return re.split(r'[.\\n]', text, 1)[0].strip()  # Keep only the part before the first \".\" or \"\\n\"\n",
    "        return re.split(r'[.\\n\"]|\\s*\\(', text, 1)[0].strip()  # Split at \".\", \"\\n\", or \" (\" and keep the first part\n",
    "    return text\n",
    "    \n",
    "for column in columns_to_normalize:\n",
    "    TEST_DF[column] = TEST_DF[column].str.strip('\"').str.strip().apply(clean_text)\n",
    "    TEST_DF[column] = TEST_DF[column].replace(normalization_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5d54a315-3bfe-4bb2-94ea-e4816d756722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RAG_llama3.3:70b-instruct-q6_K\n",
       "hatespeech    420\n",
       "offensive     344\n",
       "normal        166\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_DF[columns_to_normalize[8]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "62b27a4f-324c-45fe-b1ab-a65a0ddf084d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [-3.8870854, 5.516928, 1.5130757, -0.4188277, ...\n",
       "1       [0.5292801, 1.2109683, -0.64650404, 2.0842671,...\n",
       "2       [1.5791895, -0.32219458, 0.5753123, 1.6588185,...\n",
       "3       [4.513079, -1.212101, -0.9618452, -1.1730635, ...\n",
       "4       [3.9823904, -1.1007478, 0.04596758, 3.8737075,...\n",
       "                              ...                        \n",
       "8995    [-0.35139227, 3.5876145, -3.2650406, 3.1035538...\n",
       "8996    [-4.0064135, 4.1975603, -0.6081386, 1.9110469,...\n",
       "8997    [4.365764, 0.40833455, -0.82745516, -0.1222669...\n",
       "8998    [7.199881, 2.5057359, 5.326466, 0.2398137, 2.4...\n",
       "8999    [3.3631604, 1.5252637, -2.2813034, -3.4720714,...\n",
       "Name: X_train_emb, Length: 9000, dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DF['X_train_emb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4f617a-eae9-4cde-ba35-a2c49f4524a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c4966ba4-e13f-4d2d-bc3c-23b16c5e0edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "hatespeech    1304\n",
      "normal        1304\n",
      "offensive     1304\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usama\\AppData\\Local\\Temp\\ipykernel_28392\\1699575113.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=min_count, random_state=42))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Define the minimum count (smallest class)\n",
    "min_count = TRAIN_DF['label'].value_counts().min()\n",
    "\n",
    "# Downsample each class to `min_count`\n",
    "TRAIN_DF = (TRAIN_DF.groupby('label')\n",
    "               .apply(lambda x: x.sample(n=min_count, random_state=42))\n",
    "               .reset_index(drop=True))\n",
    "\n",
    "# Check the new distribution\n",
    "print(TRAIN_DF['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "17408c08-e32c-4011-80c9-a47e66658c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\MachineLearning\\AICU\\recommendation_system\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:21:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.2962\n",
      "\n",
      "XGBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  hatespeech       0.28      0.32      0.30       628\n",
      "      normal       0.30      0.45      0.36       628\n",
      "   offensive       0.32      0.12      0.17       628\n",
      "\n",
      "    accuracy                           0.30      1884\n",
      "   macro avg       0.30      0.30      0.28      1884\n",
      "weighted avg       0.30      0.30      0.28      1884\n",
      "\n",
      "\n",
      "Accuracy for Hermes-3-Llama-3.1-70B-Q5_K_S: 0.5210\n",
      "\n",
      "Hermes-3-Llama-3.1-70B-Q5_K_S Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  hatespeech       0.49      0.88      0.63       628\n",
      "      normal       0.70      0.40      0.51       626\n",
      "   offensive       0.44      0.29      0.35       627\n",
      "\n",
      "    accuracy                           0.52      1881\n",
      "   macro avg       0.54      0.52      0.50      1881\n",
      "weighted avg       0.54      0.52      0.50      1881\n",
      "\n",
      "\n",
      "Accuracy for llama3.3:70B-Instruct-Q2_K: 0.4613\n",
      "\n",
      "llama3.3:70B-Instruct-Q2_K Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  hatespeech       0.43      0.94      0.59       628\n",
      "      normal       0.80      0.24      0.36       628\n",
      "   offensive       0.40      0.21      0.27       628\n",
      "\n",
      "    accuracy                           0.46      1884\n",
      "   macro avg       0.55      0.46      0.41      1884\n",
      "weighted avg       0.55      0.46      0.41      1884\n",
      "\n",
      "\n",
      "Accuracy for llama3.3:70b-instruct-q6_K-SEEN_DATA: 0.4644\n",
      "\n",
      "llama3.3:70b-instruct-q6_K-SEEN_DATA Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  hatespeech       0.45      0.98      0.62       628\n",
      "      normal       0.89      0.25      0.39       628\n",
      "   offensive       0.31      0.17      0.22       628\n",
      "\n",
      "    accuracy                           0.46      1884\n",
      "   macro avg       0.55      0.46      0.41      1884\n",
      "weighted avg       0.55      0.46      0.41      1884\n",
      "\n",
      "\n",
      "Accuracy for llama3.3:70b-instruct-q6_K: 0.5170\n",
      "\n",
      "llama3.3:70b-instruct-q6_K Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  hatespeech       0.49      0.93      0.65       628\n",
      "      normal       0.85      0.30      0.44       628\n",
      "   offensive       0.42      0.32      0.36       628\n",
      "\n",
      "    accuracy                           0.52      1884\n",
      "   macro avg       0.59      0.52      0.48      1884\n",
      "weighted avg       0.59      0.52      0.48      1884\n",
      "\n",
      "\n",
      "Accuracy for mistral:7b-instruct-v0.2-q8_0: 0.4502\n",
      "\n",
      "mistral:7b-instruct-v0.2-q8_0 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  hatespeech       0.73      0.16      0.26       628\n",
      "      normal       0.67      0.38      0.48       623\n",
      "   offensive       0.37      0.82      0.51       628\n",
      "\n",
      "    accuracy                           0.45      1879\n",
      "   macro avg       0.59      0.45      0.42      1879\n",
      "weighted avg       0.59      0.45      0.42      1879\n",
      "\n",
      "\n",
      "Accuracy for RAG_llama3.3:70b-instruct-q6_K: 0.6086\n",
      "\n",
      "RAG_llama3.3:70b-instruct-q6_K Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  hatespeech       0.63      0.87      0.73       305\n",
      "      normal       0.75      0.40      0.52       316\n",
      "   offensive       0.51      0.57      0.54       309\n",
      "\n",
      "    accuracy                           0.61       930\n",
      "   macro avg       0.63      0.61      0.60       930\n",
      "weighted avg       0.63      0.61      0.60       930\n",
      "\n",
      "\n",
      "Accuracy for RAG_mistral:7b-instruct-v0.2-q8_0: 0.5361\n",
      "\n",
      "RAG_mistral:7b-instruct-v0.2-q8_0 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  hatespeech       0.78      0.36      0.50       305\n",
      "      normal       0.66      0.50      0.57       315\n",
      "   offensive       0.42      0.74      0.53       309\n",
      "\n",
      "    accuracy                           0.54       929\n",
      "   macro avg       0.62      0.54      0.53       929\n",
      "weighted avg       0.62      0.54      0.53       929\n",
      "\n",
      "\n",
      "Accuracy for RAG_llama3.3:70b-instruct-q6_K: 0.6086\n",
      "\n",
      "RAG_llama3.3:70b-instruct-q6_K Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  hatespeech       0.63      0.87      0.73       305\n",
      "      normal       0.75      0.40      0.52       316\n",
      "   offensive       0.51      0.57      0.54       309\n",
      "\n",
      "    accuracy                           0.61       930\n",
      "   macro avg       0.63      0.61      0.60       930\n",
      "weighted avg       0.63      0.61      0.60       930\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Prepare the labels (encoded labels for classification)\n",
    "label_encoder = LabelEncoder()\n",
    "TRAIN_DF['label_encoded'] = label_encoder.fit_transform(TRAIN_DF['label'])\n",
    "TEST_DF['label_encoded'] = label_encoder.transform(TEST_DF['label'])\n",
    "\n",
    "# Step 3: Convert 'X_train' column to a list of embeddings\n",
    "X_train = TRAIN_DF['X_train_emb'].tolist()\n",
    "X_test = TEST_DF['X_train_emb'].tolist()\n",
    "y_train = TRAIN_DF['label_encoded'].tolist()\n",
    "y_test = TEST_DF['label_encoded'].tolist()\n",
    "\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective='multi:softmax',  # Use 'multi:softmax' for multi-class classification\n",
    "    num_class=len(label_encoder.classes_),  # Number of classes\n",
    "    eval_metric='mlogloss',  # Multi-class log loss\n",
    "    use_label_encoder=False  # Avoid warnings about label encoding\n",
    ")\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the XGBoost model\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost Accuracy: {accuracy_xgb:.4f}\")\n",
    "\n",
    "# Detailed classification report for XGBoost\n",
    "print(\"\\nXGBoost Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb, target_names=label_encoder.classes_))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "other_classifier_columns = [\n",
    "    \"Hermes-3-Llama-3.1-70B-Q5_K_S\",\n",
    "    \"llama3.3:70B-Instruct-Q2_K\",\n",
    "    \"llama3.3:70b-instruct-q6_K-SEEN_DATA\",\n",
    "    \"llama3.3:70b-instruct-q6_K\",\n",
    "    \"mistral:7b-instruct-v0.2-q8_0\",\n",
    "\n",
    "    \"RAG_llama3.3:70b-instruct-q6_K\",\n",
    "    \"RAG_mistral:7b-instruct-v0.2-q8_0\",\n",
    "    \"RAG_llama3.3:70b-instruct-q6_K\",\n",
    "    \n",
    "]\n",
    "\n",
    "# Convert string predictions from other classifiers to label-encoded integers\n",
    "\n",
    "for column in other_classifier_columns:\n",
    "    # Initialize a list to hold the valid label-encoded predictions\n",
    "    y_pred_other = []\n",
    "\n",
    "    for pred in TEST_DF[column].astype(str):\n",
    "        try:\n",
    "            # Try to transform the prediction into an encoded label\n",
    "            y_pred_other.append(label_encoder.transform([pred])[0])\n",
    "        except ValueError:\n",
    "            # Handle unseen label: treat it as a default value (e.g., -1)\n",
    "            y_pred_other.append(-1)\n",
    "\n",
    "    y_pred_other = np.array(y_pred_other)\n",
    "\n",
    "    # Remove the '-1' values (unseen labels) from both y_pred_other and y_test\n",
    "    valid_indices = (y_pred_other != -1) & (y_test != -1)\n",
    "    y_pred_other_valid = y_pred_other[valid_indices]\n",
    "    y_test_valid = np.array(y_test)[valid_indices]\n",
    "\n",
    "    # Accuracy for this classifier's predictions\n",
    "    accuracy_other = accuracy_score(y_test_valid, y_pred_other_valid)\n",
    "    print(f\"\\nAccuracy for {column}: {accuracy_other:.4f}\")\n",
    "\n",
    "    # Detailed classification report for each other classifier\n",
    "    print(f\"\\n{column} Classification Report:\")\n",
    "    print(classification_report(y_test_valid, y_pred_other_valid, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b780f4b1-5e3c-4891-8de3-6efeac09c905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "hatespeech    1304\n",
       "normal        1304\n",
       "offensive     1304\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DF['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e17b626-e2d7-4eac-bce2-520b835ad349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
