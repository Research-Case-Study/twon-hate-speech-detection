{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e028bccb-12db-426e-8ef5-d4e1f8e60b9e",
   "metadata": {},
   "source": [
    "Purpose of this notebook is to experiment with how the explainations are created.\n",
    "In section 1, we first initialize functions for (loading llm, connecting vector db, and en embeddings model)\n",
    "In section 2, we experiment and run this flow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9567b13d-37da-4ccb-8893-6d5527897833",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a3f356-7ed9-4538-8e18-cc28a3aea83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "!pip install sentence_transformers \n",
    "!pip install qdrant_client\n",
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45c51813-435f-46fa-ba29-c8f30da86341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams, Batch\n",
    "from collections import Counter\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Change to the parent directory of the notebook\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "de704bea-b691-4f38-8d4d-db1b9f0fe2a9",
   "metadata": {},
   "source": [
    "Available Models:\n",
    "\n",
    "\"llama3.1:8b-instruct-q6_K\", \n",
    "\"gemma:7b-instruct-q6_K\",\n",
    "\"qwen2:72b-instruct-q6_K\",\n",
    "\"llama3.1:70b-instruct-q6_K\",\n",
    "\"phi3:14b-medium-128k-instruct-q6_K\",\n",
    "\"mixtral:8x7b-instruct-v0.1-q6_K\",\n",
    "\"mistral:7b-instruct-v0.2-q6_K\",\n",
    "\"llama3.3:70b-instruct-q6_K\",\n",
    "\"phi3.5:3.8b-mini-instruct-q6_K\",\n",
    "\"gemma2:27b-instruct-q6_K\","
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3110e4-b57e-4379-8dde-3ac93b2e176b",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81de4bb-5d53-4c15-ae64-4c8269a426e0",
   "metadata": {},
   "source": [
    "## Load Embeddings model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36247ff3-4124-404e-a9df-765218c17d80",
   "metadata": {},
   "source": [
    "If you are just experimenting with explainations and here to run LLM. then no need to run the cells in this section.\n",
    "\n",
    "Bellow there are 3 cells with 3 different type of models. uncomment the one suits best for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de1d121c-87cb-4693-8f85-fdb530925264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUNS superfast on CPU, Bad Results, good for old or weak laptop cpus, speed up testing\n",
    "\n",
    "# EMBEDDINGS_MODEL = SentenceTransformer('sentence-transformers/all-MiniLM-L12-v2', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580fdcdc-e66e-4a9b-841b-db8329eaed3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUNS superfast on CPU too, Good Results, works well on laptop with good cpu and laptop without GPU.\n",
    "\n",
    "EMBEDDINGS_MODEL = SentenceTransformer('jxm/cde-small-v1', trust_remote_code=True, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6a38c7d-b7cc-4e08-a974-3b8bd11f180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY USE THIS IF YOU HAVE CUDA (NVIDIA GPU with 9 GB VRAM available:\n",
    "# RUNS superfast on GPU, Best Results.\n",
    "\n",
    "# EMBEDDINGS_MODEL = SentenceTransformer(\"dunzhang/stella_en_1.5B_v5\", trust_remote_code=True, device='cpu') #.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd7c9c00-2c4b-4168-ace9-65cf3e8e6387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 17.1 s\n",
      "Wall time: 2.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# benchmarking how much time it takes to create embeddings of 50 iters\n",
    "for i in range(50):\n",
    "    EMBEDDINGS_MODEL.encode(\"# testing how much time embeddings model take on your system\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "672bc77b-5526-4553-bc06-1408e7998099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dimension\n",
    "len(EMBEDDINGS_MODEL.encode(\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb486448-c637-4fd3-8361-8a7a56557fcd",
   "metadata": {},
   "source": [
    "## Configure Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9882e102-03ef-463f-8eaf-ec6c1ace8687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://7ef18c4d-2ef6-4fb0-9243-0ac62546593c.us-east4-0.gcp.cloud.qdrant.io:6333/dashboard#/collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00d88b83-d2c8-4e1d-949d-6532420dacb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collections=[CollectionDescription(name='test_index_'), CollectionDescription(name='HateXplain_index_3'), CollectionDescription(name='HateXplain_index_1'), CollectionDescription(name='HateXplain_index_2'), CollectionDescription(name='HateXplain_index'), CollectionDescription(name='HateXplain_8129'), CollectionDescription(name='HateXplain_index_4'), CollectionDescription(name='test_index')]\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "qdrant_client = QdrantClient(\n",
    "    url=\"https://7ef18c4d-2ef6-4fb0-9243-0ac62546593c.us-east4-0.gcp.cloud.qdrant.io:6333\", \n",
    "    api_key=\"BR8zsNr5lEYrqJPL4EknUj2oRska2JO1nHwPFawlFMqZIrYMuGZ0Wg\",\n",
    ")\n",
    "\n",
    "print(qdrant_client.get_collections())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0010b1b-ba3a-4f9d-bc24-5122cf237279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker only \n",
    "qdrant_client = QdrantClient(location='127.0.0.1', port=6333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6a407b5-d82a-475a-8bd2-438d5c01b4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(index_name):\n",
    "    qdrant_client.create_collection(\n",
    "        collection_name=index_name,\n",
    "        vectors_config=VectorParams(size=len(EMBEDDINGS_MODEL.encode(\"\")), distance=Distance.DOT)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c06ab9-fd82-401c-a396-40020d9ab9f1",
   "metadata": {},
   "source": [
    "## Configure LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35261a1b-2919-4b19-ac32-d2979a59ff07",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://inf.cl.uni-trier.de/chat/\"\n",
    "\n",
    "def llm(model_name, system_prompt, input_query):\n",
    "    # Construct the request payload\n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\"content\": system_prompt, \"role\": \"system\"},\n",
    "            {\"content\": input_query, \"role\": \"user\"}\n",
    "        ],\n",
    "        \"model\": model_name,\n",
    "        \"options\": {}\n",
    "    }\n",
    "    \n",
    "    # Set the request headers\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    # Send the POST request\n",
    "    response = requests.post(API_URL, headers=headers, data=json.dumps(payload))\n",
    "    \n",
    "    # Process the response\n",
    "    if response.status_code == 200:\n",
    "        print(\"Response received successfully:\")\n",
    "        response = response.json() # json.dumps(, indent=4)\n",
    "    else:\n",
    "        print(f\"Failed to retrieve response. Status code: {response.status_code}\")\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312ec57d-ae1c-45e8-9c51-79943ee25924",
   "metadata": {},
   "source": [
    "## Load Dataset and convert to DF | Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65ee6ef3-f276-4773-ac21-13a3a398d420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset.json file\n",
    "file_path = 'Data/dataset.json'\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4380f977-fe8f-40c3-9aef-f997c9e1a6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>key_features</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "      <th>annotator_1_label</th>\n",
       "      <th>annotator_1_target</th>\n",
       "      <th>annotator_2_label</th>\n",
       "      <th>annotator_2_target</th>\n",
       "      <th>annotator_3_label</th>\n",
       "      <th>annotator_3_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20143</th>\n",
       "      <td>9989999_gab</td>\n",
       "      <td>if ur still on twitter tell carlton i said his...</td>\n",
       "      <td>[alcoholic, drug, addicted, teenage, single, m...</td>\n",
       "      <td>Men, None, Other, Women</td>\n",
       "      <td>offensive</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Men, Women, Other</td>\n",
       "      <td>offensive</td>\n",
       "      <td>None</td>\n",
       "      <td>normal</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20144</th>\n",
       "      <td>9990225_gab</td>\n",
       "      <td>when i first got on here and said i hate trump...</td>\n",
       "      <td>[i, hate, trump, i, was, hating, niggers]</td>\n",
       "      <td>African, None, Other</td>\n",
       "      <td>offensive</td>\n",
       "      <td>offensive</td>\n",
       "      <td>African</td>\n",
       "      <td>offensive</td>\n",
       "      <td>African, Other</td>\n",
       "      <td>normal</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20145</th>\n",
       "      <td>9991681_gab</td>\n",
       "      <td>was macht der moslem wenn der zion gegen seine...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Islam, None, Other</td>\n",
       "      <td>normal</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Islam</td>\n",
       "      <td>normal</td>\n",
       "      <td>Other</td>\n",
       "      <td>normal</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20146</th>\n",
       "      <td>9992513_gab</td>\n",
       "      <td>it is awful look at world demographics asians ...</td>\n",
       "      <td>[asians, are, fucking, everywhere, white, geno...</td>\n",
       "      <td>Asian, Hispanic</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>Asian</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20147</th>\n",
       "      <td>9998729_gab</td>\n",
       "      <td>the jewish globalist elite have only imported ...</td>\n",
       "      <td>[imported, few, million, muslims, to, multicul...</td>\n",
       "      <td>African, Islam, Jewish</td>\n",
       "      <td>offensive</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>African, Islam</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Islam, Jewish</td>\n",
       "      <td>offensive</td>\n",
       "      <td>African, Islam, Jewish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           post_id                                         tweet_text  \\\n",
       "20143  9989999_gab  if ur still on twitter tell carlton i said his...   \n",
       "20144  9990225_gab  when i first got on here and said i hate trump...   \n",
       "20145  9991681_gab  was macht der moslem wenn der zion gegen seine...   \n",
       "20146  9992513_gab  it is awful look at world demographics asians ...   \n",
       "20147  9998729_gab  the jewish globalist elite have only imported ...   \n",
       "\n",
       "                                            key_features  \\\n",
       "20143  [alcoholic, drug, addicted, teenage, single, m...   \n",
       "20144          [i, hate, trump, i, was, hating, niggers]   \n",
       "20145                                                 []   \n",
       "20146  [asians, are, fucking, everywhere, white, geno...   \n",
       "20147  [imported, few, million, muslims, to, multicul...   \n",
       "\n",
       "                        target       label annotator_1_label  \\\n",
       "20143  Men, None, Other, Women   offensive         offensive   \n",
       "20144     African, None, Other   offensive         offensive   \n",
       "20145       Islam, None, Other      normal         offensive   \n",
       "20146          Asian, Hispanic  hatespeech        hatespeech   \n",
       "20147   African, Islam, Jewish   offensive        hatespeech   \n",
       "\n",
       "      annotator_1_target annotator_2_label annotator_2_target  \\\n",
       "20143  Men, Women, Other         offensive               None   \n",
       "20144            African         offensive     African, Other   \n",
       "20145              Islam            normal              Other   \n",
       "20146           Hispanic        hatespeech              Asian   \n",
       "20147     African, Islam         offensive      Islam, Jewish   \n",
       "\n",
       "      annotator_3_label      annotator_3_target  \n",
       "20143            normal                    None  \n",
       "20144            normal                    None  \n",
       "20145            normal                    None  \n",
       "20146         offensive                   Asian  \n",
       "20147         offensive  African, Islam, Jewish  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rows = []\n",
    "for row in data.items():\n",
    "    post_id = row[1]['post_id']\n",
    "    post_tokens = row[1]['post_tokens']\n",
    "    rationales = row[1]['rationales']\n",
    "    annotators = row[1]['annotators']\n",
    "    tweet_text = \" \".join(post_tokens)\n",
    "\n",
    "    # Aggregate all rationales\n",
    "    combined_rationale = [any(rat[i] for rat in rationales) for i in range(len(post_tokens))] if rationales else [0] * len(post_tokens)\n",
    "\n",
    "    # Extract key features\n",
    "    key_features = [post_tokens[i] for i, is_key in enumerate(combined_rationale) if is_key]\n",
    "\n",
    "    annotator_data = {}\n",
    "    all_targets = set()  # To store unique targets\n",
    "    labels = []  # To collect labels for voting\n",
    "\n",
    "    for index, annotator in enumerate(annotators, start=1):  # Use index as annotator_id\n",
    "        annotator_data[f\"annotator_{index}_label\"] = annotator['label']\n",
    "        annotator_data[f\"annotator_{index}_target\"] = \", \".join(annotator['target']) if annotator['target'] else None\n",
    "\n",
    "        # Collect all targets\n",
    "        all_targets.update(annotator['target'])\n",
    "\n",
    "        # Collect labels for voting\n",
    "        labels.append(annotator['label'])\n",
    "\n",
    "    # Combine all unique targets\n",
    "    combined_target = \", \".join(sorted(all_targets))\n",
    "\n",
    "    # Perform majority voting for the label\n",
    "    label_counts = Counter(labels)\n",
    "    voted_label = label_counts.most_common(1)[0][0] if labels else None\n",
    "\n",
    "    # Create the row\n",
    "    row_data = {\n",
    "        \"post_id\": post_id,\n",
    "        \"tweet_text\": tweet_text,\n",
    "        \"key_features\": key_features,\n",
    "        \"target\": combined_target,\n",
    "        \"label\": voted_label,\n",
    "    }\n",
    "    row_data.update(annotator_data)  # Add annotator-related fields\n",
    "\n",
    "    rows.append(row_data)\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f03a4fe4-5a4b-401e-8601-4c14393cd7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Data/dataset.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46c6f77c-26b2-424b-a44e-651a8392f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filder data\n",
    "data = [\n",
    "    {key: d[key] for key in ('post_id', 'tweet_text', 'key_features', 'target', 'label')}\n",
    "    for d in rows\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1902ecc-f262-45e9-adb8-281a9793b539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'post_id': '1178534874602496000_twitter',\n",
       " 'tweet_text': '<user> <user> this is exactly the same as the argument that people who get raped when they were dressed scantily were asking for it you are lame af',\n",
       " 'key_features': [],\n",
       " 'target': 'None',\n",
       " 'label': 'normal'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see data\n",
    "data[10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309b0685-c62f-4ac7-9f02-ea33fb85d236",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd18839-ffed-4b3b-beb3-9ccbe60a6cd1",
   "metadata": {},
   "source": [
    "Here we make experiments with system prompt, \n",
    "\n",
    "System prompt contains : what model is supposed to do with the input query. with an exmple output.\n",
    "Input Query contains, one row of dataset.\n",
    "explaination variable will have the output of model which will be an explaination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eac2453b-a98f-4631-8cf8-cb46e49d5a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing LLM\n",
    "system_prompt = \"You are a helpful assistant.\"\n",
    "input_query = \"Hi\"\n",
    "model_name = \"llama3.3:70b-instruct-q6_K\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a14604fb-0006-4238-b022-e20f502311de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response received successfully:\n",
      "Hello! How can I assist you today? Do you have any questions or need help with something in particular? I'm here to help!\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 20.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "response = llm(model_name, system_prompt, input_query)\n",
    "explaination = response['response']\n",
    "print(explaination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "997d9393-967b-4eaa-88e9-bfa667dea15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"post_id\": \"1178534874602496000_twitter\", \"tweet_text\": \"<user> <user> this is exactly the same as the argument that people who get raped when they were dressed scantily were asking for it you are lame af\", \"key_features\": [], \"target\": \"None\", \"label\": \"normal\"}'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Picking one row from dataset and converting it into string.\n",
    "user_input = json.dumps(data[10000])\n",
    "user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73a34dbd-acc9-4a4a-9726-6955e5ac5c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response received successfully:\n",
      "The given tweet text, although labeled as \"normal,\" can be perceived as both hate speech and not hate speech depending on the context and interpretation. On one hand, the language used is strong, with the phrase \"you are lame af\" being derogatory, which could imply a form of verbal aggression or insult towards an individual or group. This kind of language might be seen as offensive or even hateful by some standards because it directly attacks the character or intelligence of the person being addressed. On the other hand, the tweet's core argument seems to critique and liken an unspecified argument to a harmful and victim-blaming attitude often applied to rape victims based on their attire, suggesting that the author is actually advocating against such harmful attitudes and defending victims' rights. The absence of specific key features listed might indicate that the annotators focused more on the intent behind the message rather than its literal content, interpreting it as a critique of harmful ideologies rather than an expression of hate. Overall, while the tweet's language is offensive in nature due to its use of derogatory terms, its context suggests that it aims to condemn victim-blaming and misogyny, which are forms of hate speech, thereby making the decision on whether it is hate speech or not complex and dependent on how one weighs the intent behind the message against the literal meaning of the words used.\n"
     ]
    }
   ],
   "source": [
    "# Testing LLM\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are supposed to write an explaination to user's input explaining why ITS hate speech and why its not hate speech, based on the information provided. Our annotators has already decided if a text is a hate speech or not, and labeled.\n",
    "you will be given\n",
    "tweet_text : \n",
    "\n",
    "key_features: \n",
    "\n",
    "{'post_id': ## post id . ignore it\n",
    " 'tweet_text': #its the main user text that you need to write explaination on.\n",
    " 'key_features': [] # list of the words that made a decision, important feature\n",
    " 'target': # targetted audience. \n",
    " 'label': # either offensive, hate speech or normal.   \n",
    " }\n",
    "\n",
    " If label is neutral and you think the text is hate speech. you still have to explain why this text is not hate speech. \n",
    " if the label is offensive, you judge how its offensive based on text and keyfeatures etc.\n",
    " \n",
    "# Notes:\n",
    "1. Explaination should be one paragraph\n",
    "2. Explaination should explain the context and user's intention.\n",
    "3. How is the explaination bad, and how is it not.\n",
    "4. what helps in making the decision.\n",
    "\n",
    "Now you will be given user input and you have to Write explainations.\n",
    "\"\"\"\n",
    "\n",
    "input_query = user_input\n",
    "model_name = \"llama3.3:70b-instruct-q6_K\"\n",
    "\n",
    "response = llm(model_name, system_prompt, input_query)\n",
    "explaination = response['response']\n",
    "print(explaination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fb05ff7-6265-487a-aa15-12d87f0e171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a in data.items():\n",
    "#     print(a.key())\n",
    "#     break\n",
    "# # a[1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ac3b153-2243-49f7-893d-5c9360374bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a[1]['annotators']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5c0d230-e860-4dfb-bf05-13d3266a011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79d5fe5-ed18-4051-bd16-734267230613",
   "metadata": {},
   "source": [
    "# Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881f7f80-0a43-405c-9fd5-ef8ac89ef043",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c3c59fd-2546-4027-a3d9-0c123b8ddc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"HateXplain_cpu_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47002354-dd3a-41b2-992e-83f75d4cca44",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93359e06-1cea-417a-a777-8c08450bb0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collections=[CollectionDescription(name='CUDA'), CollectionDescription(name='test_index'), CollectionDescription(name='HateXplain_8129'), CollectionDescription(name='HateXplain_cpu_test'), CollectionDescription(name='LnR')]\n"
     ]
    }
   ],
   "source": [
    "print(qdrant_client.get_collections())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebee5a2e-7468-445f-b999-80cbd27511a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Upload data into index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcaee8c-22d0-4a18-a220-2879f722ba5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e83a1923-aa47-4baa-ac1e-5b3d72137acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert_in_qdrant_collection(data_list, data_list_embeddings, ids):\n",
    "    try:\n",
    "        qdrant_client.upsert(\n",
    "            collection_name=index_name,\n",
    "            points=Batch(\n",
    "                ids=ids,\n",
    "                vectors=data_list_embeddings,\n",
    "                payloads=data_list\n",
    "            ),\n",
    "        )\n",
    "    except Exception as e:\n",
    "        # traceback.print_exc()\n",
    "        print(f\"Exception in create_embeddings_and_upsert {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d7e4f32-c0a6-4092-9d5b-792c1575d45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings_and_upsert(batch_size=1000):\n",
    "\n",
    "    print(\"Creating rows embeddings\")\n",
    "    ids = list(range(1, len(data) + 1))\n",
    "    \n",
    "    for i in tqdm(range(0, len(data), batch_size)):\n",
    "        batch_data = data[i:i + batch_size]\n",
    "        batch_ids = ids[i:i + batch_size]\n",
    "        \n",
    "        batch_data_list_embeddings = []\n",
    "        for row in batch_data:\n",
    "            payload = (\n",
    "                f\"tweet_text: {row['tweet_text']}\\n\"\n",
    "                f\"key_features: {row['key_features']}\\n\"\n",
    "                f\"target: {row['target']}\\n\"\n",
    "                f\"label: {row['label']}\\n\"\n",
    "                # WE add EXPLAINATIONS HERE\n",
    "                # f\"post_id: {row['post_id']}\"\n",
    "            )\n",
    "            \n",
    "            batch_data_list_embeddings.append(EMBEDDINGS_MODEL.encode(payload))\n",
    "            #batch_ids.append(row['post_id'])\n",
    "\n",
    "        # Call the Qdrant function\n",
    "        upsert_in_qdrant_collection(batch_data, batch_data_list_embeddings, batch_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58927144-418f-49a0-968f-415dda313982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating rows embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–ˆâ–ˆâ–Š                                                                                                                                              | 2/101 [03:15<2:42:18, 98.37s/it]"
     ]
    }
   ],
   "source": [
    "create_embeddings_and_upsert(batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1344a801-805a-4e8a-8715-b1392428a5a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "861.6121917963028"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_size = 322663509  # bytes\n",
    "limit = 33554432  # bytes\n",
    "\n",
    "# Calculate percentage larger\n",
    "percentage_larger = ((file_size - limit) / limit) * 100\n",
    "percentage_larger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7121406-68f5-45a2-84f1-1c9bc964bdf2",
   "metadata": {},
   "source": [
    "## Query RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2c87b359-e21c-4d6e-b655-38b0d79186d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"loomergate\"\n",
    "top_k = 3\n",
    "embedding = EMBEDDINGS_MODEL.encode(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "afe8c186-f7c2-4b3c-86c6-1347ea59a612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ScoredPoint(id=17182, version=171, score=918.36975, payload={'post_id': '22049484_gab', 'tweet_text': 'is there any opposition to muslim invasion in sweden', 'key_features': [], 'target': 'Islam', 'label': 'normal'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=16153, version=161, score=892.71375, payload={'post_id': '18469603_gab', 'tweet_text': 'how boomers let jews loot the usa', 'key_features': [], 'target': 'Jewish, Men, None, Women', 'label': 'normal'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=17452, version=174, score=876.84314, payload={'post_id': '22918483_gab', 'tweet_text': 'reminder that google is run by jews', 'key_features': [], 'target': 'Jewish, None', 'label': 'normal'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=11898, version=118, score=873.79474, payload={'post_id': '1167982348769660928_twitter', 'tweet_text': 'everyone in your life is a fucking lie i promise', 'key_features': [], 'target': 'Men, None, Women', 'label': 'normal'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=13177, version=131, score=867.65, payload={'post_id': '1227305288501465089_twitter', 'tweet_text': '<user> syrian muslims suffer a lots', 'key_features': [], 'target': 'Arab, Islam, None', 'label': 'normal'}, vector=None, shard_key=None, order_value=None)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result = qdrant_client.search(\n",
    "    collection_name=index_name, query_vector=embedding, limit=5\n",
    ")\n",
    "search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e34614d-7351-44e7-95c7-4abd63ee785b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ScoredPoint(id=8179, version=41, score=13764.598, payload={'post_id': '1179085583680819200_twitter', 'tweet_text': 'please i want to get raped', 'key_features': [], 'target': 'None', 'label': 'normal'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=1275, version=7, score=12908.079, payload={'post_id': '1179064447941402625_twitter', 'tweet_text': 'love getting ass raped by pc kids on pubs when i am on console ðŸ¤ ', 'key_features': [], 'target': 'Homosexual, None', 'label': 'normal'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=7475, version=38, score=12023.535, payload={'post_id': '1178704722343219200_twitter', 'tweet_text': '<user> i d get raped for a rational debate', 'key_features': [], 'target': 'None', 'label': 'normal'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=13476, version=68, score=12018.386, payload={'post_id': '1242254807164948481_twitter', 'tweet_text': '<user> <user> <number> less boys being raped', 'key_features': [], 'target': 'Men, None', 'label': 'normal'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=11898, version=60, score=11993.904, payload={'post_id': '1167982348769660928_twitter', 'tweet_text': 'everyone in your life is a fucking lie i promise', 'key_features': [], 'target': 'Men, None, Women', 'label': 'normal'}, vector=None, shard_key=None, order_value=None)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = \"I might rape console players tonight\"\n",
    "top_k = 5\n",
    "embedding = EMBEDDINGS_MODEL.encode(user_input)\n",
    "search_result = qdrant_client.search(\n",
    "    collection_name=index_name, query_vector=embedding, limit=top_k\n",
    ")\n",
    "search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd6f048-85e8-4651-aa53-07b8f0c2ab64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
