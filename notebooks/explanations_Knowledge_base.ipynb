{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e028bccb-12db-426e-8ef5-d4e1f8e60b9e",
   "metadata": {},
   "source": [
    "Purpose of this notebook is to experiment with how the explainations are created.\n",
    "In section 1, we first initialize functions for (loading llm, connecting vector db, and en embeddings model)\n",
    "In section 2, we experiment and run this flow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9567b13d-37da-4ccb-8893-6d5527897833",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a3f356-7ed9-4538-8e18-cc28a3aea83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "!pip install sentence_transformers \n",
    "!pip install qdrant_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45c51813-435f-46fa-ba29-c8f30da86341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams, Batch\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Change to the parent directory of the notebook\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "de704bea-b691-4f38-8d4d-db1b9f0fe2a9",
   "metadata": {},
   "source": [
    "Available Models:\n",
    "\n",
    "\"llama3.1:8b-instruct-q6_K\", \n",
    "\"gemma:7b-instruct-q6_K\",\n",
    "\"qwen2:72b-instruct-q6_K\",\n",
    "\"llama3.1:70b-instruct-q6_K\",\n",
    "\"phi3:14b-medium-128k-instruct-q6_K\",\n",
    "\"mixtral:8x7b-instruct-v0.1-q6_K\",\n",
    "\"mistral:7b-instruct-v0.2-q6_K\",\n",
    "\"llama3.3:70b-instruct-q6_K\",\n",
    "\"phi3.5:3.8b-mini-instruct-q6_K\",\n",
    "\"gemma2:27b-instruct-q6_K\","
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3110e4-b57e-4379-8dde-3ac93b2e176b",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81de4bb-5d53-4c15-ae64-4c8269a426e0",
   "metadata": {},
   "source": [
    "## Load Embeddings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de1d121c-87cb-4693-8f85-fdb530925264",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDINGS_MODEL = SentenceTransformer('sentence-transformers/all-MiniLM-L12-v2', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb486448-c637-4fd3-8361-8a7a56557fcd",
   "metadata": {},
   "source": [
    "## Configure Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00d88b83-d2c8-4e1d-949d-6532420dacb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collections=[]\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "qdrant_client = QdrantClient(\n",
    "    url=\"https://7ef18c4d-2ef6-4fb0-9243-0ac62546593c.us-east4-0.gcp.cloud.qdrant.io:6333\", \n",
    "    api_key=\"BR8zsNr5lEYrqJPL4EknUj2oRska2JO1nHwPFawlFMqZIrYMuGZ0Wg\",\n",
    ")\n",
    "\n",
    "print(qdrant_client.get_collections())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6a407b5-d82a-475a-8bd2-438d5c01b4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(index_name):\n",
    "    qdrant_client.create_collection(\n",
    "        collection_name=index_name,\n",
    "        vectors_config=VectorParams(size=len(EMBEDDINGS_MODEL.encode(\"\")), distance=Distance.DOT)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c06ab9-fd82-401c-a396-40020d9ab9f1",
   "metadata": {},
   "source": [
    "## Configure LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35261a1b-2919-4b19-ac32-d2979a59ff07",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://inf.cl.uni-trier.de/chat/\"\n",
    "\n",
    "def llm(model_name, system_prompt, input_query):\n",
    "    # Construct the request payload\n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\"content\": system_prompt, \"role\": \"system\"},\n",
    "            {\"content\": input_query, \"role\": \"user\"}\n",
    "        ],\n",
    "        \"model\": model_name,\n",
    "        \"options\": {}\n",
    "    }\n",
    "    \n",
    "    # Set the request headers\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    # Send the POST request\n",
    "    response = requests.post(API_URL, headers=headers, data=json.dumps(payload))\n",
    "    \n",
    "    # Process the response\n",
    "    if response.status_code == 200:\n",
    "        print(\"Response received successfully:\")\n",
    "        response = response.json() # json.dumps(, indent=4)\n",
    "    else:\n",
    "        print(f\"Failed to retrieve response. Status code: {response.status_code}\")\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309b0685-c62f-4ac7-9f02-ea33fb85d236",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd18839-ffed-4b3b-beb3-9ccbe60a6cd1",
   "metadata": {},
   "source": [
    "Here we make experiments with system prompt, \n",
    "\n",
    "System prompt contains : what model is supposed to do with the input query. with an exmple output.\n",
    "Input Query contains, one row of dataset.\n",
    "explaination variable will have the output of model which will be an explaination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eac2453b-a98f-4631-8cf8-cb46e49d5a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make changes here.\n",
    "system_prompt = \"You are a helpful assistant.\"\n",
    "input_query = \"Hi\"\n",
    "model_name = \"llama3.3:70b-instruct-q6_K\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14604fb-0006-4238-b022-e20f502311de",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm(model_name, system_prompt, input_query)\n",
    "explaination = response['response']\n",
    "print(explaination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312ec57d-ae1c-45e8-9c51-79943ee25924",
   "metadata": {},
   "source": [
    "### Load Dataset and convert to DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15d92f2d-9e93-49d7-929d-97f9092691a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data = [json.loads(line) for line in open(file_path)]\n",
    "\n",
    "# Convert the loaded JSONL data to a Pandas DataFrame\n",
    "complete_df = pd.DataFrame(complete_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efd10c3-286a-436a-8350-245e5377241f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65ee6ef3-f276-4773-ac21-13a3a398d420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>key_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1179055004553900032_twitter</td>\n",
       "      <td>i dont think im getting my baby them white 9 h...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1179055004553900032_twitter</td>\n",
       "      <td>i dont think im getting my baby them white 9 h...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1179055004553900032_twitter</td>\n",
       "      <td>i dont think im getting my baby them white 9 h...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1179055004553900032_twitter</td>\n",
       "      <td>i dont think im getting my baby them white 9 h...</td>\n",
       "      <td>[ching, chong]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1179055004553900032_twitter</td>\n",
       "      <td>i dont think im getting my baby them white 9 h...</td>\n",
       "      <td>[bitch, i, hate, white, bitches]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       post_id  \\\n",
       "0  1179055004553900032_twitter   \n",
       "1  1179055004553900032_twitter   \n",
       "2  1179055004553900032_twitter   \n",
       "3  1179055004553900032_twitter   \n",
       "4  1179055004553900032_twitter   \n",
       "\n",
       "                                          tweet_text  \\\n",
       "0  i dont think im getting my baby them white 9 h...   \n",
       "1  i dont think im getting my baby them white 9 h...   \n",
       "2  i dont think im getting my baby them white 9 h...   \n",
       "3  i dont think im getting my baby them white 9 h...   \n",
       "4  i dont think im getting my baby them white 9 h...   \n",
       "\n",
       "                       key_features  \n",
       "0                                []  \n",
       "1                                []  \n",
       "2                                []  \n",
       "3                    [ching, chong]  \n",
       "4  [bitch, i, hate, white, bitches]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## incomplete TODO\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the dataset.json file\n",
    "file_path = 'Data\\\\dataset.json'\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Convert the JSON structure into a pandas DataFrame\n",
    "rows = []\n",
    "for row in data.items():\n",
    "    post_tokens = row[1]['post_tokens']\n",
    "    rationales =  row[1]['rationales']\n",
    "    # tweet_text = \" \".join(post_data[\"post_tokens\"])\n",
    "    # post_tokens = details.get(\"post_tokens\", [])\n",
    "    # rationales = details.get(\"rationales\", [])\n",
    "    \n",
    "    # Aggregate all rationales\n",
    "    combined_rationale = [any(rat[i] for rat in rationales) for i in range(len(post_tokens))] if rationales else [0] * len(post_tokens)\n",
    "    \n",
    "    # Extract key features\n",
    "    key_features = [post_tokens[i] for i, is_key in enumerate(combined_rationale) if is_key]\n",
    "    rows.append({\n",
    "            \"post_id\": post_id,\n",
    "            \"tweet_text\": tweet_text,\n",
    "            \"key_features\": key_features,\n",
    "            # \"annotator_id\": annotator[\"annotator_id\"],\n",
    "            # \"label\": annotator[\"label\"],\n",
    "            #\"target\": \", \".join(annotator[\"target\"]) if annotator[\"target\"] else None\n",
    "        })\n",
    "    \n",
    "    # for annotator in post_data[\"annotators\"]:\n",
    "    #   rows.append({\n",
    "    #        \"post_id\": post_id,\n",
    "    #        \"tweet_text\": tweet_text,\n",
    "    #        \"key_features\": key_features,\n",
    "    #        \"annotator_id\": annotator[\"annotator_id\"],\n",
    "    #        \"label\": annotator[\"label\"],\n",
    "    #        #\"target\": \", \".join(annotator[\"target\"]) if annotator[\"target\"] else None\n",
    "    #    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fb05ff7-6265-487a-aa15-12d87f0e171d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'post_id': '1179055004553900032_twitter',\n",
       " 'annotators': [{'label': 'normal', 'annotator_id': 1, 'target': ['None']},\n",
       "  {'label': 'normal', 'annotator_id': 2, 'target': ['None']},\n",
       "  {'label': 'normal', 'annotator_id': 3, 'target': ['None']}],\n",
       " 'rationales': [],\n",
       " 'post_tokens': ['i',\n",
       "  'dont',\n",
       "  'think',\n",
       "  'im',\n",
       "  'getting',\n",
       "  'my',\n",
       "  'baby',\n",
       "  'them',\n",
       "  'white',\n",
       "  '9',\n",
       "  'he',\n",
       "  'has',\n",
       "  'two',\n",
       "  'white',\n",
       "  'j',\n",
       "  'and',\n",
       "  'nikes',\n",
       "  'not',\n",
       "  'even',\n",
       "  'touched']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54cafad1-790e-4a72-bc84-789455d4a016",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1179055004553900032_twitter', {'post_id': '1179055004553900032_twitter', 'annotators': [{'label': 'normal', 'annotator_id': 1, 'target': ['None']}, {'label': 'normal', 'annotator_id': 2, 'target': ['None']}, {'label': 'normal', 'annotator_id': 3, 'target': ['None']}], 'rationales': [], 'post_tokens': ['i', 'dont', 'think', 'im', 'getting', 'my', 'baby', 'them', 'white', '9', 'he', 'has', 'two', 'white', 'j', 'and', 'nikes', 'not', 'even', 'touched']})\n"
     ]
    }
   ],
   "source": [
    "for a in data.items():\n",
    "    print(a)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79d5fe5-ed18-4051-bd16-734267230613",
   "metadata": {},
   "source": [
    "# Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881f7f80-0a43-405c-9fd5-ef8ac89ef043",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c3c59fd-2546-4027-a3d9-0c123b8ddc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"test_index\"\n",
    "create_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93359e06-1cea-417a-a777-8c08450bb0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collections=[CollectionDescription(name='test_index')]\n"
     ]
    }
   ],
   "source": [
    "print(qdrant_client.get_collections())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebee5a2e-7468-445f-b999-80cbd27511a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
