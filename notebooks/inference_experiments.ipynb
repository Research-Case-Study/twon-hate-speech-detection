{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9567b13d-37da-4ccb-8893-6d5527897833",
   "metadata": {
    "id": "9567b13d-37da-4ccb-8893-6d5527897833"
   },
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02a3f356-7ed9-4538-8e18-cc28a3aea83b",
   "metadata": {
    "id": "02a3f356-7ed9-4538-8e18-cc28a3aea83b"
   },
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "!pip install sentence_transformers\n",
    "!pip install qdrant_client\n",
    "!pip install einops\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45c51813-435f-46fa-ba29-c8f30da86341",
   "metadata": {
    "id": "45c51813-435f-46fa-ba29-c8f30da86341"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams, Batch\n",
    "from collections import Counter\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42201bf0-bd14-4ffe-b6d8-39cb6ba05ce1",
   "metadata": {
    "id": "42201bf0-bd14-4ffe-b6d8-39cb6ba05ce1"
   },
   "source": [
    "# LLM for Explaination Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c06ab9-fd82-401c-a396-40020d9ab9f1",
   "metadata": {
    "id": "07c06ab9-fd82-401c-a396-40020d9ab9f1"
   },
   "source": [
    "## Configure LLM"
   ]
  },
  {
   "cell_type": "raw",
   "id": "de704bea-b691-4f38-8d4d-db1b9f0fe2a9",
   "metadata": {
    "id": "de704bea-b691-4f38-8d4d-db1b9f0fe2a9"
   },
   "source": [
    "Bellow Experiments, you can select any of these models by copy pasting the name in model_name\n",
    "\n",
    "Available Models:\n",
    "\n",
    "\"llama3.1:8b-instruct-q6_K\",\n",
    "\"gemma:7b-instruct-q6_K\",\n",
    "\"qwen2:72b-instruct-q6_K\",\n",
    "\"llama3.1:70b-instruct-q6_K\",\n",
    "\"phi3:14b-medium-128k-instruct-q6_K\",\n",
    "\"mixtral:8x7b-instruct-v0.1-q6_K\",\n",
    "\"mistral:7b-instruct-v0.2-q6_K\",\n",
    "\"llama3.3:70b-instruct-q6_K\",\n",
    "\"phi3.5:3.8b-mini-instruct-q6_K\",\n",
    "\"gemma2:27b-instruct-q6_K\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35261a1b-2919-4b19-ac32-d2979a59ff07",
   "metadata": {
    "id": "35261a1b-2919-4b19-ac32-d2979a59ff07"
   },
   "outputs": [],
   "source": [
    "# Define LLM inference function to use later\n",
    "API_URL = \"https://inf.cl.uni-trier.de/chat/\"\n",
    "\n",
    "\n",
    "def llm(model_name, system_prompt, input_query, rag_context):\n",
    "    rag_context = f\"Additional Context: {rag_context}\"\n",
    "    # Construct the request payload\n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\"content\": system_prompt, \"role\": \"system\"},\n",
    "            {\"content\": rag_context, \"role\": \"system\"},\n",
    "            {\"content\": input_query, \"role\": \"user\"}\n",
    "        ],\n",
    "        \"model\": model_name,\n",
    "        \"options\": {}\n",
    "    }\n",
    "\n",
    "    # Set the request headers\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    # Send the POST request\n",
    "    response = requests.post(API_URL, headers=headers,\n",
    "                             data=json.dumps(payload))\n",
    "\n",
    "    # Process the response\n",
    "    if response.status_code == 200:\n",
    "        print(\"Response received successfully:\")\n",
    "        response = response.json()  # json.dumps(, indent=4)\n",
    "    else:\n",
    "        print(\n",
    "            f\"Failed to retrieve response. Status code: {response.status_code}\")\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd18839-ffed-4b3b-beb3-9ccbe60a6cd1",
   "metadata": {
    "id": "8fd18839-ffed-4b3b-beb3-9ccbe60a6cd1"
   },
   "source": [
    "Here we make experiments with system prompt,\n",
    "\n",
    "System prompt contains : what model is supposed to do with the input query. with an exmple output.\n",
    "Input Query contains, one row of dataset.\n",
    "explaination variable will have the output of model which will be an explaination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eac2453b-a98f-4631-8cf8-cb46e49d5a38",
   "metadata": {
    "id": "eac2453b-a98f-4631-8cf8-cb46e49d5a38"
   },
   "outputs": [],
   "source": [
    "# # Testing LLM\n",
    "# system_prompt = \"You are a helpful assistant.\"\n",
    "# input_query = \"Hi\"\n",
    "# model_name = \"llama3.3:70b-instruct-q6_K\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a14604fb-0006-4238-b022-e20f502311de",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a14604fb-0006-4238-b022-e20f502311de",
    "outputId": "223d1972-f328-418c-dc94-3ababa9f9695"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response received successfully:\n",
      "Hello! How can I assist you today? Do you have any questions, need help with something, or just want to chat? I'm here to help!\n",
      "CPU times: user 99.4 ms, sys: 27.4 ms, total: 127 ms\n",
      "Wall time: 23 s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# response = llm(model_name, system_prompt, input_query)\n",
    "# explaination = response['response']\n",
    "# print(explaination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c0d230-e860-4dfb-bf05-13d3266a011f",
   "metadata": {
    "id": "d5c0d230-e860-4dfb-bf05-13d3266a011f"
   },
   "outputs": [],
   "source": [
    "# a[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fe7b5d-c64e-41ee-af07-dbe6d2b77f56",
   "metadata": {
    "id": "49fe7b5d-c64e-41ee-af07-dbe6d2b77f56"
   },
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81de4bb-5d53-4c15-ae64-4c8269a426e0",
   "metadata": {
    "id": "b81de4bb-5d53-4c15-ae64-4c8269a426e0"
   },
   "source": [
    "## Load Embeddings model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36247ff3-4124-404e-a9df-765218c17d80",
   "metadata": {
    "id": "36247ff3-4124-404e-a9df-765218c17d80"
   },
   "source": [
    "If you are just experimenting with explainations and here to run LLM. then no need to run the cells in this section.\n",
    "\n",
    "Bellow there are 3 cells with 3 different type of models. uncomment the one suits best for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de1d121c-87cb-4693-8f85-fdb530925264",
   "metadata": {
    "id": "de1d121c-87cb-4693-8f85-fdb530925264"
   },
   "outputs": [],
   "source": [
    "# RUNS superfast on CPU, Bad Results, good for old or weak laptop cpus, speed up testing\n",
    "\n",
    "# EMBEDDINGS_MODEL = SentenceTransformer('sentence-transformers/all-MiniLM-L12-v2', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "580fdcdc-e66e-4a9b-841b-db8329eaed3e",
   "metadata": {
    "id": "580fdcdc-e66e-4a9b-841b-db8329eaed3e"
   },
   "outputs": [],
   "source": [
    "# # RUNS superfast on CPU too, Good Results, works well on laptop with good cpu and laptop without GPU.\n",
    "\n",
    "# EMBEDDINGS_MODEL = SentenceTransformer(\n",
    "#     'jxm/cde-small-v1', trust_remote_code=True, device='cuda').to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6a38c7d-b7cc-4e08-a974-3b8bd11f180f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6a38c7d-b7cc-4e08-a974-3b8bd11f180f",
    "outputId": "1ece3514-3290-46ab-966c-dd9d8a18a3e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "EMBEDDINGS_MODEL = SentenceTransformer(\n",
    "    \"dunzhang/stella_en_1.5B_v5\",\n",
    "    trust_remote_code=True,\n",
    "    device=device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "672bc77b-5526-4553-bc06-1408e7998099",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "672bc77b-5526-4553-bc06-1408e7998099",
    "outputId": "b7e6a998-34fe-4abc-c565-c3c141c9b11b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 538 ms, sys: 1.89 ms, total: 540 ms\n",
      "Wall time: 539 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# dimension\n",
    "len(EMBEDDINGS_MODEL.encode(\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb486448-c637-4fd3-8361-8a7a56557fcd",
   "metadata": {
    "id": "cb486448-c637-4fd3-8361-8a7a56557fcd"
   },
   "source": [
    "## Configure Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9882e102-03ef-463f-8eaf-ec6c1ace8687",
   "metadata": {
    "id": "9882e102-03ef-463f-8eaf-ec6c1ace8687"
   },
   "outputs": [],
   "source": [
    "# https://7ef18c4d-2ef6-4fb0-9243-0ac62546593c.us-east4-0.gcp.cloud.qdrant.io:6333/dashboard#/collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00d88b83-d2c8-4e1d-949d-6532420dacb7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "00d88b83-d2c8-4e1d-949d-6532420dacb7",
    "outputId": "346e23a3-deeb-4f99-c871-b8cc4c2a76d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collections=[CollectionDescription(name='HateXplain_8129'), CollectionDescription(name='HateXplain_index_2'), CollectionDescription(name='explainations_nimora_test'), CollectionDescription(name='HateXplain_index'), CollectionDescription(name='HateXplain_index_3'), CollectionDescription(name='HateXplain_gpu_stella_0'), CollectionDescription(name='HateXplain_gpu_nilo_0'), CollectionDescription(name='test_index'), CollectionDescription(name='HateXplain_index_1'), CollectionDescription(name='HateXplain_gpu_usama_0'), CollectionDescription(name='HateXplain_gpu_nilo_1'), CollectionDescription(name='test_index_'), CollectionDescription(name='HateXplain_index_4')]\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "qdrant_client = QdrantClient(\n",
    "    url=\"https://7ef18c4d-2ef6-4fb0-9243-0ac62546593c.us-east4-0.gcp.cloud.qdrant.io:6333\",\n",
    "    api_key=\"BR8zsNr5lEYrqJPL4EknUj2oRska2JO1nHwPFawlFMqZIrYMuGZ0Wg\",\n",
    ")\n",
    "\n",
    "print(qdrant_client.get_collections())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0010b1b-ba3a-4f9d-bc24-5122cf237279",
   "metadata": {
    "id": "c0010b1b-ba3a-4f9d-bc24-5122cf237279"
   },
   "outputs": [],
   "source": [
    "# docker only\n",
    "# qdrant_client = QdrantClient(location='127.0.0.1', port=6333)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d95d3d7-46d9-45a3-bae1-de3a3283c8ee",
   "metadata": {
    "id": "2d95d3d7-46d9-45a3-bae1-de3a3283c8ee"
   },
   "source": [
    "You can browse the collections/indexes here:\n",
    "\n",
    "https://7ef18c4d-2ef6-4fb0-9243-0ac62546593c.us-east4-0.gcp.cloud.qdrant.io:6333/dashboard#/collections\n",
    "\n",
    "and and enter the API: BR8zsNr5lEYrqJPL4EknUj2oRska2JO1nHwPFawlFMqZIrYMuGZ0Wg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79d5fe5-ed18-4051-bd16-734267230613",
   "metadata": {
    "id": "a79d5fe5-ed18-4051-bd16-734267230613"
   },
   "source": [
    "## Deploy | Upload dataset on RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c3c59fd-2546-4027-a3d9-0c123b8ddc0b",
   "metadata": {
    "id": "0c3c59fd-2546-4027-a3d9-0c123b8ddc0b"
   },
   "outputs": [],
   "source": [
    "index_name = \"HateXplain_gpu_stella_0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7121406-68f5-45a2-84f1-1c9bc964bdf2",
   "metadata": {
    "id": "d7121406-68f5-45a2-84f1-1c9bc964bdf2"
   },
   "source": [
    "## Query RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "FChE_GH-e6fF",
   "metadata": {
    "id": "FChE_GH-e6fF"
   },
   "outputs": [],
   "source": [
    "def fetch_explainations_rag(user_input, top_k):\n",
    "\n",
    "    embedding = EMBEDDINGS_MODEL.encode(user_input)\n",
    "    search_result = qdrant_client.search(\n",
    "        collection_name=index_name, query_vector=embedding, limit=top_k\n",
    "    )\n",
    "\n",
    "    result = [\n",
    "        {\n",
    "            \"text\": item.payload[\"tweet_text\"],\n",
    "            \"explanation\": item.payload[\"Response\"],\n",
    "            \"key_features\": item.payload[\"key_features\"],\n",
    "            # \"score\": item.score,\n",
    "            \"label\": item.payload[\"label\"]\n",
    "        }\n",
    "        for item in search_result\n",
    "    ]\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cldWDj5vtQlb",
   "metadata": {
    "id": "cldWDj5vtQlb"
   },
   "source": [
    "# INFERENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-HSU_uBwm3fm",
   "metadata": {
    "id": "-HSU_uBwm3fm"
   },
   "source": [
    "## Userinput + RAG output - > LLM -> classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Eak9xAaMm5-e",
   "metadata": {
    "id": "Eak9xAaMm5-e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "FgnQIPLAm6mP",
   "metadata": {
    "id": "FgnQIPLAm6mP"
   },
   "outputs": [],
   "source": [
    "system_prompt_classification = \"\"\"\n",
    "Lets classify the following text for hate speech.\n",
    "\n",
    "if its hatespeech your reply will be: \"hate speech\"\n",
    "if its not hatespeech your reply will be : \"normal\"\n",
    "if its offensive and not hatespeech, your reply will be : \"offensive\"\n",
    "\n",
    "You are also given some related examples and their decision along with explainations why the decision was took. If those examples help make an unbiast decision contextually.\n",
    "Focus more on userinput.\n",
    "\n",
    "\n",
    "Here is user input and reply with only one word ONLY such as [hate speech, normal, or offensive] \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "k805xo65nHUf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k805xo65nHUf",
    "outputId": "f1248404-1f85-412b-e4ce-8a5686d85261"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################### \n",
      "UserInput: Userinput:I might rape console players tonight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-2f29db771a04>:4: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_result = qdrant_client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################### \n",
      "RAG Results:\n",
      "[\n",
      "    {\n",
      "        \"text\": \"i ate dan because it raped me on minecraft\",\n",
      "        \"explanation\": \"The provided tweet text is classified as neutral due to the following reasons:\\n\\n1. The tweet's content does not contain any overt hate speech or directly offensive language.\\n\\n2. While references to sexual assault and violence are present (\\\"it raped me\\\"), they appear to be used in a non-literal context related to the game Minecraft, where \\\"rape\\\" can colloquially mean domination or defeat within the gaming community.\\n\\n3. The tweet does not target any specific group or individual, nor does it promote harm or discrimination against anyone.\\n\\n4. Given the lack of clear malicious intent and the absence of direct targeting or inflammatory language, this tweet is best categorized as neutral, despite its potentially disturbing content when taken out of context.\",\n",
      "        \"key_features\": \"[]\",\n",
      "        \"label\": \"normal\"\n",
      "    },\n",
      "    {\n",
      "        \"text\": \"<user> what if you get raped or the condom breaks\",\n",
      "        \"explanation\": \"The text falls into the 'Offensive' category for the following reasons:\\n\\n1. The tweet directly targets another user with a sexually violent and threatening remark.\\n2. Key features include the words 'raped' and 'condom breaks', which carry explicit sexual connotations and imply a threat of non-consensual sex or pregnancy. These phrases contribute to the hostile tone and intent of the message.\\n3. The target is another user who is directly addressed in a demeaning and aggressive manner. This personalizes the attack, making it more severe and intimidating.\\n4. The tweet's tone is confrontational and menacing, using hypothetical violence to belittle or threaten the recipient. It creates an unsettling context that promotes harm.\\n5. In conclusion, the text is classified as 'Offensive' due to its sexually explicit threat of violence against a targeted individual. The aggressive language and implied assault make it a clear case of online harassment and intimidation.\",\n",
      "        \"key_features\": \"[]\",\n",
      "        \"label\": \"normal\"\n",
      "    }\n",
      "]\n",
      "Response received successfully:\n",
      "\n",
      "######################################### \n",
      "LLM Classification output: \n",
      " <think>\n",
      "Okay, let's see. I have to classify the user input as hate speech, normal, or offensive. The input is: \"I might rape console players tonight.\"\n",
      "\n",
      "First, I should consider the context and the words used. The word \"rape\" is a strong term that typically refers to sexual assault, which is a serious issue. However, in gaming contexts, especially among players, terms like \"rape\" can sometimes be slang for dominating or defeating someone in the game.\n",
      "\n",
      "So, in this case, the user says they might \"rape console players.\" Console players are people who play video games on consoles like PlayStation or Xbox. The phrase could imply that the user is going to dominate them in a game, not literally commit any violence. \n",
      "\n",
      "But I need to be careful here because even if it's slang, using the word \"rape\" can still be offensive and triggering for some people. It's a sensitive term, so even if the intent is about gaming, the language itself might cross into being offensive rather than just normal or hateful.\n",
      "\n",
      "Looking at the examples provided earlier, in one case, the explanation mentioned that references to rape were in a non-literal context related to Minecraft, and it was classified as \"normal.\" However, another example where someone was directly targeted with a threatening remark about rape was classified as \"offensive.\"\n",
      "\n",
      "In this current input, the user is talking about console players in general, not targeting a specific individual. So maybe it's more offensive rather than hate speech because it uses a violent term but doesn't target a specific group beyond gamers.\n",
      "\n",
      "Hate speech usually involves attacking a person or group based on characteristics like race, religion, etc., with intent to harm or incite violence. Here, the term is used in a gaming context, so it might not meet the criteria for hate speech but could still be offensive because of the word choice.\n",
      "\n",
      "So, considering all that, I think the correct classification here would be \"offensive.\"\n",
      "</think>\n",
      "\n",
      "offensive\n",
      "CPU times: user 2.3 s, sys: 3.35 s, total: 5.65 s\n",
      "Wall time: 50.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_name = \"deepseek-r1:70b\"\n",
    "user_input = \"I might rape console players tonight\"\n",
    "top_k = 2  # number of explainations fetched from vector db\n",
    "\n",
    "\n",
    "user_input = \"Userinput:\" + user_input\n",
    "print(f\"######################################### \\nUserInput: {user_input}\")\n",
    "\n",
    "rag_results = fetch_explainations_rag(user_input, top_k)\n",
    "rag_results_str = json.dumps(rag_results, indent=4)\n",
    "\n",
    "print(f\"\\n######################################### \\nRAG Results:\")\n",
    "print(rag_results_str)\n",
    "\n",
    "response = llm(model_name, system_prompt_classification, user_input, rag_results_str)\n",
    "llm_classification_output = response['response']\n",
    "print(f\"\\n######################################### \\nLLM Classification output: \\n {llm_classification_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AqO2uf5zqtuQ",
   "metadata": {
    "id": "AqO2uf5zqtuQ"
   },
   "source": [
    "## userinput + classification  -> Explaination or decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "vKvgMuzfrErg",
   "metadata": {
    "id": "vKvgMuzfrErg"
   },
   "outputs": [],
   "source": [
    "system_prompt_explaination = \"\"\"\n",
    "You are a helpful chatbot, which acts normal when the label is normal, but when you get userinput along with label as offensive or hatespeech. you have to tell the user why its hatespeech or offensive.\n",
    "And tell the user what he should tell, help him learn and avoid\n",
    "\n",
    "You are given userinput, and the label bellow: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9f74e16-d222-46fd-b7b2-ebe1b50bc82e",
   "metadata": {
    "id": "vKvgMuzfrErg"
   },
   "outputs": [],
   "source": [
    "Dena_system_prompt_explaination_1 = \"\"\"\n",
    "You are a helpful and empathetic chatbot programmed to assist users in understanding and improving their communication. \n",
    "Your task is to respond to user inputs based on their classification: normal, offensive, or hate speech. \n",
    "Here is how you should react:\n",
    "\n",
    "- If the input is classified as \"normal\", acknowledge the message positively and encourage further interaction.\n",
    "- If the input is classified as \"offensive\", explain why the content might be offensive, flag it, and offer guidance on how to communicate more respectfully.\n",
    "- If the input is classified as \"hate speech\", explain the harmful impact of such speech, flag and report the content, and provide information on the importance of maintaining a respectful and inclusive dialogue.\n",
    "\n",
    "Always respond with the aim to educate and promote a respectful dialogue. Provide clear explanations and offer support where needed.\n",
    ": \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83H8fCC2rAmx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "83H8fCC2rAmx",
    "outputId": "13d97778-3daa-440c-c2b8-3f579fb99326"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################### \n",
      "UserInput: Userinput:I might rape console players tonight\n",
      "Response received successfully:\n",
      "\n",
      "######################################### \n",
      "LLM final output for user: \n",
      " <think>\n",
      "Alright, I need to figure out how to handle this user input. The user wrote, \"I might rape console players tonight.\" First, I should classify the message. The word \"rape\" here is being used in a threatening way towards a group of people based on their gaming preferences. That definitely falls under hate speech because it's promoting violence against others.\n",
      "\n",
      "Now, according to the guidelines, when dealing with hate speech, I need to explain why it's harmful, flag and report it, and emphasize respectful communication. So my response should acknowledge that using such language can perpetuate a toxic environment and exclude or harm others. It's important to make clear that promoting violence is unacceptable.\n",
      "\n",
      "I also need to offer support by inviting the user to reflect on their words and engage in positive conversations instead. This approach helps educate them on the impact of their language while encouraging better communication.\n",
      "\n",
      "Putting it all together, I should structure my reply to address each point: explain the harm, flag the content, report it, and provide a supportive invitation for improvement. Keeping the tone empathetic yet firm is key here.\n",
      "</think>\n",
      "\n",
      "I understand that you're expressing some strong feelings about console players, but everyone deserves respect and kindness, regardless of their gaming preferences. Threatening or violent language can be really hurtful and create a toxic environment for others. It's important to remember that we should always communicate in ways that are inclusive and considerate.\n",
      "\n",
      "Let's focus on positive interactions and finding common ground with others, even when we disagree. If you'd like to talk about your feelings or experiences, I'm here to listen and help!\n",
      "CPU times: user 14.7 ms, sys: 41.8 ms, total: 56.5 ms\n",
      "Wall time: 32.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_name = \"deepseek-r1:70b\"\n",
    "user_input = \"I might rape console players tonight\"\n",
    "top_k = 2  # number of explainations fetched from vector db\n",
    "\n",
    "\n",
    "user_input = \"Userinput:\" + user_input\n",
    "print(f\"######################################### \\nUserInput: {user_input}\")\n",
    "\n",
    "classified_label = \"offensive\"\n",
    "response = llm(model_name, Dena_system_prompt_explaination_1, user_input, classified_label)\n",
    "llm_output = response['response']\n",
    "print(f\"\\n######################################### \\nLLM final output for user: \\n {llm_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9350e1-12fd-4df5-ae34-5a2bbea9cd47",
   "metadata": {},
   "source": [
    "Dena- Comment on the output of this prompt: \n",
    "I liked the empathy and conciceness in the LLMs answer. However, I would like some more detailes regarding which label the sentence is classified under and a short justification and explanation of the label. I would also like the action that the Agent takes to be mentioned in the final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "oiXmaecOsx92",
   "metadata": {
    "id": "oiXmaecOsx92"
   },
   "outputs": [],
   "source": [
    "Dena_system_prompt_explaination_2 = \"\"\"\n",
    "You are a helpful and empathetic chatbot programmed to assist users in understanding and improving their communication. \n",
    "Your task is to respond to user inputs based on their classification: normal, offensive, or hate speech. \n",
    "Your task is to analyze user inputs and respond based on their classificationâ€”normal, offensive, or hate speech. \n",
    "Your responses should educate users and promote respectful dialogue. \n",
    "Here is how you should react:\n",
    "\n",
    "- Normal: Acknowledge the message positively, encourage further positive interaction, and maintain engagement with the user.\n",
    "- Offensive: Provide a concise explanation of why the content is considered offensive. Point out the specific language or terms that are problematic and explain their impact. Flag it and offer guidance on how to communicate more respectfully.\n",
    "- Hate Speech: Explain the specific reasons why the content is classified as hate speech, including the potential harm it causes to individuals or groups. Highlight the seriousness of hate speech and its consequences in violating community standards. Flag and report the content immediately and shortly mention that it in your answer.\n",
    "Always respond with the intent to educate and inform, ensuring that each user receives a clear explanation of the issue and knows how to avoid similar mistakes in the future. \n",
    "Offer support and guidance to help users understand the importance of their word choices and the impact they have on others. Ask if they would like a deeper explanation. \n",
    "\n",
    ": \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbc2a4ac-23d8-4f0a-b73c-71c02d791b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################### \n",
      "UserInput: Userinput:I might rape console players tonight\n",
      "Response received successfully:\n",
      "\n",
      "######################################### \n",
      "LLM final output for user: \n",
      " <think>\n",
      "Alright, so I'm trying to figure out how to handle this user input: \"I might rape console players tonight.\" First off, I need to classify it as either normal, offensive, or hate speech.\n",
      "\n",
      "Looking at the sentence, the word \"rape\" is a strong term and can be really hurtful. Even if it's used jokingly, it refers to sexual assault, which is a serious issue. The target here seems to be console players, which is a group of people based on their gaming preferences. So this could be both offensive and hate speech because it's targeting a specific group with violent language.\n",
      "\n",
      "I should break this down. Using the term \"rape\" in any context can be triggering for many people who have experienced trauma. It's not just about the word itself but the implications and harm it can cause. Also, threatening or joking about such acts towards a group can create a hostile environment, which is why it's classified as hate speech.\n",
      "\n",
      "Now, how should I respond? The guidelines say to explain why it's problematic, point out specific issues, and offer guidance. So I need to make sure the user understands the impact of their words without being confrontational. Maybe something like acknowledging that while gaming rivalries can be fun, using such language crosses a line.\n",
      "\n",
      "I also have to remember to flag this as hate speech because it targets a group and uses violent imagery. It's important to mention the potential harm and the seriousness of the issue. I should inform them that this kind of content is reported but keep the tone educational rather than punitive.\n",
      "\n",
      "Finally, offering support by asking if they need further explanation shows empathy and willingness to help them understand better. So putting it all together, the response should be clear, informative, and supportive while addressing the severity of the statement.\n",
      "</think>\n",
      "\n",
      "The statement \"I might rape console players tonight\" contains language that can be distressing due to its reference to sexual assault, a serious issue with profound emotional impact. The term \"rape\" is inherently harmful and triggering, even in jest. Targeting a group based on gaming preferences can foster hostility.\n",
      "\n",
      "Response:\n",
      "\n",
      "Your comment has been flagged as hate speech because it uses violent imagery targeting a specific group. Such language can cause significant harm and create a hostile environment. While gaming rivalries can be enjoyable, using terms like \"rape\" crosses boundaries. Let's keep interactions positive and respectful. If you need further clarification on why this is problematic, feel free to ask.\n",
      "CPU times: user 14.4 ms, sys: 35.9 ms, total: 50.4 ms\n",
      "Wall time: 44.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_name = \"deepseek-r1:70b\"\n",
    "user_input = \"I might rape console players tonight\"\n",
    "top_k = 2  # number of explainations fetched from vector db\n",
    "\n",
    "\n",
    "user_input = \"Userinput:\" + user_input\n",
    "print(f\"######################################### \\nUserInput: {user_input}\")\n",
    "\n",
    "classified_label = \"offensive\"\n",
    "response = llm(model_name, Dena_system_prompt_explaination_2, user_input, classified_label)\n",
    "llm_output = response['response']\n",
    "print(f\"\\n######################################### \\nLLM final output for user: \\n {llm_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e38303-f9b8-413e-9f90-f309678dd589",
   "metadata": {},
   "source": [
    "Dena comment- Overall, I like the answer much better.\n",
    "However, interestingly the model flags this tweet as \"hate speech\" even though the actual label given was \"offensive\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313c1bd5-0c8e-4a74-a4b3-aab710119167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "07c06ab9-fd82-401c-a396-40020d9ab9f1",
    "b81de4bb-5d53-4c15-ae64-4c8269a426e0",
    "cb486448-c637-4fd3-8361-8a7a56557fcd",
    "d7121406-68f5-45a2-84f1-1c9bc964bdf2",
    "-HSU_uBwm3fm",
    "AqO2uf5zqtuQ"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
