{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50e92e1-ad7f-4da8-b922-e2e9aba5dabd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78da56aa-72ef-4086-9c28-b1b9eda0e0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b577356-f334-4c97-8d15-f30006dfbadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "from collections import Counter\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Change to the parent directory of the notebook\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9151accc-d62d-4d12-b105-afd987f70b2a",
   "metadata": {},
   "source": [
    "## Load and Transform Dataset + convert to DF | Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fedfca94-1dea-4043-8cf3-067461f8e76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset.json file\n",
    "file_path = 'Data/dataset.json'\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f58a7e53-43f8-4eb6-988a-4f083bef2f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>key_features</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "      <th>annotator_1_label</th>\n",
       "      <th>annotator_1_target</th>\n",
       "      <th>annotator_2_label</th>\n",
       "      <th>annotator_2_target</th>\n",
       "      <th>annotator_3_label</th>\n",
       "      <th>annotator_3_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20143</th>\n",
       "      <td>9989999_gab</td>\n",
       "      <td>if ur still on twitter tell carlton i said his...</td>\n",
       "      <td>[alcoholic, drug, addicted, teenage, single, m...</td>\n",
       "      <td>Men, None, Other, Women</td>\n",
       "      <td>offensive</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Men, Women, Other</td>\n",
       "      <td>offensive</td>\n",
       "      <td>None</td>\n",
       "      <td>normal</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20144</th>\n",
       "      <td>9990225_gab</td>\n",
       "      <td>when i first got on here and said i hate trump...</td>\n",
       "      <td>[i, hate, trump, i, was, hating, niggers]</td>\n",
       "      <td>African, None, Other</td>\n",
       "      <td>offensive</td>\n",
       "      <td>offensive</td>\n",
       "      <td>African</td>\n",
       "      <td>offensive</td>\n",
       "      <td>African, Other</td>\n",
       "      <td>normal</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20145</th>\n",
       "      <td>9991681_gab</td>\n",
       "      <td>was macht der moslem wenn der zion gegen seine...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Islam, None, Other</td>\n",
       "      <td>normal</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Islam</td>\n",
       "      <td>normal</td>\n",
       "      <td>Other</td>\n",
       "      <td>normal</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20146</th>\n",
       "      <td>9992513_gab</td>\n",
       "      <td>it is awful look at world demographics asians ...</td>\n",
       "      <td>[asians, are, fucking, everywhere, white, geno...</td>\n",
       "      <td>Asian, Hispanic</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>Asian</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20147</th>\n",
       "      <td>9998729_gab</td>\n",
       "      <td>the jewish globalist elite have only imported ...</td>\n",
       "      <td>[imported, few, million, muslims, to, multicul...</td>\n",
       "      <td>African, Islam, Jewish</td>\n",
       "      <td>offensive</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>African, Islam</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Islam, Jewish</td>\n",
       "      <td>offensive</td>\n",
       "      <td>African, Islam, Jewish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           post_id                                         tweet_text  \\\n",
       "20143  9989999_gab  if ur still on twitter tell carlton i said his...   \n",
       "20144  9990225_gab  when i first got on here and said i hate trump...   \n",
       "20145  9991681_gab  was macht der moslem wenn der zion gegen seine...   \n",
       "20146  9992513_gab  it is awful look at world demographics asians ...   \n",
       "20147  9998729_gab  the jewish globalist elite have only imported ...   \n",
       "\n",
       "                                            key_features  \\\n",
       "20143  [alcoholic, drug, addicted, teenage, single, m...   \n",
       "20144          [i, hate, trump, i, was, hating, niggers]   \n",
       "20145                                                 []   \n",
       "20146  [asians, are, fucking, everywhere, white, geno...   \n",
       "20147  [imported, few, million, muslims, to, multicul...   \n",
       "\n",
       "                        target       label annotator_1_label  \\\n",
       "20143  Men, None, Other, Women   offensive         offensive   \n",
       "20144     African, None, Other   offensive         offensive   \n",
       "20145       Islam, None, Other      normal         offensive   \n",
       "20146          Asian, Hispanic  hatespeech        hatespeech   \n",
       "20147   African, Islam, Jewish   offensive        hatespeech   \n",
       "\n",
       "      annotator_1_target annotator_2_label annotator_2_target  \\\n",
       "20143  Men, Women, Other         offensive               None   \n",
       "20144            African         offensive     African, Other   \n",
       "20145              Islam            normal              Other   \n",
       "20146           Hispanic        hatespeech              Asian   \n",
       "20147     African, Islam         offensive      Islam, Jewish   \n",
       "\n",
       "      annotator_3_label      annotator_3_target  \n",
       "20143            normal                    None  \n",
       "20144            normal                    None  \n",
       "20145            normal                    None  \n",
       "20146         offensive                   Asian  \n",
       "20147         offensive  African, Islam, Jewish  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rows = []\n",
    "for row in data.items():\n",
    "    post_id = row[1]['post_id']\n",
    "    post_tokens = row[1]['post_tokens']\n",
    "    rationales = row[1]['rationales']\n",
    "    annotators = row[1]['annotators']\n",
    "    tweet_text = \" \".join(post_tokens)\n",
    "\n",
    "    # Aggregate all rationales\n",
    "    combined_rationale = [any(rat[i] for rat in rationales) for i in range(len(post_tokens))] if rationales else [0] * len(post_tokens)\n",
    "\n",
    "    # Extract key features\n",
    "    key_features = [post_tokens[i] for i, is_key in enumerate(combined_rationale) if is_key]\n",
    "\n",
    "    annotator_data = {}\n",
    "    all_targets = set()  # To store unique targets\n",
    "    labels = []  # To collect labels for voting\n",
    "\n",
    "    for index, annotator in enumerate(annotators, start=1):  # Use index as annotator_id\n",
    "        annotator_data[f\"annotator_{index}_label\"] = annotator['label']\n",
    "        annotator_data[f\"annotator_{index}_target\"] = \", \".join(annotator['target']) if annotator['target'] else None\n",
    "\n",
    "        # Collect all targets\n",
    "        all_targets.update(annotator['target'])\n",
    "\n",
    "        # Collect labels for voting\n",
    "        labels.append(annotator['label'])\n",
    "\n",
    "    # Combine all unique targets\n",
    "    combined_target = \", \".join(sorted(all_targets))\n",
    "\n",
    "    # Perform majority voting for the label\n",
    "    label_counts = Counter(labels)\n",
    "    voted_label = label_counts.most_common(1)[0][0] if labels else None\n",
    "\n",
    "    # Create the row\n",
    "    row_data = {\n",
    "        \"post_id\": post_id,\n",
    "        \"tweet_text\": tweet_text,\n",
    "        \"key_features\": key_features,\n",
    "        \"target\": combined_target,\n",
    "        \"label\": voted_label,\n",
    "    }\n",
    "    row_data.update(annotator_data)  # Add annotator-related fields\n",
    "\n",
    "    rows.append(row_data)\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec781926-80ac-4f45-ab77-09094317610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filder data\n",
    "data = [\n",
    "    {key: d[key] for key in ('post_id', 'tweet_text', 'key_features', 'target', 'label')}\n",
    "    for d in rows\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6ac3444-60f2-4b27-a8dd-b49c9852ffaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'post_id': '1178534874602496000_twitter',\n",
       " 'tweet_text': '<user> <user> this is exactly the same as the argument that people who get raped when they were dressed scantily were asking for it you are lame af',\n",
       " 'key_features': [],\n",
       " 'target': 'None',\n",
       " 'label': 'normal'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see data\n",
    "data[10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009a9b75-09b3-4991-8f2e-e0cf5b44b3bd",
   "metadata": {},
   "source": [
    "# LLM for Explaination Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a15191c-f2f0-470f-bf96-4c0a8ca96589",
   "metadata": {},
   "source": [
    "## Configure LLM"
   ]
  },
  {
   "cell_type": "raw",
   "id": "474a2fc2-2329-4b8b-b67c-dd02644790de",
   "metadata": {},
   "source": [
    "Bellow Experiments, you can select any of these models by copy pasting the name in model_name\n",
    "\n",
    "Available Models:\n",
    "\n",
    "\"llama3.1:8b-instruct-q6_K\", \n",
    "\"gemma:7b-instruct-q6_K\",\n",
    "\"qwen2:72b-instruct-q6_K\",\n",
    "\"llama3.1:70b-instruct-q6_K\",\n",
    "\"phi3:14b-medium-128k-instruct-q6_K\",\n",
    "\"mixtral:8x7b-instruct-v0.1-q6_K\",\n",
    "\"mistral:7b-instruct-v0.2-q6_K\",\n",
    "\"llama3.3:70b-instruct-q6_K\",\n",
    "\"phi3.5:3.8b-mini-instruct-q6_K\",\n",
    "\"gemma2:27b-instruct-q6_K\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9bc462a-1fad-46c3-b400-71ffa0e549ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LLM inference function to use later\n",
    "API_URL = \"https://inf.cl.uni-trier.de/chat/\"\n",
    "\n",
    "def llm(model_name, system_prompt, input_query):\n",
    "    # Construct the request payload\n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\"content\": system_prompt, \"role\": \"system\"},\n",
    "            {\"content\": input_query, \"role\": \"user\"}\n",
    "        ],\n",
    "        \"model\": model_name,\n",
    "        \"options\": {}\n",
    "    }\n",
    "    \n",
    "    # Set the request headers\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    # Send the POST request\n",
    "    response = requests.post(API_URL, headers=headers, data=json.dumps(payload))\n",
    "    \n",
    "    # Process the response\n",
    "    if response.status_code == 200:\n",
    "        print(\"Response received successfully:\")\n",
    "        response = response.json() # json.dumps(, indent=4)\n",
    "    else:\n",
    "        print(f\"Failed to retrieve response. Status code: {response.status_code}\")\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69884f5d-15cb-4778-b867-b737314b7df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"post_id\": \"1178534874602496000_twitter\", \"tweet_text\": \"<user> <user> this is exactly the same as the argument that people who get raped when they were dressed scantily were asking for it you are lame af\", \"key_features\": [], \"target\": \"None\", \"label\": \"normal\"}'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Picking one row from dataset and converting it into string.\n",
    "user_input = json.dumps(data[10000])\n",
    "user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ead4106f-ae0e-4ecc-b055-1a69d8d3a240",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = \"\"\"\n",
    "Your Job is to analyze the tweet and write **Explaination** on it by taking inspiration from the examples bellow. \n",
    "Label -> Normal\n",
    "\n",
    "1.\n",
    "\"i know this is somewhat hypocritical but what the fuck is the deal with queer guys and slightly too small white tshirts\"\n",
    "\n",
    "Explanation:\n",
    "The tweet has been labeled normal because the user is solely expressing an observation. However the use of vulgar terms such as “fuck” may indicate that the user has a rather negative outlook towards topics concerning queers. Given that the context is not clear it may be understood as a neutral observation. The targets used within the dataset do not contain the word “queer” but the word homosexual. \n",
    "\n",
    "2.\n",
    "“wore a nipsey blue suit today only the niggers in the work place feel the energy”\n",
    "\n",
    "This tweet has been labeled normal because it seems to be a positive reference of paying tribute to the rapper nipsey hussle who is known for a specific shade of blue that is affiliated to the crib gang culture of LA.\n",
    "\n",
    "Explanation:\n",
    "The use of the term \"niggers\" is offensive and rooted in racism. Even if no direct harm or attack is evident, it perpetuates a derogatory term, which many systems and definitions include as hate speech. However, disagreement in labeling often arises due to contextual interpretations. Example for that could be Cultural or Social Context that goes Intended Meaning. In the tweet addition The phrase might be interpreted as describing a situation where the \"energy\" of the outfit is appreciated by a certain group, which could be seen as neutral, despite the offensive language.\n",
    "\n",
    "3. rafiullah shaheed a young man from levi force was shot dead by unknown men in muslim bagh a levies officer was killed in a bomb blast in lashkar gah on sunday while militants were also killed on the same day three people including mullahaniyev were killed in chaman\"\n",
    "\n",
    "Explanation:\n",
    "\n",
    "The statement is a factual report of events without any explicit derogatory, hateful, or harmful language targeting a specific individual or group based on characteristics like race, religion, or ethnicity. It lacks the intention to incite hate or violence, which is key to labeling content as hate speech.\n",
    "\n",
    "Label -> Offensive\n",
    " \n",
    "“pocahontas jumps in bed with moslem terrorists interesting combo”\n",
    "\n",
    "Explanation:\n",
    "This statement is labeled offensive because it uses derogatory language and stereotypes to insult and demean individuals or groups. Referring to someone as \"Pocahontas\" in a pejorative context is disrespectful, and associating them with \"Muslim terrorists\" perpetuates harmful stereotypes and biases, making the comment offensive and inappropriate.\n",
    "\n",
    "iIslamophobic you for real and how is islam a race you half wit\n",
    "\n",
    "It is labled offensive beacuse it contains an insult.\n",
    "\n",
    "\n",
    "treat the immigrants as drug traffickers they will soon have a change of mind\n",
    "This statement is offensive because it unjustly stereotypes immigrants as drug traffickers, promoting a harmful generalization that dehumanizes and criminalizes an entire group of people. Such language fosters prejudice, discrimination, and hostility toward immigrants. Furthermore it incitement to\n",
    "\n",
    " \n",
    "Label -> Hate Speech\n",
    "1)you niggas is fake asl that why you dont see none round me\n",
    "\n",
    "Explanation:\n",
    "This statement is classified as hate speech because it uses a racial slur (\"niggas\"), which is historically and culturally offensive, particularly against Black individuals. Even when used in some contexts as reclaimed language, its use in this statement appears derogatory, contributing to a hostile and discriminatory tone. The inclusion of aggressive language further amplifies its hateful nature.\n",
    "\n",
    "\n",
    "2) \"online nazi haha guys the left can not meme <number> white privilege diversity is our strength race is just skin color the holocaust racist sexist bigot homophobe islamophobe anti semite\"\n",
    "\n",
    "Explanation:\n",
    "This statement is hate speech because it mocks and trivializes serious societal issues, such as racism, sexism, and discrimination, using a sarcastic tone to dismiss terms like \"white privilege,\" \"diversity is our strength,\" and \"anti-Semite.\" By doing so, it undermines the significance of these issues and belittles those advocating for equality. References to \"Nazi\" and \"the Holocaust\" in a dismissive context further minimize historical atrocities and signal alignment with extremist ideologies. Overall, the statement ridicules efforts to address inequality and promotes hostility, making it hate speech.\n",
    "\n",
    "3) \"pro tip the niggers do not care if you never owned slaves granddaddy fought the natzis or great great grandad ground the confederacy into dust with the boot heel of the proto bolshevik yankee gubment force of weight and arms behind it they hate you because you are white and you exist altright\"\n",
    "\n",
    "Explanation:\n",
    "This statement is classified as hate speech because it uses the racial slur (\"niggers\"). The statement further vilifies an entire group by making sweeping generalizations, such as claiming that Black people \"hate you because you are white and you exist.\" This kind of language fosters an \"us vs. them\" narrative, portraying Black people as inherently hostile toward white people, which promotes racial division and resentment. The inclusion of terms like \"proto Bolshevik Yankee gubment force\" and \"altright\" reflects alignment with extremist ideologies often associated with white nationalism and discriminatory rhetoric. Additionally, references to historical events such as \"granddaddy fought the Nazis\" and \"great great grandad ground the Confederacy\" are weaponized to evoke a sense of pride in white heritage while simultaneously vilifying Black individuals. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52ec571d-08bd-4d52-9842-06e7624c9ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2 = \"\"\"\n",
    "As a hate speech specialist, your task is to analyze tweets to determine if they contain hate speech, offensive content, \n",
    "or are neutral. Hate speech can be conveyed through any form of expression. \n",
    "Hate speech is “discriminatory” (biased, bigoted, or intolerant) or “pejorative” (prejudiced, contemptuous, or demeaning) of an individual or group. \n",
    "Hate speech calls out real or perceived “identity factors” of an individual or a group, including: “religion, ethnicity, nationality, race, color, descent, gender,” \n",
    "but also characteristics such as language, economic or social origin, disability, health status, or sexual orientation, among many others.\n",
    "\n",
    "Here are some examples to illustrate:\n",
    "- \"Nigga\", \"Bitch\" // Offensive: This term is offensive as it historically derogates African Americans and Women.\n",
    "- \"A negro moslem doctor got struck off for negligence when a white <number> year old kid with down syndrome died; the guardian's response is to help promote a crowdfunding campaign for her\" // Hate speech: This statement is hate speech as it discriminates based on race and religion, promoting negative stereotypes.\n",
    "- \"Smiling cuz I am young black rich and I am handsome!\" // No hate speech: This expression is a positive self-description and does not target or degrade any other group.\n",
    "\n",
    "For each tweet provided, you will analyze:\n",
    "- tweet_text: The text of the tweet\n",
    "- key_features: Significant words or phrases identified in the tweet\n",
    "- target: The intended audience of the tweet\n",
    "- label: The classification of the tweet (hate speech, offensive, or neutral)\n",
    "\n",
    "Your explanation should discuss:\n",
    "- The context and user's intention behind the tweet.\n",
    "- Why the tweet falls into its assigned category based on the information provided.\n",
    "- How key features and the specific content of the tweet support your classification.\n",
    "\n",
    "This careful analysis is vital for improving our understanding and detection of hate speech, providing nuanced insights into how such speech can be identified and classified accurately.\n",
    "\n",
    "# Notes:\n",
    "1. Each explanation should be a single, comprehensive paragraph.\n",
    "2. Include insights into the tweet's context and the user's intent.\n",
    "3. Analyze the content through the lens of the provided hate speech definition, discussing the role of key features in your decision.\n",
    "4. Your detailed assessment will help refine the AI's capabilities in recognizing and differentiating between hate speech, offensive content, and neutral statements.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d2f3ec6-f6fb-45f0-ba2e-58d971efdd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_3 = \"\"\"\n",
    "You are tasked with providing a detailed explanation of why a given text is classified as hate speech, offensive, or neutral, based on annotations provided. Follow a step-by-step reasoning process to justify the classification, considering the context, user's intent, and linguistic features.\n",
    "\n",
    "The dataset provides the following information:\n",
    "- tweet_text: The main user text requiring explanation.\n",
    "- key_features: Words or phrases crucial to the decision.\n",
    "- target: The audience or group targeted by the text.\n",
    "- label: The classification of the text (hate speech, offensive, or neutral).\n",
    "\n",
    "Your job is to:\n",
    "1. Start by identifying the label of the text and summarizing what it indicates about the content.\n",
    "2. Analyze the key features and explain how they support the classification.\n",
    "3. Consider the target and evaluate how the text affects or refers to this group.\n",
    "4. Examine the overall context and tone to understand the user's intent.\n",
    "5. Conclude with a detailed explanation, justifying the classification and the reasoning behind it.\n",
    "\n",
    "Guidelines:\n",
    "- If the label is neutral, but you believe the text could be hate speech, explain why it is still considered neutral.\n",
    "- If the label is offensive, describe the nature of the offense and how the key features contribute to it.\n",
    "- Ensure the explanation is in one clear paragraph, summarizing the reasoning process.\n",
    "- Highlight what helped in making the decision and why the text is classified as it is.\n",
    "\n",
    "Here are examples for guidance:\n",
    "\n",
    "1. **Hate Speech**:\n",
    "   - tweet_text: \"All [group] people should be eliminated.\"\n",
    "   - key_features: [\"eliminated\", \"[group] people\"]\n",
    "   - target: A specific ethnic or religious group\n",
    "   - label: Hate Speech\n",
    "   Reasoning: \n",
    "   Step 1: The label is hate speech, which indicates that the content is intended to incite harm or violence against a group.  \n",
    "   Step 2: Key features like \"eliminated\" express a clear call for harm, targeting \"[group] people.\"  \n",
    "   Step 3: The target is a specific ethnic or religious group, making this statement particularly harmful.  \n",
    "   Step 4: The context and tone show a violent intention to exclude and harm the group.  \n",
    "   Conclusion: This text qualifies as hate speech due to its explicit incitement of violence and harm directed toward a specific group.\n",
    "\n",
    "2. **Offensive**:\n",
    "   - tweet_text: \"Why are men so bad at taking care of kids?\"\n",
    "   - key_features: [\"men\", \"bad at taking care\"]\n",
    "   - target: Men\n",
    "   - label: Offensive\n",
    "   Reasoning:\n",
    "   Step 1: The label is offensive, which suggests the text contains harmful stereotypes or derogatory assumptions.  \n",
    "   Step 2: Key features like \"bad at taking care\" perpetuate a stereotype that questions men’s abilities in caregiving.  \n",
    "   Step 3: The target is men, a group generalized and negatively characterized in this statement.  \n",
    "   Step 4: While the tone is not explicitly harmful, the language dismisses and demeans the target group.  \n",
    "   Conclusion: This text is offensive because it perpetuates a harmful stereotype about men, although it does not incite direct harm.\n",
    "\n",
    "3. **Neutral**:\n",
    "   - tweet_text: \"What’s everyone’s favorite food?\"\n",
    "   - key_features: None\n",
    "   - target: None\n",
    "   - label: Neutral\n",
    "   Reasoning:\n",
    "   Step 1: The label is neutral, meaning the text does not contain offensive or harmful language.  \n",
    "   Step 2: There are no key features or elements that suggest hostility, harm, or stereotypes.  \n",
    "   Step 3: The content is inclusive and general, without targeting any group or individual.  \n",
    "   Step 4: The context and tone are friendly and open-ended, with no intent to harm or offend.  \n",
    "   Conclusion: This text is neutral because it is non-controversial, lacks harmful language, and does not target any individual or group.\n",
    "\n",
    "Now, write an explanation for the given input using this reasoning framework.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e79c1f51-e7a6-46cd-8f00-d55685d2888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to select a range of 10 rows\n",
    "def pick_inputs(data, start_row, num_inputs=10):\n",
    "    if start_row + num_inputs > len(data):\n",
    "        raise ValueError(\"Start row plus number of inputs exceeds dataset size.\")\n",
    "    return data[start_row:start_row + num_inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e924c4-c475-4b59-a333-8996bb19d2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing LLM responses:   1%|██▋                                                                                                                                                                                                                                                    | 1/90 [01:14<1:50:22, 74.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response received successfully:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing LLM responses:   2%|█████▍                                                                                                                                                                                                                                                 | 2/90 [01:34<1:02:08, 42.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response received successfully:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing LLM responses:   3%|████████▎                                                                                                                                                                                                                                                | 3/90 [01:53<45:44, 31.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response received successfully:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "# Function to pick a range of inputs\n",
    "def pick_inputs(data, start_row, num_inputs=10):\n",
    "    if start_row + num_inputs > len(data):\n",
    "        raise ValueError(\"Start row plus number of inputs exceeds dataset size.\")\n",
    "    return data[start_row:start_row + num_inputs]\n",
    "\n",
    "# Models, prompts, and inputs\n",
    "models = [\n",
    "    \"mistral:7b-instruct-v0.2-q6_K\",\n",
    "    \"llama3.3:70b-instruct-q6_K\",\n",
    "    \"qwen2:72b-instruct-q6_K\"\n",
    "]\n",
    "prompts = [\n",
    "    prompt_1, \n",
    "    prompt_2, \n",
    "    prompt_3\n",
    "]\n",
    "inputs = pick_inputs(data, start_row=100, num_inputs=10)\n",
    "\n",
    "# Run all combinations with progress bar and retry logic\n",
    "results = []\n",
    "\n",
    "# Total number of combinations\n",
    "total_combinations = len(inputs) * len(prompts) * len(models)\n",
    "\n",
    "# Use tqdm for progress tracking\n",
    "with tqdm(total=total_combinations, desc=\"Processing LLM responses\") as pbar:\n",
    "    for model in models:\n",
    "        for prompt in prompts:\n",
    "            for input_text in inputs:\n",
    "                attempt = 0\n",
    "                time_taken = 0.0  # Initialize time taken\n",
    "                while attempt < 3:  # Retry up to 3 times\n",
    "                    try:\n",
    "                        start_time = time.time()  # Start timing\n",
    "                        response = llm(model, prompt, json.dumps(input_text))\n",
    "                        end_time = time.time()  # End timing\n",
    "                        time_taken = round(end_time - start_time, 2)  # Calculate time taken\n",
    "                        explanation = response['response']\n",
    "                        results.append({\n",
    "                            \"Model\": model,\n",
    "                            \"Prompt\": prompt,\n",
    "                            \"Input\": input_text,\n",
    "                            \"Response\": explanation,\n",
    "                            \"Time Taken (s)\": time_taken\n",
    "                        })\n",
    "                        break\n",
    "                    except Exception as e:\n",
    "                        attempt += 1\n",
    "                        if attempt == 3:\n",
    "                            # Log error and continue\n",
    "                            results.append({\n",
    "                                \"Model\": model,\n",
    "                                \"Prompt\": prompt,\n",
    "                                \"Input\": input_text,\n",
    "                                \"Response\": \"error\",\n",
    "                                \"Time Taken (s)\": time_taken\n",
    "                            })\n",
    "                            print(f\"Error after 3 retries: {e}\")\n",
    "                pbar.update(1)\n",
    "        break\n",
    "\n",
    "# Convert results to DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Save results to CSV\n",
    "df_results.to_csv(\"llm_results_with_retries.csv\", index=False)\n",
    "\n",
    "# Display the first few rows\n",
    "df_results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce4aabd-37ae-4e73-ad66-1aa1a5ed7125",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
