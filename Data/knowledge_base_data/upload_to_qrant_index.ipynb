{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9567b13d-37da-4ccb-8893-6d5527897833",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a3f356-7ed9-4538-8e18-cc28a3aea83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "!pip install sentence_transformers \n",
    "!pip install qdrant_client\n",
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45c51813-435f-46fa-ba29-c8f30da86341",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\MachineLearning\\UniTrier\\RCS\\twon-hate-speech-detection\\.venv\\Lib\\site-packages\\torchvision\\io\\image.py:14: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams, Batch\n",
    "from collections import Counter\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Change to the parent directory of the notebook\n",
    "# os.chdir('..')\n",
    "# os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b15f6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('TRAIN_DF.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "423702a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Input' in df.columns:\n",
    "    df = df.drop(columns=['Input', 'Time Taken (s)', 'Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c4e1ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.replace({np.nan: None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d47a1240",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd18839-ffed-4b3b-beb3-9ccbe60a6cd1",
   "metadata": {},
   "source": [
    "Here we make experiments with system prompt, \n",
    "\n",
    "System prompt contains : what model is supposed to do with the input query. with an exmple output.\n",
    "Input Query contains, one row of dataset.\n",
    "explaination variable will have the output of model which will be an explaination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fe7b5d-c64e-41ee-af07-dbe6d2b77f56",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81de4bb-5d53-4c15-ae64-4c8269a426e0",
   "metadata": {},
   "source": [
    "## Load Embeddings model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36247ff3-4124-404e-a9df-765218c17d80",
   "metadata": {},
   "source": [
    "If you are just experimenting with explainations and here to run LLM. then no need to run the cells in this section.\n",
    "\n",
    "Bellow there are 3 cells with 3 different type of models. uncomment the one suits best for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de1d121c-87cb-4693-8f85-fdb530925264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUNS superfast on CPU, Bad Results, good for old or weak laptop cpus, speed up testing\n",
    "\n",
    "# EMBEDDINGS_MODEL = SentenceTransformer('sentence-transformers/all-MiniLM-L12-v2', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "580fdcdc-e66e-4a9b-841b-db8329eaed3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RUNS superfast on CPU too, Good Results, works well on laptop with good cpu and laptop without GPU.\n",
    "\n",
    "# EMBEDDINGS_MODEL = SentenceTransformer(\n",
    "#     'jxm/cde-small-v1', trust_remote_code=True, device='cuda').to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6a38c7d-b7cc-4e08-a974-3b8bd11f180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY USE THIS IF YOU HAVE CUDA (NVIDIA GPU with 9 GB VRAM available:\n",
    "# RUNS superfast on GPU, Best Results.\n",
    "\n",
    "EMBEDDINGS_MODEL = SentenceTransformer(\"dunzhang/stella_en_1.5B_v5\", trust_remote_code=True, device='cuda') #.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd7c9c00-2c4b-4168-ace9-65cf3e8e6387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 46s\n",
      "Wall time: 13.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# benchmarking how much time it takes to create embeddings of 50 iters\n",
    "for i in range(50):\n",
    "    EMBEDDINGS_MODEL.encode(\"# testing how much time embeddings model take on your system\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "672bc77b-5526-4553-bc06-1408e7998099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dimension\n",
    "len(EMBEDDINGS_MODEL.encode(\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb486448-c637-4fd3-8361-8a7a56557fcd",
   "metadata": {},
   "source": [
    "## Configure Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9882e102-03ef-463f-8eaf-ec6c1ace8687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://7ef18c4d-2ef6-4fb0-9243-0ac62546593c.us-east4-0.gcp.cloud.qdrant.io:6333/dashboard#/collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39bfbab-fd77-4a11-86c8-85961d17f035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00d88b83-d2c8-4e1d-949d-6532420dacb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collections=[CollectionDescription(name='rcs_twon_index')]\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "qdrant_client = QdrantClient(\n",
    "    url=\"https://cf521759-86ad-49b4-b7f7-07fe3bb5f2ec.europe-west3-0.gcp.cloud.qdrant.io:6333\", \n",
    "    api_key=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.-Uof-NN6Q2IUWexHgY26SBVNHKIiJP32fF2gchKkWgI\",\n",
    ")\n",
    "\n",
    "print(qdrant_client.get_collections())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0010b1b-ba3a-4f9d-bc24-5122cf237279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker only\n",
    "# qdrant_client = QdrantClient(location='127.0.0.1', port=6333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6a407b5-d82a-475a-8bd2-438d5c01b4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(index_name):\n",
    "    qdrant_client.create_collection(\n",
    "        collection_name=index_name,\n",
    "        vectors_config=VectorParams(\n",
    "            size=len(EMBEDDINGS_MODEL.encode(\"\")), distance=Distance.DOT)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d95d3d7-46d9-45a3-bae1-de3a3283c8ee",
   "metadata": {},
   "source": [
    "You can browse the collections/indexes here:\n",
    "\n",
    "hhttps://cf521759-86ad-49b4-b7f7-07fe3bb5f2ec.europe-west3-0.gcp.cloud.qdrant.io:6333/dashboard#/collections\n",
    "\n",
    "and and enter the API: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.-Uof-NN6Q2IUWexHgY26SBVNHKIiJP32fF2gchKkWgI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79d5fe5-ed18-4051-bd16-734267230613",
   "metadata": {},
   "source": [
    "## Deploy | Upload dataset on RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c3c59fd-2546-4027-a3d9-0c123b8ddc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"rcs_twon_index_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47002354-dd3a-41b2-992e-83f75d4cca44",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93359e06-1cea-417a-a777-8c08450bb0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collections=[CollectionDescription(name='rcs_twon_index'), CollectionDescription(name='rcs_twon_index_1')]\n"
     ]
    }
   ],
   "source": [
    "print(qdrant_client.get_collections())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ebee5a2e-7468-445f-b999-80cbd27511a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data into index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcaee8c-22d0-4a18-a220-2879f722ba5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e83a1923-aa47-4baa-ac1e-5b3d72137acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert_in_qdrant_collection(data_list, data_list_embeddings, ids):\n",
    "    try:\n",
    "        qdrant_client.upsert(\n",
    "            collection_name=index_name,\n",
    "            points=Batch(\n",
    "                ids=ids,\n",
    "                vectors=data_list_embeddings,\n",
    "                payloads=data_list\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        # traceback.print_exc()\n",
    "        print(f\"Exception in create_embeddings_and_upsert {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9a9e897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Row Number': 2,\n",
       " 'Response': '<think>\\nOkay, so I\\'m trying to figure out why this tweet is classified as normal. The tweet says: \"we cannot continue calling ourselves feminists if the rights of all womxn aren\\'t addressed yes to a sexual offences public list but will a trans lesbian bisexual and queer womxn be able to enter their information on the reporting sheet gender forum\". \\n\\nFirst, I notice that the user is talking about feminism and ensuring that all women\\'s rights are addressed. They mention a sexual offenses public list, which sounds like a registry or something similar for people who commit sexual offenses. Then they ask if transgender, lesbian, bisexual, and queer women can enter their information on a reporting sheet related to gender forums.\\n\\nSo, the main points here are about inclusivity in feminism and ensuring that marginalized groups within the community have access and representation. The key features mentioned are \"womxn\", which is an inclusive term for women, often used to encompass all genders. They\\'re addressing different sexual orientations: trans, lesbian, bisexual, queer. \\n\\nLooking at the classification process steps:\\n1. The label is normal, so it doesn\\'t contain hate speech or offensive language.\\n2. Key features: \"womxn\" and various identities mentioned are inclusive terms, not derogatory or harmful.\\n3. Target group seems to be the feminist community and specific subgroups within it, but without any negative targeting.\\n4. The context is about advocacy for inclusivity and addressing systemic issues, so the tone is concerned but constructive.\\n\\nSince there\\'s no use of hate speech or offensive language, just a discussion about ensuring all groups are included in feminist efforts, it makes sense that this tweet is classified as normal. It\\'s promoting awareness and equality without attacking anyone.\\n</think>\\n\\n**Analysis:**\\n\\nThe tweet is classified as \"normal\" because it discusses inclusivity within feminism and raises concerns about the representation of marginalized groups. Key features include the use of inclusive language (\"womxn\") and mentions of various identities (trans, lesbian, bisexual, queer), all of which are presented in a constructive manner to advocate for equality. The target is the feminist community, aiming to highlight the need for comprehensive support without any negative targeting. The tone is concerned but focused on positive advocacy, lacking offensive or harmful language.\\n\\n**Conclusion:**\\n\\nThe tweet promotes inclusivity and awareness within feminism, using respectful and inclusive terms without any derogatory language, thus fitting the classification of \"normal.\"',\n",
       " 'tweet_text': 'nawt yall niggers ignoring me',\n",
       " 'key_features': '[]',\n",
       " 'label': 'normal',\n",
       " 'target': 'African, None'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c29c1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "\n",
    "# def clean_dict(data):\n",
    "#     data.pop('Input', None)\n",
    "\n",
    "#     # Replace NaN values with None\n",
    "#     for key, value in data.items():\n",
    "#         if isinstance(value, float) and np.isnan(value):\n",
    "#             data[key] = None\n",
    "\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21ecf8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d7e4f32-c0a6-4092-9d5b-792c1575d45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings_and_upsert(batch_size=1000):\n",
    "\n",
    "    print(\"Creating rows embeddings\")\n",
    "    ids = list(range(1, len(data) + 1))\n",
    "\n",
    "    for i in tqdm(range(0, len(data), batch_size)):\n",
    "        batch_data = data[i:i + batch_size]\n",
    "        batch_ids = ids[i:i + batch_size]\n",
    "\n",
    "        batch_data_list_embeddings = []\n",
    "        for row in batch_data:\n",
    "            payload = (\n",
    "                f\"tweet_text: {row['tweet_text']}\\n\"\n",
    "                f\"key_features: {row['key_features']}\\n\"\n",
    "                f\"target: {row['target']}\\n\"\n",
    "                f\"label: {row['label']}\\n\"\n",
    "                f\"explaination: {row['Response']}\\n\"\n",
    "                # WE add EXPLAINATIONS HERE\n",
    "                # f\"post_id: {row['post_id']}\"\n",
    "            )\n",
    "\n",
    "            batch_data_list_embeddings.append(EMBEDDINGS_MODEL.encode(payload))\n",
    "            # batch_ids.append(row['post_id'])\n",
    "\n",
    "        # Call the Qdrant function\n",
    "        upsert_in_qdrant_collection(\n",
    "            batch_data, batch_data_list_embeddings, batch_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58927144-418f-49a0-968f-415dda313982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating rows embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                      | 779/907 [20:48<03:46,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in create_embeddings_and_upsert Unexpected Response: 400 (Bad Request)\n",
      "Raw response content:\n",
      "b'{\"status\":{\"error\":\"Format error in JSON body: data did not match any variant of untagged enum BatchVectorStruct\"},\"time\":0.0}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 907/907 [24:34<00:00,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 20min 28s\n",
      "Wall time: 24min 34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "create_embeddings_and_upsert(batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1344a801-805a-4e8a-8715-b1392428a5a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "861.6121917963028"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_size = 322663509  # bytes\n",
    "limit = 33554432  # bytes\n",
    "\n",
    "# Calculate percentage larger\n",
    "percentage_larger = ((file_size - limit) / limit) * 100\n",
    "percentage_larger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7121406-68f5-45a2-84f1-1c9bc964bdf2",
   "metadata": {},
   "source": [
    "## Query RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c87b359-e21c-4d6e-b655-38b0d79186d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"paki\"\n",
    "top_k = 3\n",
    "embedding = EMBEDDINGS_MODEL.encode(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "afe8c186-f7c2-4b3c-86c6-1347ea59a612",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usama\\AppData\\Local\\Temp\\ipykernel_36676\\3195492518.py:1: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_result = qdrant_client.search(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ScoredPoint(id=8573, version=428, score=1024.6355, payload={'Row Number': 9522, 'Response': 'This tweet contains hate speech aimed at Pakistani women. Key features of the post include:\\n\\n1) The use of a derogatory term (\"paki\") to refer to an ethnic group.\\n2) A stereotypical and demeaning comment about the appearance/body modification choices of the targeted group (belly piercing).\\n3) The implication that this appearance is related to the \"attachment\" of air fresheners.\\n\\nThe tone and intent appear mocking and degrading towards Pakistani women. Additionally, using such a slur targets the nationality, gender, religion and race, making it hate speech.\\n\\nIn conclusion, based on the discriminatory language, stereotyping, and targeting of a specific group in this post, I classify it as hate speech aimed at demeaning Pakistani women.', 'tweet_text': 'why do paki women always have pierced belly buttons so they can attach the air freshener', 'key_features': \"['why', 'do', 'paki', 'women', 'always', 'have', 'pierced', 'belly', 'buttons', 'so', 'they', 'can', 'attach', 'the', 'air', 'freshener']\", 'label': 'hatespeech', 'target': 'Asian, Islam, None, Women'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=993, version=49, score=981.2903, payload={'Row Number': 1116, 'Response': 'The text is classified as hate speech due to the following key factors:\\r\\n\\r\\n1. The tweet directly associates Pakistan, a Muslim-majority country, with terrorism.\\r\\n2. Key features such as \"muslim,\" \"country,\" \"produces,\" and \"terrorists\" collectively create an inflammatory statement that fosters animosity towards Islam and Pakistanis.\\r\\n3. By claiming Pakistan \"produces terrorists,\" the text vilifies an entire nation and religion, contributing to a hostile stereotype.\\r\\n4. The context reveals a clear intent to disparage and provoke by linking a specific country with terrorism based on its religious demographics.\\r\\n5. In conclusion, this tweet is classified as hate speech because it aggressively targets Islam and Pakistanis, promoting prejudice and hostility through a direct association with terrorism.', 'tweet_text': 'black ppl who went to all white schools become annoying ass adults üòÇ üòÇ üòÇ üòÇ', 'key_features': '[]', 'label': 'normal', 'target': 'Caucasian, None'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=13668, version=683, score=950.5149, payload={'Row Number': 11200, 'Response': 'The text in question is classified as normal. The tweet simply suggests checking out offers on a Nissan Micra, which is a straightforward recommendation about a product without any controversial content or targeted language. The tone of the message is neutral and does not aim to offend or target any specific group, making it an innocuous piece of information sharing. Therefore, based on its lack of negativity or harm towards others, the tweet can be classified as normal.', 'tweet_text': 'guus check out the anazing offers on the streetsmartsensation nissan micra <user>', 'key_features': '[]', 'label': 'normal', 'target': None}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=1925, version=96, score=946.025, payload={'Row Number': 2153, 'Response': 'The text is classified as normal. While the term \"hillbilly\" can be considered a stereotype or slur in some contexts, here it appears to be used humorously and self-referentially by the user. The key phrase \"i would take offense to that if it were not funny\" suggests that the user acknowledges the potential offensiveness of the term but finds its usage acceptable due to its humorous intent. There is no apparent target or group being attacked or denigrated, making this a casual and non-malicious exchange.', 'tweet_text': '<user> why d they all isra a muzzie', 'key_features': '[]', 'label': 'normal', 'target': 'Islam, None'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=1082, version=54, score=944.6208, payload={'Row Number': 1212, 'Response': 'The tweet is classified as offensive due to its use of the term \"paki,\" which is a known slur targeting people of Pakistani or Muslim background. The key features that support this classification include:\\r\\n\\r\\n1. **Derogatory Language**: The word \"paki\" is a derogatory term used to demean individuals of Pakistani origin or, more broadly, those who appear to be from the Indian subcontinent and follow Islam.\\r\\n   \\r\\n2. **Context**: In the tweet, \"little Johnny\" uses the slur in response to a question about Pakistan\\'s location, associating it with an individual named Steve, implying that the person is somehow connected to Pakistan or its culture.\\r\\n\\r\\n3. **Impact on Target Group**: The use of \"paki\" directly targets individuals of Pakistani heritage and Muslims by extension, perpetuating negative stereotypes and potentially inciting hostility against these groups.\\r\\n\\r\\n4. **Intent**: Though presented humorously, the intent appears to be mocking or belittling through the use of a pejorative term in a classroom setting, which exacerbates the offense due to the educational context where respect and sensitivity are expected.\\r\\n\\r\\nIn conclusion, the tweet is deemed offensive because it employs a recognized slur in an unnecessary and derisory manner, reinforcing negative biases against Pakistani individuals and those perceived as such. The classification is justified by the presence of key inflammatory language that targets a specific ethnic and religious group.', 'tweet_text': 'sadiq khan a nasty paki muslim said this is part and parcel of life in london and wants all non muslims out of london so he can bring in <number> million more muslims <number> fucked up mps are all for it know thy enemy', 'key_features': \"['nasty', 'paki', 'muslim', 'all', 'non', 'muslims', 'out', 'of', 'london', 'million', 'more', 'muslims']\", 'label': 'hatespeech', 'target': 'Islam'}, vector=None, shard_key=None, order_value=None)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result = qdrant_client.search(\n",
    "    collection_name=index_name, query_vector=embedding, limit=5\n",
    ")\n",
    "search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63e53034-ad31-4cd6-9226-6d7c1a3d56ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Row Number': 188,\n",
       " 'tweet_text': 'what a pakis favorite clothing brand jihadidas',\n",
       " 'key_features': \"['pakis', 'jihadidas']\",\n",
       " 'label': 'offensive',\n",
       " 'target': 'Indian, Islam',\n",
       " 'Response': 'The tweet is classified as offensive due to its use of the term \"pakis,\" which is a derogatory slang for people from Pakistan or those perceived as such. This slur targets individuals based on their nationality and potentially their religious affiliation (Islam), contributing to the classification.\\r\\n\\r\\nThe key feature supporting this label is the combination of the word \"pakis\" with \"jihadidas.\" The latter term mocks and derides Islamic culture by blending \"Jihad,\" often wrongly associated with violence in a Western context, with the sportswear brand Adidas. This creates a phrase that offensively stereotypes an entire group based on their religion and nationality.\\r\\n\\r\\nThe tweet\\'s target is clearly specified as individuals of Indian descent (which could imply Pakistanis due to historical context) and Islam. The use of the slur \"pakis\" directly insults this demographic, creating a hostile environment.\\r\\n\\r\\nConsidering these factors, it\\'s evident that the intent behind the tweet was not benign but aimed at demeaning and insulting the target group through culturally insensitive language and stereotypes. This justifies its classification as offensive content.',\n",
       " 'Time Taken (s)': 25.06}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result[0].payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ca3cd5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ScoredPoint(id=1792, version=92, score=21.119978, payload={'Row Number': 1792, 'tweet_text': '<user> this dumb bitch killed <number> rabbits in her failed raid this is who you guys praise you guys are the problem not the farmers', 'key_features': \"['dumb', 'bitch']\", 'label': 'offensive', 'target': 'None, Women', 'Response': '**Offensive**:\\r\\n- The tweet contains strong language and insults directed at a user, specifically using gendered slurs (\"dumb bitch\").\\r\\n- It criticizes the individual for causing harm to animals which further intensifies the negative sentiment.\\r\\n- Despite not explicitly naming a group, the language used is hostile and denigrating towards women.\\r\\n- This classification is justified by the inflammatory tone and usage of targeted insults.', 'Time Taken (s)': 9.29}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=605, version=33, score=20.767206, payload={'Row Number': 605, 'tweet_text': 'rick ripping that guys throat out to save carl from getting raped by that old hillbilly top <number> savage twd moments', 'key_features': \"['raped', 'by', 'that', 'old', 'hillbilly']\", 'label': 'offensive', 'target': 'Caucasian, None', 'Response': '**Offensive**:\\r\\n- tweet_text: \"rick ripping that guys throat out to save carl from getting raped by that old hillbilly top <number> savage twd moments\"\\r\\n- Key features include the mention of a violent act (\"ripping that guy\\'s throat out\") and a sexual assault (\"raped\"). The use of the term \"old hillbilly\" to describe the perpetrator adds an element of mockery towards rural, less educated populations.\\r\\n- This tweet is classified as offensive due to its graphic depiction of violence, reference to sexual assault, and the demeaning portrayal of a specific group based on cultural stereotypes.', 'Time Taken (s)': 15.18}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=106, version=8, score=20.463829, payload={'Row Number': 106, 'tweet_text': 'create a list destabilizing violence', 'key_features': '[]', 'label': 'normal', 'target': None, 'Response': 'The tweet \"create a list destabilizing violence\" is classified as normal. Although it contains the term \"destabilizing violence,\" which might seem concerning, there are no specific key features or targets identified that would categorize this as hate speech or overtly offensive.\\r\\n\\r\\nThe context and tone of the message do not appear to advocate for or encourage violence. Without additional information about the user\\'s intent or a clear connection to any targeted group, it is difficult to classify this as anything other than neutral or normal discourse.\\r\\n\\r\\nIn conclusion, based on the provided text alone, which lacks explicit targets or inherently inflammatory language, and considering the absence of identifiable key features that would suggest otherwise, the classification of \"normal\" is justified.', 'Time Taken (s)': 14.26}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=1346, version=70, score=20.285038, payload={'Row Number': 1346, 'tweet_text': '<user> kill yourself o üôÑ', 'key_features': \"['kill', 'yourself']\", 'label': 'offensive', 'target': None, 'Response': 'The tweet is classified as **Offensive** due to the presence of key phrases like \"kill yourself\" which are explicitly harmful and promote self-harm. The tone of the text suggests an aggressive intent towards the target, which further reinforces its offensiveness. Although no specific group is targeted, the message itself carries a threatening and damaging connotation that could potentially encourage dangerous behavior or create a hostile environment.', 'Time Taken (s)': 9.76}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=2158, version=110, score=19.153694, payload={'Row Number': 2158, 'tweet_text': 'pac said all you mfs fuck you too fuck u die slow mfs my <number> make sure all you all kid do not grow', 'key_features': '[]', 'label': 'normal', 'target': 'None, Women', 'Response': '{\"post_id\": \"1178873120804999169_twitter\", \"tweet_text\": \"pac said all you mfs fuck you too fuck u die slow mfs my <number> make sure all you all kid do not grow\", \"key_features\": [\"fuck you too\", \"die slow\"], \"target\": \"Women\", \"label\": \"hate speech\"}\\r\\n\\r\\nThe text contains aggressive language and threats directed towards women, which classifies it as hate speech. The key features \"fuck you too\" and \"die slow\" are explicitly hostile and convey a strong intent to harm or offend. There\\'s no context that could dilute the severity of these terms.\\r\\n\\r\\nDespite its normal label suggestion, the presence of direct threats (\"die slow\") and severe profanity aimed at women, makes this text clearly fall into the hate speech category. Its aggressive tone and hostile language are not excusable under any circumstance.', 'Time Taken (s)': 18.14}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=1763, version=91, score=19.065142, payload={'Row Number': 1763, 'tweet_text': 'your target is here go get these filthy shit skin moslem terrorists', 'key_features': \"['filthy', 'shit', 'skin', 'moslem', 'terrorists']\", 'label': 'hatespeech', 'target': 'Islam, Minority, Other', 'Response': '**Hate Speech**:\\r\\n\\r\\n- The tweet targets Muslim and minority communities with a string of highly derogatory terms such as \"filthy,\" \"shit skin,\" and \"moslem terrorists.\"\\r\\n- Key features include the usage of slurs and dehumanizing language, which are intended to incite hatred or violence against the targeted groups.\\r\\n- By labeling an entire religious community as \"terrorists\" based on their faith, the tweet promotes bigotry and encourages hostility towards these groups. This is a clear case of hate speech, as it advocates for harm against individuals due to their religion and ethnicity.\\r\\n- The tone is aggressive and inflammatory, suggesting an intent to provoke conflict or promote animosity.\\r\\n\\r\\nIn conclusion, this text\\'s classification as hate speech is justified by its use of extreme, dehumanizing language targeting specific religious and ethnic groups, with the clear intention of inciting hostility or violence against them.', 'Time Taken (s)': 17.9}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=689, version=37, score=18.786518, payload={'Row Number': 689, 'tweet_text': '<user> <user> <user> <user> <user> <user> <user> <user> <user> <user> <user> <user> <user> <user> <user> <user> <user> <user> <user> <user> <user> <user> <user> <user> <user> ur r shudh <number> percent photoshop fake jihadi', 'key_features': '[]', 'label': 'normal', 'target': None, 'Response': 'Based on the provided tweet text and analysis framework:\\r\\n\\r\\n1. The label \\'normal\\' suggests that this tweet does not contain hate speech or explicitly offensive content.\\r\\n\\r\\n2. There are no key features mentioned that would support a different classification. \\r\\n\\r\\n3. Without an explicit target group mentioned, it\\'s difficult to assess any intended impact or reference. \\r\\n\\r\\n4. The context and tone seem casual, with multiple user mentions which could indicate a conversation or discussion among users.\\r\\n\\r\\n5. Conclusion: The tweet appears to be a part of a conversation without clear hate speech or direct offense towards any group, supporting its \\'normal\\' classification. However, the phrase \"photoshop fake jihadi\" might raise questions about its intent and meaning, but based solely on this text snippet, it\\'s not sufficient to categorize it as hate speech or offensive.', 'Time Taken (s)': 19.79}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=126, version=9, score=18.776474, payload={'Row Number': 126, 'tweet_text': 'overthink can kill yourself too <happy>', 'key_features': '[]', 'label': 'normal', 'target': None, 'Response': 'The text \"overthink can kill yourself too <happy>\" falls into the normal category. This classification is based on several factors:\\r\\n\\r\\n1. The message implies that overthinking can lead to self-harm or mental distress, which is a general observation and not targeted at any specific group.\\r\\n2. There are no key features like slurs, insults, or provocative language that would suggest hate speech or offensiveness.\\r\\n3. The absence of a defined target group further supports its neutral standing.\\r\\n\\r\\nThe tone seems to convey a lighthearted warning about the dangers of overthinking but is not intended to cause harm or offense. Hence, it\\'s classified as normal due to lack of aggressive language and any reference to sensitive topics or groups.', 'Time Taken (s)': 16.87}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=2959, version=150, score=18.652317, payload={'Row Number': 2959, 'tweet_text': '<user> i fucking hate you bro üíÄ üíÄ üíÄ', 'key_features': '[]', 'label': 'normal', 'target': None, 'Response': 'The given tweet falls into the category of **Offensive**. \\r\\n\\r\\n1. The text uses aggressive language directed at another user, specifically the phrase \"i fucking hate you bro\". \\r\\n2. The key features here are the usage of strong expletives and expressions of intense dislike which contribute to the hostile tone.\\r\\n3. Although no specific group is targeted, the tweet employs harsh language towards an individual, creating a negative environment.\\r\\n4. The context seems to be one of interpersonal conflict or disagreement, with the user expressing their animosity through vulgar terms.\\r\\n5. In conclusion, while not rising to the level of hate speech due to lack of targeting based on protected characteristics, the aggressive and vulgar language used in this tweet classifies it as offensive.', 'Time Taken (s)': 18.19}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=1232, version=64, score=18.523352, payload={'Row Number': 1232, 'tweet_text': 'this sumbitch is not part of wtp and <number> stupid motherfuckers liking his post these bastards are not awake for the goddam record all <number> billion of those goat fucking moslem bastards needs to be eradicated from the planet leave none alive from the womb to the tomb they gotta go', 'key_features': \"['sumbitch', 'stupid', 'motherfuckers', 'bastards', 'goat', 'fucking', 'moslem', 'bastards', 'needs', 'to', 'be', 'eradicated', 'from', 'the', 'planet', 'leave', 'none', 'alive', 'from', 'the', 'womb', 'to', 'the', 'tomb', 'they', 'gotta', 'go']\", 'label': 'hatespeech', 'target': 'Arab, Islam', 'Response': '**Hate Speech**:\\r\\n- The tweet uses highly aggressive and hostile language such as \"sumbitch,\" \"stupid motherfuckers,\" \"bastards,\" \"goat fucking moslem bastards,\" calling for the eradication of all Muslims from the planet. \\r\\n- Key features include derogatory terms like \"sumbitch\" and \"motherfuckers\" that target individuals, coupled with genocidal rhetoric against a religious group (\"moslem bastards\"), indicating intent to incite violence.\\r\\n- The reference to \"wtp\" likely stands for \"White Trash Party,\" indicating the tweet targets Arab and Islamic groups.\\r\\n- The tweet\\'s extreme tone advocating eradication of all Muslims from \"the womb to the tomb\" leaves no doubt as to its classification as hate speech. Its virulent, dehumanizing language aimed at provoking violence against a religious group is the epitome of hate speech.\\r\\n\\r\\nIn conclusion, the tweet\\'s use of aggressive slurs and explicit calls for genocidal actions against a specific religious group (\"moslem bastards\") due to their identity, along with hostile generalizations about all members of this group being worthy of eradication, unambiguously qualifies it as hate speech. The key features leave no room for interpretation other than the intent to incite violence and promote eliminationist ideology targeting Muslims.', 'Time Taken (s)': 32.37}, vector=None, shard_key=None, order_value=None)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = \"Burn them\"\n",
    "top_k = 10\n",
    "embedding = EMBEDDINGS_MODEL.encode(user_input)\n",
    "search_result = qdrant_client.search(\n",
    "    collection_name=index_name, query_vector=embedding, limit=top_k\n",
    ")\n",
    "search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ef6373f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ScoredPoint(id=689, version=37, score=18.6327, payload={'Row Number': 689, 'tweet_text': '<user> <user> <user> <user> <user> <user> <user> <user> <user> <user> <user> <user> <user> <user> <user> <user> <user> <user> <user> <user> <user> <user> <user> <user> <user> ur r shudh <number> percent photoshop fake jihadi', 'key_features': '[]', 'label': 'normal', 'target': None, 'Response': 'Based on the provided tweet text and analysis framework:\\r\\n\\r\\n1. The label \\'normal\\' suggests that this tweet does not contain hate speech or explicitly offensive content.\\r\\n\\r\\n2. There are no key features mentioned that would support a different classification. \\r\\n\\r\\n3. Without an explicit target group mentioned, it\\'s difficult to assess any intended impact or reference. \\r\\n\\r\\n4. The context and tone seem casual, with multiple user mentions which could indicate a conversation or discussion among users.\\r\\n\\r\\n5. Conclusion: The tweet appears to be a part of a conversation without clear hate speech or direct offense towards any group, supporting its \\'normal\\' classification. However, the phrase \"photoshop fake jihadi\" might raise questions about its intent and meaning, but based solely on this text snippet, it\\'s not sufficient to categorize it as hate speech or offensive.', 'Time Taken (s)': 19.79}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=495, version=27, score=16.15483, payload={'Row Number': 495, 'tweet_text': '<user> <user> <user> you are a vanilla isis thug engaging in targeted harassment of me for exposing truth about jewish participation in white supremacy backed by jewish publications authors truth is only anti semitic to descendants of slavetrading colonizers who wish to sustain their impunity', 'key_features': '[]', 'label': 'normal', 'target': None, 'Response': 'The provided text cannot be accurately classified without identifying the key features and target group. Please provide these details for an accurate analysis.', 'Time Taken (s)': 3.63}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=1757, version=90, score=15.755769, payload={'Row Number': 1757, 'tweet_text': '<user> hello mr prime minister please help me üôè i am a refugee from afghanistan in indonesia since <number> i got the refugee card from unhcr in <number> and i am still waiting for the resettlement please help me for resettlement no job no hope for life no future please üôè üò¢', 'key_features': '[]', 'label': 'normal', 'target': None, 'Response': \"This text falls into the neutral category. The user is reaching out to a prime minister for assistance with their refugee status in Indonesia, expressing a sense of desperation and hopelessness due to lack of job prospects and uncertainty about resettlement.\\r\\n\\r\\nKey features supporting this classification include:\\r\\n- The use of emojis conveying emotional distress (\\\\ud83d\\\\ude4f and \\\\ud83d\\\\ude22).\\r\\n- Reference to being a refugee from Afghanistan without any negative or stereotypical connotations.\\r\\n- Request for help with resettlement, highlighting the challenging living conditions and lack of job opportunities.\\r\\n\\r\\nThe tone is pleading yet polite, without any elements of hate speech or offensiveness. The user's intent appears to be seeking genuine assistance from a figure of authority due to their dire situation.\\r\\n\\r\\nIn conclusion, this text is classified as neutral because it lacks inflammatory language, does not target any specific group negatively, and primarily conveys the individual's personal plight and plea for help.\", 'Time Taken (s)': 23.03}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=755, version=40, score=15.161642, payload={'Row Number': 755, 'tweet_text': 'well now that that over time for me to hoe out üíÉ üèª', 'key_features': '[]', 'label': 'normal', 'target': None, 'Response': '**Neutral**:\\r\\n- tweet_text: \"well now that that over time for me to hoe out üê≥üá´\"\\r\\n- This text contains no identifiable hate speech or explicitly offensive content. It seems to express a personal sentiment about moving on from an unspecified event, using casual language and emojis.\\r\\n- The informal tone and absence of any targeted or inflammatory language make this tweet neutral. It lacks context that would suggest malicious intent or harm towards any group or individual.', 'Time Taken (s)': 11.42}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=2511, version=128, score=15.044951, payload={'Row Number': 2511, 'tweet_text': '<user> <user> maybe for the future you could post any queer couples if you want', 'key_features': '[]', 'label': 'normal', 'target': 'Homosexual, None', 'Response': 'The text is classified as neutral due to its lack of controversial or targeted language. The user suggests posting content related to queer couples in the future, which does not promote hate or offense towards any group. Instead, it encourages inclusiveness and representation of diverse relationships. This recommendation reflects a positive intent and acknowledges the importance of varied perspectives. Therefore, the text is neutral as it poses no harm or insult to any target audience.', 'Time Taken (s)': 10.32}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=794, version=42, score=14.540703, payload={'Row Number': 794, 'tweet_text': 'been networking with a lot of black and hispanic women', 'key_features': '[]', 'label': 'normal', 'target': None, 'Response': '**Neutral**\\r\\n\\r\\n- The tweet text mentions the user has been networking with black and Hispanic women. \\r\\n- There are no key features that indicate hate speech or offensiveness.\\r\\n- The tone is neutral and factual, discussing professional networking activities.\\r\\n- This does not target any group negatively nor uses inflammatory language.\\r\\n\\r\\nConclusion: The tweet is classified as normal due to its non-offensive content and the absence of targeted or inflammatory language.', 'Time Taken (s)': 10.24}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=407, version=23, score=14.5045185, payload={'Row Number': 407, 'tweet_text': 'i know its hard being queer in the lgbt community generally so positive vibes for everyone ‚òÜ ‚ô° ‚òÜ', 'key_features': '[]', 'label': 'normal', 'target': None, 'Response': 'The tweet is classified as neutral because it expresses a supportive sentiment towards the queer community. The usage of emojis further enhances this supportive tone without targeting or offending any group. The overall message promotes positivity and understanding, which aligns with our criteria for a neutral classification.', 'Time Taken (s)': 6.67}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=1979, version=101, score=14.211968, payload={'Row Number': 1979, 'tweet_text': 'if twitter dm had an unsend option chats be like hi i like you hey hello this message was deleted you are beautiful helloo deleted texts fuck you bitch slut whore', 'key_features': '[]', 'label': 'normal', 'target': 'None, Women', 'Response': '**Normal**:\\r\\n- tweet_text: \"if twitter dm had an unsend option chats be like hi i like you hey hello this message was deleted you are beautiful helloo deleted texts fuck you bitch slut whore\"\\r\\n- Although the text contains profanity and harsh language towards the end, it is presented in a hypothetical context of messages being deleted.\\r\\n- The initial part includes friendly greetings and compliments, suggesting a playful or joking tone rather than genuine malice.\\r\\n- While the strong language may be considered crude, it lacks the clear intent to harm or marginalize that would classify it as hate speech.\\r\\n- Without additional context implying targeted abuse or aggression, this text falls into the normal category due to its speculative nature and lack of direct offense against a specific individual or group.', 'Time Taken (s)': 15.34}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=727, version=39, score=13.944761, payload={'Row Number': 727, 'tweet_text': '<user> when i see or hear news about any country electing a moslem politician it like getting news of someone dying of a deadly disease then just waiting for their name to show on the obituaries in the coming days weeks or months', 'key_features': '[]', 'label': 'normal', 'target': None, 'Response': '{\"analysis\": \"**Normal**:\\\\n- tweet_text: \\\\\"<user> when i see or hear news about any country electing a moslem politician it like getting news of someone dying of a deadly disease then just waiting for their name to show on the obituaries in the coming days weeks or months\\\\\"\\\\n- While expressing personal disapproval towards Muslim politicians, the text avoids explicitly hateful language or direct attacks. It employs an unfavorable comparison but lacks clear incitement or targeted offense. The absence of specific derogatory terms and a generalized tone suggests a critical opinion rather than promoting hate, placing it in the normal category despite its negative sentiment.\"}', 'Time Taken (s)': 15.47}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=2344, version=120, score=13.92658, payload={'Row Number': 2344, 'tweet_text': 'all this crap with trump may be going on does not mean i can not wish my dear naija a happy 5 9 th üá≥ üá¨ üá≥ üá¨ ‚ù§Ô∏è ‚ù§Ô∏è naijaat59 nigeria at 59 nigeria independence africa', 'key_features': '[]', 'label': 'normal', 'target': None, 'Response': \"The text is classified as neutral for the following reasons:\\r\\n\\r\\n1. The tweet expresses a personal sentiment about wishing Nigeria a happy 59th Independence Day, without targeting any specific group or individual.\\r\\n2. It lacks key features such as derogatory language, controversial statements, or direct attacks on individuals or communities that would classify it as hate speech or offensive.\\r\\n3. The context of the message is celebratory and positive towards Nigeria's independence anniversary, reflecting a user intent to spread goodwill.\\r\\n\\r\\nIn conclusion, the neutral classification is justified by the absence of any elements of hate speech or offensiveness in the text. It focuses on celebrating a national event without causing harm or offense to any group, upholding a tone of positivity and cultural appreciation.\", 'Time Taken (s)': 17.93}, vector=None, shard_key=None, order_value=None)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = \"Go back to your country\"\n",
    "top_k = 10\n",
    "embedding = EMBEDDINGS_MODEL.encode(user_input)\n",
    "search_result = qdrant_client.search(\n",
    "    collection_name=index_name, query_vector=embedding, limit=top_k\n",
    ")\n",
    "search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4d3c8072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ScoredPoint(id=1290, version=67, score=27.500534, payload={'Row Number': 1290, 'tweet_text': 'nigger queers are the worst', 'key_features': \"['nigger', 'queers', 'are', 'the', 'worst']\", 'label': 'hatespeech', 'target': 'African, Homosexual', 'Response': 'The text \"nigger queers are the worst\" falls into the hate speech category due to its use of highly derogatory and inflammatory language. The key features that support this classification include the slurs \"nigger\" and \"queers,\" which target African Americans and homosexuals respectively, both historically marginalized groups.\\r\\n\\r\\nThis tweet\\'s impact on these communities is significant, as it employs language intended to degrade and insult based solely on race and sexual orientation. The user\\'s intent appears to be maligning these groups without any context that might mitigate the offensiveness.\\r\\n\\r\\nIn conclusion, by combining extremely pejorative terms for African Americans and homosexuals in a negative statement, this text unequivocally qualifies as hate speech aimed at vilifying these communities based on their inherent characteristics.', 'Time Taken (s)': 18.02}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=886, version=47, score=27.236507, payload={'Row Number': 886, 'tweet_text': 'actually you are just another stupid fucking nigger with a big mouth and a porous brain nobody worthy of knowing takes anything you say or do seriously fucking niggers raw sewage that needs to be flushed immediately', 'key_features': \"['fucking', 'nigger', 'fucking', 'niggers']\", 'label': 'hatespeech', 'target': 'African', 'Response': 'The text is classified as hate speech due to its use of highly derogatory language targeting African individuals. Key features such as \"fucking nigger\" and \"fucking niggers\" are slurs that dehumanize and incite violence against the target group. The aggressive tone and intent to harm through phrases like \"raw sewage that needs to be flushed immediately\" further solidify this classification. The user\\'s aim is to demean, threaten, and promote hostility towards African people, making it a clear case of hate speech.', 'Time Taken (s)': 11.6}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=986, version=52, score=27.10902, payload={'Row Number': 986, 'tweet_text': 'found that psychopath guilty bitch want have to worry about texting gone get all the attention she needs them bull dykes waiting üòÇ üòÇ üòÇ', 'key_features': \"['bitch', 'bull', 'dykes']\", 'label': 'hatespeech', 'target': 'Homosexual, Women', 'Response': \"The text is classified as hate speech due to the inclusion of aggressive language and derogatory terms targeting women and the homosexual community. Key features such as 'bitch,' 'bull,' and 'dykes' are used in a negative context, contributing to an environment of hostility. The text suggests intent to cause harm or discomfort to these groups, further solidifying its classification as hate speech.\", 'Time Taken (s)': 9.53}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=2068, version=106, score=26.253334, payload={'Row Number': 2068, 'tweet_text': 'cuz these niggas wanna take my life no weapon formed against me everything i pray at night scooping thotties in this benz that the way of life and make them fuck they best friends like they was dykes', 'key_features': \"['niggas', 'thotties', 'dykes']\", 'label': 'offensive', 'target': 'African, Homosexual, Women', 'Response': \"The text is classified as **Offensive** due to its use of highly inflammatory and derogatory language targeting multiple groups.\\r\\n\\r\\n1. The term 'niggas' is a blatant racial slur against African Americans.\\r\\n2. The phrase 'scooping thotties' objectifies women, using a slang term that demeans them.\\r\\n3. Referring to individuals as 'dykes' employs a pejorative term for homosexual women.\\r\\n\\r\\nThese key features collectively contribute to an environment of intolerance and marginalization of the groups mentioned. The context implies aggressive intent towards these communities, reinforcing negative stereotypes.\\r\\n\\r\\nIn conclusion, this text is classified as offensive because it employs multiple slurs and objectifying language aimed at African Americans, women, and the homosexual community, promoting a hostile tone and intent.\", 'Time Taken (s)': 15.93}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=1587, version=82, score=26.146084, payload={'Row Number': 1587, 'tweet_text': 'hey <user> <user> you fascist pigs since idk y i am banned def a white person or trumper but i repeat myself when tf is the ban over u nazi scum racist sexist white supremacist terrorism supporting garbage wastes of flesh you re all trash not raised right be ashamed', 'key_features': '[]', 'label': 'normal', 'target': None, 'Response': '**Offensive**:\\r\\n\\r\\nThe text contains strong language and insults directed at a specific group. Key features include:\\r\\n\\r\\n- Use of terms like \"fascist pigs\", \"nazi scum\", \"racist\", \"sexist\", \"white supremacist\" which are highly charged and inflammatory.\\r\\n- The aggressive tone and use of expletives (\"garbage wastes of flesh\") further amplify the offense.\\r\\n  \\r\\nThe target appears to be users with opposing political views, specifically those identified as white supremacists or supporters of a certain political figure (trumper). The text does not contribute to productive discourse but serves to demean and antagonize.\\r\\n\\r\\nConsidering the hostile language, personal attacks, and targeting of a group based on their presumed beliefs and identity, this text is classified as offensive.', 'Time Taken (s)': 17.85}, vector=None, shard_key=None, order_value=None)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = \"All gay people are disgusting and should be punished\"\n",
    "top_k = 5\n",
    "embedding = EMBEDDINGS_MODEL.encode(user_input)\n",
    "search_result = qdrant_client.search(\n",
    "    collection_name=index_name, query_vector=embedding, limit=top_k\n",
    ")\n",
    "search_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
