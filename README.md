<h1 style="color:blue;">Developing an Agent for Hate Speech Detection.</h1>


<h2>Overview</h2>
<p>We are developing a state-of-the-art hate speech detection agent specifically designed to not only identify but also thoroughly explain harmful content on social media platforms. Our innovative approach integrates advanced language models with deep psychological insights and utilizes labeled data to create a robust, context-aware tool. The core of our development effort is centered on explainability, ensuring that our agent not only detects hate speech but also provides clear, understandable explanations of the reasons behind each classification. This feature is crucial for transparency and helps in educating users about the subtleties of hate speech, ultimately contributing to more informed and conscientious online interactions.</p>

<h2>Key Objectives</h2>
<ul>
  <li><strong>Accurate Detection:</strong> Build a reliable agent that identifies hate speech across diverse contexts.</li>
  <li><strong>Detailed Explanations:</strong> Provide clear, understandable explanations for the detection decisions, enhancing transparency.</li>
  <li><strong>Severity Assessment:</strong> Evaluate the severity of detected hate speech to guide response strategies.</li>
  <li><strong>Actionable Insights:</strong> Offer actionable suggestions based on the severity, assisting moderators and platform managers.</li>
</ul>

<h2>Current Status</h2>
<p>We are currently using the HateXplain dataset, which is pre-labeled with categories: Hate Speech, Offensive, and Normal. Our experiments with various prompting techniques—chain of thought, few-shot, and zero-shot—aim to refine the explanations provided by our model. 
A comprehensive survey has been conducted, assessing not only which explanations were preferred by participants but also collecting demographic data including their job roles and ages. This survey further explored participants' trust in AI's capabilities to effectively detect hate speech, underscoring our project's commitment to understanding the social and psychological dimensions of hate speech detection. The feedback and demographic analysis are instrumental in developing a tool that resonates well with diverse user groups. The most effective explanation method, as determined by the survey, will be integrated into our Retrieval-Augmented Generation (RAG) framework. Additionally, we are developing a User Interface (UI) based on WebUI to make the system accessible and user-friendly. This interface will allow users to interact with the model, review explanations, and understand the reasoning behind AI-generated classifications, ensuring transparency and interpretability.</p>

<h2>Part of the TWON Initiative</h2>

This project is undertaken as part of the TWin of Online Social Networks (TWON), an EU-funded research initiative studying the societal impacts of online social networks like Facebook, Twitter, and TikTok. By contributing to TWON, we aim to foster healthier online environments and reduce societal harm.
